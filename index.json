[
{
	"uri": "https://hahafamilia.github.io/bigdata/",
	"title": "Bigdata",
	"tags": [],
	"description": "",
	"content": "  클러스터 네트워크 일시 장애로 인한 Kafka/Zookeeper 문제해결     IntelliJ maven scala 프로젝트 설정     Apache Pig Latin     Cloudera CDH Configuration     Apache Zeppelin Project Build     Apache Zeppelin on CDH, Yarn     Apache Zeppelin Upgrade from 0.8.1 to 0.8.2     Cloudera CDH 6.1.1 설치하기     Kafka Manager 설치     Apache Zeppelin Interpreter, Hive, Impala     Apache Zeppelin Usage     Apache Zeppelin 설치, QuickStart     Oozie Workflow Email 알림 설정     AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집     Cloudera Manager 알람 설정, Gmail SMPT 서버 사용     Hive Java UDF, 유니코드     Kafka Broker 디스크 증설, RAID구성, OS 재설치     "
},
{
	"uri": "https://hahafamilia.github.io/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": "  Python 개발환경, Pyenv, Anaconda3     "
},
{
	"uri": "https://hahafamilia.github.io/howto/",
	"title": "HowTo",
	"tags": [],
	"description": "",
	"content": "  FFMPEG를 이용해 음악 플레이리스트 동영상 만들기     휴고 설치 및 설정, Learn 테마, Hugo Website     Markdown 작성법     Jekyll, Github.io, Minimal mistakes 블로그 만들기, 목차 한글링크 버그     Git     "
},
{
	"uri": "https://hahafamilia.github.io/book/",
	"title": "Book",
	"tags": [],
	"description": "",
	"content": "  스파크 완벽 가이드     하이브 핵심 정리, Apache Hive Essentials     카프카, 데이터 플랫폼의 최강자     모든 주식을 소유하라     하둡 애플리케이션 아키텍처     "
},
{
	"uri": "https://hahafamilia.github.io/life/",
	"title": "Life",
	"tags": [],
	"description": "",
	"content": "  필리핀 세부 마리바고 블루워터 여름휴가     "
},
{
	"uri": "https://hahafamilia.github.io/tags/2020/",
	"title": "2020",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/kafka/",
	"title": "kafka",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/troubleshooting/",
	"title": "troubleshooting",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/zookeeper/",
	"title": "zookeeper",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/kafka-zookeeper-troubleshooting/",
	"title": "클러스터 네트워크 일시 장애로 인한 Kafka/Zookeeper 문제해결",
	"tags": ["2020", "zookeeper", "kafka", "troubleshooting"],
	"description": "",
	"content": " 장애알림으로 시작하는 상쾌한 월요일입니다? 빅데이터 플랫폼의 클러스터 일부 서버에서 경고 알림이 보고 되었어요. Cloudra Manager 의 서비스 리스트에는 Kafka 서비스에서 Lagging Replicas Test 실패 발생되었다고 경고를 보여주고 있네요. 이번 경우도 문제의 원인은 눈에 보이는 것과는 다르네요. 어떤 일이 있었던걸까요?\nVersion  Cloudera CDH 6.1.1 Cloudera Kafka 2.11-2.0.0-cdh6.1.1  현상파악 Cloudera Manager 확인 3대의 Kafka Broker 중에 01~02 서버에서 경고가보여지고, 03 서버는 정상으로 보여져요. 문제발생한 시간대에 Kafka 로부터 유입되는 데이터의 유실은 다행히 발생하지 않았어요. 먼저 시스템팀에 서버 및 네트워크 이슈가 있었는지 문의했어요. 돌아오는 답변은 항상 같죠.\n현상을 정리하면 클러스터는 장애를 극복하고 정상동작하였고, 문제발생한 시간대에 Cloudera Agent 의 로그 수집이 정상적이지 않아 차트의 이빨이 빠졌네요. Kafka Manager 확인 Kafka Manger 의 Topics 에서는 Broker Leader Skew, Under Replicated 가 확인되요. 추가로 Brokers Spread 가 150 이라는 거예요.  Broker Leader Skew : 리더가 브로커에 균등하게 분산되어 있는지의 퍼센트 Under Replicated : 파티션별로 리플리케이션 상태 정보 퍼센트 Brokers Spread : 파티션들이 몇개의 브로커에 분산되어 있는지의 퍼센트  Under Replicated, Broker Leader Skew 는 Reassign Partition 을 진행해 주면 되는데, Brokers Spread 수치가 150 이라는게 이상해요. 그래서 더 확인해 보니 Kafka Manager Broker 탭에서 2개의 Broker만 보여지네요.\n Reassign Partition 진행과정은 일전에 포스팅한 내용이 있어요.\n 현상을 정리하면 클러스터에서 Kafka 서비스의 Broker 03을 클러스터에서 제거했고, Kafka Manager 는 Skew, Under Replication 을 보고 했어요.\nKafka Broker 가 제거된 이유 Kafka Broker 03 서버 로그를 확인해요. Cached zkVersion\u0026hellip; 라는 로그가 보여요. Zookeeper 관련 문제로 파악되죠. Cloudera Manager Zooker 서비스의 이력을 확인하니 Zookeeper 서버들의 호스트에 불량상태 이력이 보이네요. 이때 Zookeeper 3대 서버중 2대의 서버에 5분사이에 네트워크 단절이 다수 발생했다는 보고를 받았어요.\n현상을 정리하면 Zookeeper 서버에 네트워크 연결실패가 발생했어요. 과정에서 epoch 불일치가 발생하고 Broker 내 파티션들의 ISR 상태를 유지할 수 없어 Broker 03 을 클러스터에서 제거했을 거예요.\n1개의 브로커되면서 3개의 파티션을 가진 토픽의 리더와 파티션들은 Broker Leader Skew 33%, Brokers Spread 150% 으로 불일치를 보여요. 1개 브로커가 보유하던 Replica 들만큼의 Under Replicated 33% 발생해요.\n조치사항 Cloudera Community, Stack overflow, Jira KAFKA-2729, Jira KAFKA-3042\n동일한 증상을 경험한 글들을 확인할 수 있어요. Cloudera Manager 에서 Broker03 재시작 했어요. Shutdown 과정에서 Broker 를 사용할 수 없다는 보그를 보이면서 재시작은 정상적으로 진행되요. Kafka Manager 에서 새로 추가된 Broker 를 확인할 수 있고 각 토픽의 ISR 또한 정상으로 전환되었어요. "
},
{
	"uri": "https://hahafamilia.github.io/tags/2019/",
	"title": "2019",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/intellij/",
	"title": "intellij",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/intellij-maven-scala/",
	"title": "IntelliJ maven scala 프로젝트 설정",
	"tags": ["2019", "intellij", "maven", "scala", "spark-streaming"],
	"description": "",
	"content": " IntelliJ IDE 에서 spark streaming 개발을 위해 scala maven 프로젝트 생성 방법을 알아봐요. scala 프로젝트는 sbt 를 기본으로 사용하지만, maven 에 익숙하여 maven 으로 프로젝트를 생성해요. scala-archetype-simple 으로 프로젝트 생성이 가능한데, 제가 직접 구성하는게 좋아요.\nVersion  Spark 2.4.0 Scala 2.11 Hadoop 2.7 Java 8 Window  Spark, Hadoop 설치 Spark Download 에서 Spark 를 다운로드해요. 운영중인 클러스터의 스파크버전과 맞추어 2.4.0 버전의 Pre-built for Apache Hadoop2.7 을 다운로드 했어요. 다운로드한 파일을 압축해제 하고 SPARK_HOME 환경변수로 등록후 PATH 설정해요.\nWindow 에서 Hadoop 바이너리파일을 제공하는 winutils 라는 Git 프로젝트가 있어요. zip 으로 한후 압축풀고 Hadop2.7 디렉토리를 HADOOP_HOME 환경변수로 등록후 PATH 설정해요.\nIntelliJ 프로젝트 생성  File \u0026gt; New \u0026gt; Project \u0026gt; Maven 빈 프로젝트 생성\n /src/main/java, /src/test/java 디렉토리 삭제\n /src/main/scala, /src/test/scala 디렉토리 생성\n scala 디렉토리 마우스 우클릭, Mark Directory as \u0026gt; Sources Root(TestSources Root)\n File \u0026gt; New \u0026gt; .ignore file, Languages, frameworks \u0026gt; check scala, `Global templates \u0026gt; check JetBrains, check Windows(macOS)\n 프로젝트명 마우스 우클릭 Add Framework Support... scala SDK 지정\n pom.xml 에 디펜던시를 추가해요. 구조화된 스트리밍을 프로그램을 개발할 예정이라 우선 아래의 디펜던시만 추가했어요.\norg.scala-lang:scala-library org.apache.spark:spark-core_2.11 org.apache.spark:spark-sql_2.11   확인 Structured Streaming Programming Guide 에 나와있는 테스트 코드작성하고, nc -lk 9999 Netcat 띄우고, IntelliJ 에서 Run SimpleApp 실행시킨후, Netcat 에서 텍스트 입력해봐요.\nimport org.apache.spark.sql.SparkSession object SimpleApp { def main(args: Array[String]) : Unit = { val spark = SparkSession.builder().appName(\u0026quot;SimpleApp\u0026quot;).master(\u0026quot;local[*]\u0026quot;).getOrCreate() val lines = spark.readStream.format(\u0026quot;socket\u0026quot;) .option(\u0026quot;host\u0026quot;, \u0026quot;loalhost\u0026quot;).option(\u0026quot;port\u0026quot;, 9999).load() import spark.implicits._ val words = lines.as[String].flatMap(_.split(\u0026quot; \u0026quot;)) val wordCounts = words.groupBy(\u0026quot;value\u0026quot;).count() val query = wordCounts.writeStream.outputMode(\u0026quot;complete\u0026quot;).format(\u0026quot;console\u0026quot;).start() query.awaitTermination() } }  "
},
{
	"uri": "https://hahafamilia.github.io/tags/maven/",
	"title": "maven",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/scala/",
	"title": "scala",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/spark-streaming/",
	"title": "spark-streaming",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/apache-piglatin/",
	"title": "Apache Pig Latin",
	"tags": ["2019", "bigdata", "apache-pig"],
	"description": "",
	"content": " Apache Pig Yahoo 에서 공개한 걸로 알고 있어요. 최근 버전은 Hive on Spark 처럼 Pig on Spark 으로 사용하는군요. 새로운 Flow 코드 작성시 잘 사용하진 않지만, SQL 사용시 함수와 프로시져를 만들어야 하는 경우가 있는데, 그런 경우 Pig 를 사용하고 있어요. ASIS Flow 에서 사용되어지고 있는 코드 들이 있어서 간단히 문법에 대해 정리 해봐요.\nPig Latin Basic 연산자 및 명령어들은 대소문자를 구분하지만, 별칭 및 함수 이름은 대소문자를 구분해요.\nData types int, long, float, double, chararray, Bytearray, Boolean, Datetime, Biginteger, Bigdecimal, Tuple, Bag(collection of tuples), Map\nOperator 피그에는 몇몇 종류의 operator 있는데, SQL 과 느낌이 비슷해요.\n 로드/저장: LOAD, STORE 필터: FILTER, DISTINCT, FOREACH GENERATE, STREAM 그룹/조인 : JOIN, COGROUP, GROUP, CROSS 정렬 : ORDER, LIMIT 결합/분할 : UNION, SPLIT Diagnostic : DUMP, DESCRIBE, EXPLAIN, ILLUSTRATE  주석 /* multi line comments */  -- single line comments\nShell 안에서의 사용 #!/usr/bin/env bash today=$(date +\u0026quot;%Y-%m-%d\u0026quot;) cat \u0026lt;\u0026lt; PIGEND \u0026gt; ./pigscript.pig set [environment] register [library] pig codes ... {$today} PIGEND pig ./pigscript.pig  로드/저장 LOAD Relation_name = LOAD 'Input file path' USING function as schema;\nstudent = LOAD 'hdfs://localhost:9000/pig_data/student_data.txt' USING PigStorage(',') as ( id:int, firstname:chararray, lastname:chararray, phone:chararray, city:chararray );  STORE STORE Relation_name INTO 'directory path' [using function];\nSTORE student INTO 'hdfs://localhost:9000/pig_Output/' USING PigStorage (',');  Diagnostic  Dump Relation_name; 결과를 화면에 출력 Describe Relation_name; 스키마 출력 explain Relation_name; 논리적, 물리적, MR plan 출력 illustrate Relation_name; statement 를 단계적으로 실행  그룹/조인 GROUP Group_data = GROUP Relation_name BY age;\ngroup_data = GROUP student_details by age; group_multiple = GROUP student_details by (age, city); group_all = GROUP student_details All;  COGROUP 두개 이상의 relation 을 그룹핑 해요.\ncogroup_data = COGROUP student_details by age, employee_details by age;  (23,{(6,Archana,Mishra,23,9848022335,Chennai),(5,Trupthi,Mohanthy,23,9848022336 ,Bhuwaneshwar)}, {(5,David,23,Bhuwaneshwar),(3,Maya,23,Tokyo),(2,BOB,23,Kolkata)})  SELF JOIN Relation3_name = JOIN Relation1_name BY key, Relation2_name BY key; Relation1_name, Relation2_name 가 동일한 데이터소스를 LOAD 해서 JOIN 해요.\ncustomers3 = JOIN customers1 BY id, customers2 BY id;  INNER JOIN result = JOIN relation1 BY columnname, relation2 BY columnname;\nLEFT OUTER JOIN Relation3_name = JOIN Relation1_name BY id LEFT OUTER, Relation2_name BY customer_id;\nRIGHT OUTER JOIN outer_right = JOIN customers BY id RIGHT, orders BY customer_id;\nFULL OUTER JOIN outer_full = JOIN customers BY id FULL OUTER, orders BY customer_id;\n다중키 JOIN Relation3_name = JOIN Relation2_name BY (key1, key2), Relation3_name BY (key1, key2);\nCROSS cross_data = CROSS customers, orders;\n결합/분할 UNION Relation_name3 = UNION Relation_name1, Relation_name2;\nstudent = UNION student1, student2;  SPLIT SPLIT Relation1_name INTO Relation2_name IF (condition1), Relation2_name (condition2);\nSPLIT student_details into student_details1 if age\u0026lt;23, student_details2 if (22\u0026lt;age and age\u0026gt;25);  필터 FILTER Relation2_name = FILTER Relation1_name BY (condition);\nfilter_data = FILTER student_details BY city == 'Chennai';  DISTINCT Relation_name2 = DISTINCT Relatin_name1;\ndistinct_data = DISTINCT student_details;  FOREACH Relation_name2 = FOREACH Relatin_name1 GENERATE (required data);\nforeach_data = FOREACH student_details GENERATE id,age,city;  정렬 ORDER BY Relation_name2 = ORDER Relatin_name1 BY (ASC|DESC);\norder_by_data = ORDER student_details BY age DESC;  LIMIT Result = LIMIT Relation_name required number of tuples;\nlimit_data = LIMIT student_details 4;  내장함수 Eval, Load/Store, String, Datetime, Math 등의 내장 함수는 링크로 대체 할게요.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/apache-pig/",
	"title": "apache-pig",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/bigdata/",
	"title": "bigdata",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/cloudera-cdh-configuration/",
	"title": "Cloudera CDH Configuration",
	"tags": ["2020", "cloudera-cdh", "configuration", "troubleshooting"],
	"description": "",
	"content": " Bigdata 플랫폼으로 Cloudera CDH 6.1.x 를 운영중 트러블슈팅과 설정에 대해 이야기 해볼게요.\nVersion  Cloudera CDH 6.1 Oracl Java 1.8  YARN Turning YARN YARN 의 리소스 관련 설정의 기본 값 Default Memory Setting\nYARN 리소스 튜닝 방법 Turning YARN\n노드의 전체 가용 리소스에서 서비스 데몬들의 리소스 사용량을 제하고 리소스를 할당 해요. 튜닝 문서와는 다르게 Cloudera Manager 에서 각 호스트들의 리소스 사용량은 상이해요. 튜닝 문서와 Cloudera Manager \u0026gt; Host \u0026gt; Worker \u0026gt; Resource 리소스 사용량을 참고하여 Yarn 에 할당할 CPU, Memory 를 결정한 후, 아래의 프로퍼티에 값을 설정해요. Impala, Kudu, Hbase 를 사용중이면 추가적인 메모리 할당이 필요해요.\nyarn.nodemanager.resource.cpu-vcores yarn.nodemanager.resource.memory-mb yarn.scheduler.minimum-allocation-vcores yarn.scheduler.maximum-allocation-vcores yarn.scheduler.increment-allocation-vcores yarn.scheduler.minimum-allocation-mb | 1G yarn.scheduler.maximum-allocation-mb | 101G yarn.scheduler.increment-allocation-mb | 512M  Hive HA 공식 문서 Configuration HiveServer2 HA\n절차  HAProxy 설정 HiveServer2 인스턴스를 추가 Locate the HiveServer 2 Load Balancer property Set hostname:port Restart Hive  Check  Hive on Spark Oozie job Hue Hive / Impala query scdh api, Impala JDBC Zeppelin Hive JDBC   Oozie job 들은 Hive LB 주소로 변경되어야 하며 스케쥴은 재제출되어야 해요.\nImpala, Oozie Server 는 HiveServer2 설정은 없지만, Restart 필요할 수 있어요.\n Hive Metastore Server HA Metastore HA 는 Load balance 기능은 없고 장애시 failover 를 진행 하도록 구성 할 수 있어요.\nImpala timezone bigint 시간 값을 from_unixtime() 함수를 통해 문자열로 변환하여 사용할 경우, Hive 같은 경우 현지 timezone 이 적용되는데, Impala 같은 경우 UTC 기준 변환되요.\nImpala 구성 Impala Daemon 명령줄 인수 고급 구성 메뉴에 아래와 같이 설정하여 현지 timezone 을 따르게 할 수 있어요.\n--use_local_tz_for_unix_timestamp_conversions=true --convert_legacy_hive_parquet_utc_timestamps=true  Impala 쿼리 Oozie Workflow 등록 Bash 쉘을 통해 impala-shell CLI 를 사용해서 Shell 을 실행하거나 Impala 쿼리를 Oozie Workflow 를 등록하여 배치를 작성할 수 있는데요. PYTHON_EGG_CACHE 오류가 발생 할 수 있어요. Shell 상단에 캐시 경로를 지정해 주면 되요.\nexport PYTHON_EGG_CACHE=/tmp/.python-eggs  Oozie Schedule Timezone Oozie Server 에 Workflow 를 예약등록 할때 사용되어지는 Timezone 을 변경해야해요. Oozie 구성 oozie-site.xml에 대한 Oozie Server 고급 구성 에 값을 추가하여 설정해요.\noozie.processing.timezone GMT+0900  Capture output 오류 Workflow 실패의 원인 중에 capture output 을 사용할 경우, output 사이즈가 기본설정값(2048) 을 초과하여 오류가 발생 할 수 있어요. Oozie 구성 action-conf/default.xml 에 대한 Oozie Server 고급 구성 에 값을 추가하여 사이즈 설정 할 수 있어요.\noozie.action.max.output.data 10240  Hue Timezone Hue UI의 Timezone 설정은 time_zone 에 값을 Asis/Seoul 변경해요.\nKafka Kafka Manager Jmx Kafka Manager 는 Kafka 클러스터를 모니터링 할 수 있는 좋은 도구 인데요. Kafka Jmx 서버에 접속하여 매트릭스를 수집해요. 그런데, Kafka 는 JMX 서버를 127.0.0.1 로 바인딩하기 때문에, 공인/사설 IP 간의 접속이 불가능해요. Kafka 구성 Additional Broker Java Optoins 설정에서 Jmx 포트를 0.0.0.0 으로 바인딩 해주세요.\n-Dcom.sun.management.jmxremote.host=0.0.0.0 -Dcom.sun.management.jmxremote.local.only=true  Kafka Broker 역시나 공인/사설 환경에서 producer API 서버에서 Kafka Broker 에 접속하기 위해서는 Kafka Broker 서버를 0.0.0.0 으로 바인딩 해야 해요. Kafka 구성 kafka.properties에 대한 Kafka Broker 고급 구성 설정에서 각 Borker 마다 아래와 같이 설정해주세요.\n#listeners=PLAINTEXT://0.0.0.0:9092 #advertised.listeners=PLAINTEXT://[공인IP]:9092  "
},
{
	"uri": "https://hahafamilia.github.io/tags/cloudera-cdh/",
	"title": "cloudera-cdh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/configuration/",
	"title": "configuration",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/zeppelin-project-build/",
	"title": "Apache Zeppelin Project Build",
	"tags": ["2019", "zeppelin"],
	"description": "",
	"content": " Zeppelin 소스 코드를 빌드해봐요. 오픈소스 수정은 선호하진 않지만, Frontend 화면 수정은 필요할 것 같아요.\nPersonalized 기능이 필요한데 0.8.2 버전에서 Bug ZEPPELIN-3065 가 있어요.\nZeppelin Posts  Zeppelin Install \u0026amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Versions  Zeppelin 0.8.2 Git Any Maven 3.1 or igher JDK 1.7 Mac, IntelliJ   제환경은 OpenJDK 1.8 이예요. 빌드는 잘 되요.\n Build Zeppelin 공식 문서 링크\nProject Build Download source code stable 버전으로 하시는게 정신건강에 좋아요.\ngit clone -b v0.8.2 https://github.com/apache/zeppelin.git zeppelin  Maven build ./dev/change_scala_version.sh 2.11 # build zeppelin with all interpreters and include latest version of Apache spark support for local mode. mvn clean package -DskipTests -Pspark-2.0 -Phadoop-2.4 -Pr -Pscala-2.11  IntelliJ 에서는 View \u0026gt; Tool Window \u0026gt; Maven \u0026gt; Execute Maven Goal\n문제해결 R 관련 오류가 발생하는데, R interpreter 를 빌드에서 제외하길 원하시면 -Pr 옵션을 제거하고 다시 빌드하면 성공해요.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/zeppelin/",
	"title": "zeppelin",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/zeppelin-on-cdh/",
	"title": "Apache Zeppelin on CDH, Yarn",
	"tags": ["2019", "zeppelin"],
	"description": "",
	"content": " Apache Zeppelin 과 CDH 를 연동해요.\nYarn 리소스 매니저 관리하에 Spark 어플리케이션을 실행시킬 수 있어요.\nZeppelin Posts  Zeppelin Install \u0026amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Version  Zeppelin 0.8.2 Cloudera CDH 6.1.x  Zeppelin Zeppelin on CDH 공식 문서를 참고해요.\n설정 /conf/zeppelin-env.sh 파일을 수정해요. 설치 환경에 따라서 경로는 다를 수 있어요.\nexport MASTER=yarn-client export SPARK_HOME='/opt/cloudera/parcels/CDH/lib/spark` export HADOOP_CONF_DIR='etc/hadoop/conf'  Cloudera Manager \u0026gt; Yarn \u0026gt; Application 목록에서 Zeppelin 이 실행중인걸 확인 할 수 있어요.\n확인코드 %spark val df = spark.read.option(\u0026quot;inferSchema\u0026quot;, \u0026quot;true\u0026quot;).csv(\u0026quot;hdfs:///tmp/sample_07.csv\u0026quot;) df.show()  테스트 코드도 잘 작동해요.\n문제해결  Permission Error 가 보인하면 HDFS 에 zeppelin 사용자 디렉토리 /user/zeppelin 를 만들어 주세요.\n Zeppelin 0.8.1 버전을 사용하신다면, 위의 확인 코드가 아래 이슈로 오류가 발생할 수 있어요.\nIssue ZEPPELIN-3939 0.8.2 버전에서 Fix(Github ZEPPELIN-3939) 되었네요.\n  "
},
{
	"uri": "https://hahafamilia.github.io/tags/ffmpeg/",
	"title": "ffmpeg",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/ffmpeg-music-youtube/",
	"title": "ffmpeg-music-youtube",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/howto/ffmpeg-music-youtube/",
	"title": "FFMPEG를 이용해 음악 플레이리스트 동영상 만들기",
	"tags": ["2019", "ffmpeg", "ffmpeg-music-youtube"],
	"description": "",
	"content": " 음원의 플레이리스트를 앨범 자켓 이미지를 포함시켜 동영상으로 만들 수 있나요? 라는 얘기를 듣게 되었어요. 의도는 Youtube 에는 음악등록을 할 수 없어서, 동영상으로 만들어서 업로드 해야된다고 하네요.\n그래서 간단하게 프로토타입을 만들어 봤어요. FFMPEG 검색을 해보니 이러한 시도를 하는 분들이 꽤 있나 보군요.\n프로토타입  하나의 음원을 이미지를 포함시켜 동영상으로 제작 각 동영상들을 이어 붙히기\nffmpeg -loop 1 -i Happy.jpg -i Happy.mp3 -shortest -acodec copy 2.mp4 ffmpeg -loop 1 -i StellaJang.jpg -i StellaJang.mp3 -shortest -acodec copy 1.mp4 echo \u0026quot;file 1.mp4\u0026quot; \u0026gt; playlist.txt echo \u0026quot;file 2.mp4\u0026quot; \u0026gt;\u0026gt; playlist.txt ffmpeg -f concat -i playlist.txt -c copy playlist.mp4   "
},
{
	"uri": "https://hahafamilia.github.io/bigdata/zeppelin-upgrade-0.8.2/",
	"title": "Apache Zeppelin Upgrade from 0.8.1 to 0.8.2",
	"tags": ["2019", "zeppelin"],
	"description": "",
	"content": " Apache Zeppelin 0.8.2 버전이 2019.11.29 일에 Release 되었어요. 0.8.1 버전에서 발견되었던 버그들도 수정이 되었으니 업그레이드를 진행 해보도록 할게요.\nZeppelin Posts  Zeppelin Install \u0026amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Apache Zeppelin 0.8.2 Upgrading 문서를 보니 0.8.x 버전에서의 업그레이드는 conf 와 notebook 디렉토리를 복사해주기만 하면 된다고 하니 손쉽게 진행 될 것으로 예상되요.\n업그레이드 Apache Zeppelin Download 다운로드 사이트에서 바이너리 파일을 다운로드 해서, 0.8.2 버전의 설치를 마치고 conf 와 notebook 디렉토리 옮겨준 후 서버를 구동하니 사이트가 정상적으로 열리네요.\nInterpreter 별도 추가한 interpreter 설정도 알아서 잡아주네요. 별도의 repository 설정을 했다라면 다운로드 하는데 시간이 조금 걸리긴해요.\nimpala 인터프리터가 사용하는 JDBC 라이브러리를 별도 디렉토리로 관리 해왔기에, 해당 디렉토리도 같이 복사해줬어요.\n그런데 문제가 있어요 모든 게 정상으로 보이는데 옮겨온 노트북들이 열리지 않네요. 새로운 노트북을 생성해도 만들어지지 않구요. 서버로그를 확인해도 특별한 오류가 보이지 않네요. 그래서\u0026hellip; 하나씩 하나씩 해봤어요.\n원인은 Helium 플러그인! Helium 차트를 사용했었는데, conf/helium.json 설정에 관련 정보가 있어요. 이 설정 파일을 옮기게 되면 노트북이 작동을 안해요.\nHelium 플러그인을 사용한 노트북이 많다면, 해결책을 찾아야 할텐데요. 그렇지 않다면 helium.json 파일은 옮기지 마시고, Zeppelin 서버를 실행해 보세요. 그리고 Helium 플러그인 기능을 다시 Enable 시키시면 되요.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/cloudera/",
	"title": "cloudera",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/cloudera-cdh-6_1-intall/",
	"title": "Cloudera CDH 6.1.1 설치하기",
	"tags": ["2019", "cloudera", "installation"],
	"description": "",
	"content": " ASIS 플랫폼의 고도화 일환으로 빅데이터 플랫폼을 신규로 구축하게 되었어요. 구축과정의 일환인 Cloudera CDH 6.1.1 설치과정을 뒤늦게사나마 정리해볼게요. 설치를 진행하기 전에 플랫폼 아키텍처의 설계와 물리서버 사양의 선택, 랙 배치 등이 우선되었겠죠? 이것에 대해서는 또 정리하도록 할게요.\n설치 과정은 크게 3단계로 진행되요.\n 설치하기 전에 Cloudera Manager 설치 CDH 구성요소 설치  Cloudera CDH 6.1 버전의 공식 문서를 참고해서 진행했어요.\nCloudera Enterprise 6.1 Document\nCloudera Installation Guide\n버전  CentOS 7.6.1810 Java 1.8 CDH 6.1.1 Express (free edition)   도메인은 example.com 으로 표기할게요. Repository 는 util01.example.com 호스트, Cloudera Manager 는 util02.example.com 호스트, Database 는 db01.example.com 에 설치했어요.\n사용된 명령어들은 운영체제와 버전등의 상황에 따라 다를수 있으니 섹션에 맞는 작업을 진행하면 되요.\nKerberos 인증, 이중화 관련 내용은 빠져 있어요.\n 설치하기 전에 Cloudera 가이드 문서 Before you Install 과정 이예요. 이 과정에서는 설치패키지들의 관리와 운영체제 설정을 다루고 있어요. Repository 구성을 제외하고 모든 물리 서버에 동일하게 구성해요.\nConfigure Network Names Set hostname, Edit /etc/sysconfig/network sudo hostnamectl set-hostname util01.example.com sudo echo 'HOSTNAME=util01.example.com' \u0026gt;\u0026gt; /etc/sysconfig/network  Edit /etc/hosts 192.168.100.101 util01.example.com util01 192.168.100.102 util02.example.com util02 192.168.100.103 master01.example.com master01 ...  DNS 를 이용할경우 PTR(역방향조회) 설정이 되어 있어야 해요.\n확인해보기 uname -a /sbin/ifconfig host -v -t A $(hostname)  Disabling the Firewall 방화벽을 사용할경우 포트사용목록에 나열된 모든 포트를 허용 해야해요.\nsudo systemctl stop firewalld sudo systemctl disable firewalld   CDH Components Ports\nCloudera Manager Ports\n Setting SELinux mode getenforce 명령어로 정책을 해서 enforcing 일경우 /etc/selinux/config 편집하여 SELINUX=enforcing 항목을 SELINUX=permissive 로 변경해요.\n재부팅 하거나 setenforce 0 명령어로 즉시 반영해줘요. SELinux는 설치가 종료된 후 정상화(setenforce 1) 해도되요.\nEnable an NTP Service yum install ntp NTP를 설치하고, /etc/ntp.conf 파일을 수정하여 NTP 서버를 추가합니다.\nserver 0.pool.ntp.org server 1.pool.ntp.org server 2.pool.ntp.org  sudo systemctl start ntpd 서비스를 시작하고, sudo systemctl enable ntpd 부팅시 실행되도록 서비스 활성화 해주세요.\nntpdate -u 0.pool.ntp.org, hwclock —systohc 명령어로 동기화 해주세요.\nInstall Python2.7 on Hue hosts Hue 가 서비스되는 호스트에는 Python2.7 버전이 필요해요.\nnproc 구성 설치시 자동 구성되는데, /etc/security/limits.conf 값은 /etc/security/limits.d/ 값에 의해 무시될 수 있어요. nproc 값은 65536, 262144 로 충분히 높게 설정하세요.\n내부 Parcel Repository 구성 Cloudera Software Repository 를 사용할경우, 항상 최신버전을 설치하게되요. 인터넷이 차단된 상황이거나 추후에 동일 버전으로 클러스터를 확장하기 위해서 내부 Repository 를 구성해야해요. Cloudera CDH 구성요소를 설치 할때 Parcel 파일을 사용하게 되요.\n다운로드 서버 sudo yum install httpd 웹서버를 설치하고, Apache HTTP Server 설정파일 /etc/httpd/conf/httpd.conf 의 Listen 포트도 주정해주고, MIME 도 추가해주세요.\nListen 18090 \u0026lt;IfModule mime_module\u0026gt; AddType application/x-gzip .gz .tgz .parcel  sudo systemctl start httpd Apache HTTP Server 시작\nParcel 다운로드 CDH6 sudo mkdir -p /var/www/html/cloudera-repos sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/cdh6/6.1.1/parcels/ -P /var/www/html/cloudera-repos sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/gplextras6/6.1.1/parcels/ -P /var/www/html/cloudera-repos sudo chmod -R ugo+rX /var/www/html/cloudera-repos/cdh6 sudo chmod -R ugo+rX /var/www/html/cloudera-repos/gplextras6  Sqoop Connectors sudo mkdir -p /var/www/html/cloudera-repos sudo wget --recursive --no-parent --no-host-directories http://archive.cloudera.com/sqoop-connectors/parcels/latest/ -P /var/www/html/cloudera-repos sudo chmod -R ugo+rX /var/www/html/cloudera-repos/sqoop-connectors  http://util01.example.com/cloudera-repos/ 저장소를 확인해보세요.\n내부 Package Repository 구성 Cloudera Manager 는 Package 를 이용해서 설치해요. 그전에 Package Repository 를 구성해줘요.\nPackage 다운로드 sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/cm6/6.1.1/redhat7/ -P /var/www/html/cloudera-repos sudo wget https://archive.cloudera.com/cm6/6.1.1/allkeys.asc -P /var/www/html/cloudera-repos/cm6/6.1.1/ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/cm6  /var/www/html/cloudera-repos/cm6/6.1.1/redhat7/yum/cloudera-manager.repo 파일의 baseurl 의 주소를 수정해 주세요.\nCloudera Manager 설치 Package Repository 등록 util01.example.com 호스트에 설치한 내부 Package Repository 를 등록해요.\nsudo wget http://util01.example.com:18090/cloudera-repos/cm6/6.1.1/redhat7/yum/cloudera-manager.repo -P /etc/yum.repos.d/ sudo rpm --import http://util01.example.com/cloudera-repos/cm6/6.1.1/redhat7/yum/RPM-GPG-KEY-cloudera  Install JDK sudo yum install oracle-j2sdk1.8 설치경로는 /usr/java/입니다.\nInstall Cloudera Manager sudo yum install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server  Database 설치 및 구성 Database 는 Cloudera Manager, Oozie Server, Hive Metastore Server, Hue Server 에서 사용해요.\nDatabase 는 클러스터 외부의 호스트에 설치해주세요. MySQL, MariaDB, PostgreSQL, Oracle 를 지원해요. 설치하는 방법은 Cloudera 문서 Installing and Configuring Databases 로 대체할게요. Cloudera 문서에는 Database 의 권장설정을 제시하고 있어요. 권장설정을 따라주세요.\nsudo systemctl enable mysqld sudo systemctl start mysqld  MySQL로 설치했어요. 서비스등록하고, 데이터베이스 시작해주세요. sudo /usr/bin/mysql_secure_installation 보안설정도 진행해주세요.\nCreating Databases for Cloudera Software Cloudera 의 각 서비스들이 사용할 database 들을 생성해주고, 사용자 권한 설정 작업을 해주어야해요.\nDatabase 가 설치된 호스트 서버에서 mysql -u root -p MySQL에 root 로 접속해주세요.\nCREATE DATABASE \u0026lt;databaseName\u0026gt; DEFAULT CHARARCTER SET \u0026lt;characterSet\u0026gt; DEFAULT COLLATE utf8_general_ci; GRANT ALL ON \u0026lt;databaseName\u0026gt;.* TO '\u0026lt;userName\u0026gt;'@'%' IDENTIFIED BY '\u0026lt;password\u0026gt;';  생성해야 하는 Database 는 아래와 같아요.\n   Service Database UserName     Cloudera Manager scm scm   Activity Monitor amon amon   Reports Manager rman rman   Hue hue hue   Hive Metastore metastore metastore   Sentry Server sentry sentry   Oozie oozie oozie    잘 만들어졌는지 확인도 해볼게요.\nshow databases; show grants for '\u0026lt;userName\u0026gt;'@'%';  Installing JDBC Driver Database 를 사용하는 서버들에는 JDBC Driver 가 설치되어 있어야 하는데요. 우선 Cloudera Manager 를 설치할 util02.example.com 호스트 서버에 설치 해주세요. Cloudera 는 MySQL 같은 경우 5.1 버전의 JDBC Driver 를 추천하고 있네요.\nwget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz tar zxvf mysql-connector-java-5.1.46.tar.gz sudo mkdir -p /usr/share/java/ cd mysql-connector-java-5.1.46 sudo cp mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar  Set up the Cloudera Manager Database Cloudera Manager, Database 가 동일한 호스트인지 서로 다른 호스트인지에 따라 방법이 다른데요. 이 문서에서는 서로다른 서버에 설치하였어요.\nDatabse와 Cloudera Manager 를 하나의 Host에 설치한 경우 sudo /opt/cloudera/cm/schema/scm_prepare_database.sh \u0026lt;databaseName\u0026gt; \u0026lt;databaseUser\u0026gt;;  Database와 Cloudera Manager 가 서로 다른 Host인 경우 sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h \u0026lt;dbDomain\u0026gt; --scm-host \u0026lt;cmDomain\u0026gt; \u0026lt;databaseName\u0026gt; \u0026lt;databaseUser\u0026gt;; # 예를들면 sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h db01.example.com --scm-host util02.example.com scm scm  CDH 및 기타 소프트웨어 설치 Cloudera Manager 설치를 마쳤어요. 이제 Cloudera Manager Server 를 실행하고, Admin Console 에 접속하면 CDH 설치가 시작되요.\nsudo systemctl start cloudera-scm-server Cloudera Manager Server 를 시작해요. http://util02.example.com:7180/ 주소를 통해 Cloudera Manager 관리 콘솔에 접속합니다. 최초 로그인 정보는 admin 입니다.\n CDH 는 Package 와 Parcels 로 설치가능한데, Cloudera는 Parcels 설치를 권장하고 있어요. 이유는 롤링 업그레이드 가능하기 때문이예요.\n이 문서에서는 TLS 설정을 하지않고 진행했어요.\n Parcel Repository 등록  Cloudera Manager WebUI \u0026gt; Navigaton bar \u0026gt; Hosts \u0026gt; parcels \u0026gt; Configuration Cloudera Manager WebUI \u0026gt; Menu \u0026gt; Administration \u0026gt; Settings \u0026gt; Category \u0026gt; Parcels  위의 두 메뉴에서 원격 Repository URL http://util01.example.com:18090/cloudera-repos/cdh6/6.1.1/parcels/ 을 등록 할 수 있어요.\nSSH 설정 각 호스트에 SSH 접속하여 설치가 진행되는데, root 비밀번호를 이용하거나, 공개키 설정이 되어 있어야 해요.\n설치 마법사 대부분 설치마법사가 이끈는 대로 따라가면 되고, 확인이 필요한 부분은 Cloudera 문서 Install CDH and Other Software 를 참고해 주세요.\nHost Inspector CDH 설치를 완료하면, Host Inspector 를 수행하고 아래와 같은 경고가 보일 수 있어요.\n Transparent Huge Page Compaction이 설정되었으며 심각한 성능 문제를 일으킬 수 있습니다.\n Transparent Huge Page 메모리를 많이 사용하는 플랫폼에서는 설정을 꺼주는게 좋아요.  Starting with CDH 6, PostgreSQL-backed Hue requires the Psycopg2 \u0026hellip;\n Hue 서비스는 Python 2.7 을 필요로해요. 앞에서 이미 설정했어요.   클러스터 생성 Cloudera 문서 Recommended Role Distribution 를 참고해서 Cluster 의 서비스 역할을 각 호스트에 어떻게 배치 할지에 대해 미리 계획을 세워두세요.\nCluster 를 생성하고, 사용자 지정 서비스를 선택하여, HDFS, Hive, Hue, Impala, Kafka, Oozie, Spark, YARN, ZooKeeper를 설치하면되요.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/installation/",
	"title": "installation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/kafka-manager-installation/",
	"title": "Kafka Manager 설치",
	"tags": ["2019", "kafka", "kafka-manager", "installation"],
	"description": "",
	"content": " KafkaManager 설치 Kafka Manager 를 설치해 볼게요. Kafka Manager 는 Yahoo 의 오픈소스 인데, Kafka 서비스의 상태를 확인하거나, Skew 등이 발생했을때 Reassign Partitoin 등을 할 수 있는 기능을 제공해줘요.\nhttps://hahafamilia.github.io/bigdata/kafka-broker-reinstall/ Github 에서 다운로드 한 후, Scala 빌드 빌드툴 sbt 로 빌드 해줘요.\ntar -xvzf kafka-manager-1.3.3.22.tar.gz cd kafka-manager-1.3.3.22 PATH=/usr/java/jdk1.8.0_141-cloudera/bin:$PATH JAVA_HOME=/usr/java/jdk1.8.0_141-cloudera \\ ./sbt -java-home /usr/java/jdk1.8.0_141-cloudera clean dist cp target/universal/kafka-manager-1.3.3.22.zip /usr/local cd /usr/local unzip kafka-manager-1.3.3.22.zip  conf/application.conf 설정파일에 Zookeeper 호스트 주소를 설정해 줘요.\nkafka-manager.zkhosts=\u0026quot;zook01.example.com:2181,zook02.example.com:2181,zook03.example.com:2181\u0026quot;  Kafka Manager 를 실행해요.\n/usr/local/kafka-manager-1.3.3.22/bin/kafka-manager \\ -java-home /usr/java/jdk-1.8.0_181-cloudera \\ -Dconfig.file=/usr/local/kafka-manager-1.3.3.22/conf/application.conf -Dhttp.port=18090  Cloudera Manager 웹 콘솔 Kafka 서비스 구성 메뉴에서, Kafka JMX 의 바인딩 포트를 0.0.0.0 으로 변경 해줘요.\n# Additional Broker Java Options(borker_java_opts) -Dcom.sun.management.jmxremote.host=0.0.0.0 -Dcom.sun.management.jmxremote.local.only=true   JMX Server 포트는 127.0.0.1 로 바인딩되어 공인IP 접속이 불가능 해요.\n "
},
{
	"uri": "https://hahafamilia.github.io/tags/kafka-manager/",
	"title": "kafka-manager",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/book/",
	"title": "book",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/book/%EC%8A%A4%ED%8C%8C%ED%81%AC%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C/",
	"title": "스파크 완벽 가이드",
	"tags": ["book"],
	"description": "",
	"content": " 스파크 창시자가 알려주는 스파크 활용과 배포, 유지 보수의 모든 것 오픈소스 클러스터 컴퓨팅 프레임워크인 스파크의 창시자가 쓴 스파크에 대한 종합 안내서입니다. 스파크 사용법부터 배포, 유지 보수하는 방법까지 포괄적으로 익힐 수 있습니다. 스파크 2의 개선점과 새로운 기능을 자세히 설명합니다. 구조화된 스파크 API의 특징과 공통 기능은 물론이고, 엔드 투 엔드 스트리밍 애플리케이션을 구축하는 새로운 고수준 API인 구조적 스트리밍을 함께 살펴봅니다. 이 책을 읽으면 스파크를 모니터링, 튜닝, 디버깅하는 데 필요한 기본 지식을 습득할 수 있습니다. 나아가 스파크의 확장 머신러닝 라이브러리인 MLlib을 사용하는 방법과 시나리오를 익힐 수 있습니다. (교보문고 발췌)\n교보문고 스파크 완벽 가이드\n출간  저자 : 빌 체임버스, 마테이 자하리아 옮김 : 우성한, 이영호, 강재원 출판 : 한빛미디어, 2018.12.12  목차  Part 1 빅데이터와 스파크 간단히 살펴보기 Part 2 구조적 API: DataFrame, SQL, Dataset Part 3 저수준 API Part 4 운영용 애플리케이션 Part 5 스트리밍 Part 6 고급 분석과 머신러닝 Part 7 에코시스템 부록 A 스파크 설치 및 실행 부록 B 더블린 원정대: 스파크 서밋 2017 더블린 참관기  개인평 책의 전체적인 느낌은 상당히 깊이 조절이 잘 되어지고 잘 짜여져 있다는 느낌이예요. 적절한 코드 예제와 어플리케이션 개발 및 상용 서비스 적용시에 챙겨야하는 포인트들을 집어주고 있어요. 스파크를 배우는 개발자에게 스파크에 대한 인덱싱을 만들어 주어, 전체적인 그림을 그려주고 각 인덱스별로 깊이 있는 학습을 할 수 있도록 해줘요.\n개인적으로 \u0026lsquo;고급분석와 머신러닝의 개요\u0026rsquo; 파트는 전반적인 방법론들을 설명해 주고 있어서, 머신러닝의 막연한 두려움 사라지게 해주는 가장 재미있게 봤던 파트예요.\n기억하기위해서 머신러닝 파트만 요약해서 별도 포스팅 해볼 예정이예요.\n이 책을 추천해요\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/travel/",
	"title": "travel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/life/travel-cebu-2019/",
	"title": "필리핀 세부 마리바고 블루워터 여름휴가",
	"tags": ["travel"],
	"description": "",
	"content": " 이번 여름 휴가는 필리핀 세부(Cebu) 막탄으로 다녀오게되었어요. 향공권, 마리바고 블루워터 리조트, 세부날씨, 그랩, 유심칩, 모닝글로리, 탑스그릴, 김떡순, 예스마트, 더테라스, 오스파, 플라워트리, 그랜드네일, 보노보노 구매대행, 그리고 브라질리언 왁싱 등의 여행을 준비하면서 다녀오고 나서의 후기를 간략히 남겨보려합니다.\n2019년 09월, 필리핀 세부, 블루워터 마리바고 여름휴가 어른 2명, 5살 아이 1명, 돌된 아이 1명 이렇게 4인 가족의 9월 21 ~ 9월 26 일까지의 일정 이었어요. 가기전에 날씨 검색해보니 이틀 정도 소나기 예상이였는데, 여행 기간 중에 비가 오진 않았어요. 오히려 약감 구름이 껴주면 물놀이 하기 더 좋더군요.\n예방접종 질병관리본부에 문의 하면 상세한 답변을 들으실 수 있어요.\n어른들은 장티푸스 예방 접종을 했고, 돌 된 아이가 여행전에 감기에 걸려서 예방접종은 홍역만 맞추고 다녀왔어요. 영아는 돌때부터 예방접종을 많이 맞게 되는데 저희 둘째는 이제 돌이라서\u0026hellip; 그 외 2개 정도 더 맞추고 가야 하는 걸로 알아요.\n5살 첫째 아이는 별도의 예방 접종은 하지 않았어요.\n항공권 저는 5개월 전에 항공권을 예매 했어요. 위메프의 원더페이 통해서 왕복 밤비행기 645,000 원으로 예매했는데, 비싸진 않은 것 같아요. 9월에 올라오는 특가 가격이 이와 비슷하더라구요.\n리조트 제가 리스트업 한 리조트는 제이파크 아일랜드, 마리바고 블루워터, 크림슨, 플렌테이션 베이, 코스타벨라 예요. 이번에 전 마리바고로 다녀왔는데, 제가 알아본 리조트의 특색은 다음과 같아요.\n제이파크 저희는 작년에 괌 PIC 리조트에 다녀왔는데, 비슷한 성격의 리조트 같아요. 5살 첫째 아이는 아직 워터파크를 온전히 다 즐기지 못하더라구요. 가격은 리스트내 상에 속해요.\n마리바고 엄마과 아이들 여행객들이 자주 가는 리조트라고 알려져 있어요. 2019년 9월 현재에도 리노베이션이 진행중이구요. 리스트내 타 리조트 대비 룸 컨디션이 별로라는 얘기가 있어요. 수영장 풀에 미끄럼틀이 있었다고 하는데, 없어졌어요. 가격은 리스트내 하에 속해요.\n크림슨 주말에 열리는 크림슨 폼파티 라는 컨텐츠가 인기예요. 저희 일정에는 폼파티를 즐길 수 없겠더라구요. 인피티니 수영장이 있어서, 아이들도 좋지만 커플들이 가기에 더 좋아 보여요. 세련미가 있고, 리스트내 타 리조트 대비 동선이 좀 길어요. 가격은 리스트내 하에 속해요.\n플랜테이션 필리핀의 로컬한 느낌의 리조트예요. 사진들 검색해 보니 가보고 싶더라구요. 라군사이드 숙소 바로 앞에 수영장, 모래놀이 시설이 있더라구요. 상대적으로 리조트 내 동선이 길어요. 가격은 리스트내 중에 속해요.\n코스타벨라 리스트내 규모가 작은 리조트예요. 한국여행객들이 많이 없다고해요. 리조트내 숙소 건물이 2개가 있는데, 그 중 한곳은 별로 여서 잘 선택해서 가야해요. 가격은 리스트내 하에 속해요.\n마리바고 블루워터(Bluewater Maribago)로 선택했어요. 어린 아이들 데리고 다니다가 어른들 체력 다 빠질까봐 동선이 짧은 곳이 1순위 선택기준이었어요. 그리고, 아이들이 놀 컨텐츠(수영장, 모래놀이), 룸컨디션과 수영장의 수질이 2순위 선택기준이었어요. 제이파크, 플랜, 크림슨이 우선 제외 됬고, 마리바고 아무마 스파와 코스타벨라 프리미엄 디럭스 견적을 받아보고 비교했어요. 코스타벨라가 조금 더 끌렸는데, 생각보다 높은 금액이어서 결국 마리바고로 다녀오게 되었네요.\n 두 리조트는 1박당 차이가 많지는 않아요. 제가 받은 견적 차이는 크진 4박 6일 기준 10% ~ 15% 정도 인데요. 이 차이는 리조트의 차이가 아니라 레이트 체크인/체크 아웃때문에 발생하는 비용이예요. 마리바고는 레이트 체크인/체크아웃이 가능한 업체 상품이 있고, 코스타벨라는 레이트 체크인은 안되고 레이트 체크아웃도 제가 찾은건 한군데 업체 뿐이였어요.\n 리조트의 등급이나 가격대는 코스타벨라가 더 낮은데, 마리바고를 많이 가다보니 업체 통한 가격이 더 저렴한가봐요. 여러 업체 견적 받아봤는데, 마리바고/코스트벨라 각각 가장 싼 업체가 정해져 있더군요. 이것은 그 업체의 숙박 패키지 때문이라서 타 업체와 비교할 필요가 없더군요.\n커뮤니티 네이버 카페로 세부100배즐기기 에서 많은 정보를 얻었어요. 다른 카페가 있는진 모르겠지만 이 카페만으로도 대부분의 정보를 얻으실 수 있어요. 리조트 예약도 카페네 업체를 통해서 했어요.\n인천공항 귀국하는날 운전하고 오는게 힘들 것 같아서 타다를 이용할까도 했는데, 비용은 주차요금이랑 크게 차이나진 않는 것 같아요. 하지만 카시트가 없어서 이번에도 발렛 주차 이용하게 되었어요. 제가 이용한 곳은 포니주차 예요. 일전에 괌 갈때도 이용했었는데요. 작은 문제가 있었는데도 친절하게 대해주셔서 앞으로도 이용할 예정이예요. 금액도 저렴한 편에 속해요.\n막탄공항 몇년전 보라카이 공항이 쓰러질 것 같이 오래된걸 보고 불안했던 경험이 있었는데, 세부 공항은 상당히 세련되어서 놀랬어요.\n선크림 3개, 담배 1보루 면세품으로 구매했는데, 면세품 구매시 테클이 심하다는 후기들이 많아서 봉투 버리고 케이스 다 뜯어서 가방에 넣어서 가지고 갔어요. 그런데 막상 입국할때 확인하지 않더라구요.\n입국 심사는 1시간 30분 걸렸어요. 제가 탄 비행기에는 사람들이 별로 없었고 앞좌석이라서 그정도 걸린 것 같은데요. 뒤에 도착한 비행기 분들은 2시간 이상 걸렸을 것으로 예상되요. 커플들도 다수 보이던데 부럽더라구요. +_~\n택시 리조트까지 Grab Car 이용할 계획이었는데, 피곤해서 바로 택시 탔어요. 택시 호객하시는 분에게 물어보니 달러 지불시 8달러 ~ 10달러 정도라고해서 그냥 택시 탔어요. 도착하니 기사님이 10달러 달래길래 8달러로 얘기됐다고 하니 8달러만 달라고 하더군요. 페소로 400 페소 정도 되는데, 귀국할때 그랩카 4인석 이용요금이 250페소 였어요.\n그랩 그랩은 한국에서 미리 설치하고 회원가입까지 해서 가야해요. 왜냐하면 설치후 가입시에 전화인증하는데 로밍아닌이상 인증이 불가능 해요.\n제가 그랩 예약을 2번 취소했어요. 목적지가 바뀌어서 한번, 거리가 너무 멀게 잡혀서 한번\u0026hellip; 그런데 체크아웃하고 공항가기 위해서 그랩 잡으려 하는데, 취소가 많다고 18시간 이후에나 이용해야한다는 메시지가\u0026hellip; 엄청 당황했어요.\n부랴부랴 짝꿍님의 휴대폰에 그랩설치 했지만 인증이 안되더라구요. 다행이 리조트에 얘기해서 잡아달라고 했더니 잡아주셔서 무사 귀국 했어요.\n유심 괌에서는 와이파이 사용했었는데, 유심이 저렴에서 세부에서는 유심 사용했어요. 막탄공항 나오시면 유심 판매하는곳 그리고 택시 타는곳이 바로 보여요. Smart, Globe 가 있던데 글로브 유심 6G, 5일 짜리 만원 안되는 금액에 줄도 없어서 기다리지 않고 바로 구매했어요.\n 마리바고 리조트 Wifi 가 유심보다 더 빠르더라구요.\n 환전 달러를 준비해 갔고, 막탄공항에서 일부 환전하고, 마리바고 리조트 내에서 일부, 세이브 모어에서 전액 환전했어요.\n 막탄공항 1달러 47페소 마리바고 리조트 1달러 48페소 세이브모어 1달러 51페소   100달러 짜리를 더 쳐준다는 얘기가 있는데, 제가 환전할때는 그런 얘기는 없었어요.\n 마리바고 블루워터(Bluewater Maribago) 마리바고 는 로드 이름이더라구요. 현지인에게 리조트 얘기할 때 블루워터 라고 해야 정확히 알아들어요.\n룸 컨디션 아무마스타 리노베이션 351 호에 머물렀어요. 351호는 리조트 입구 옆옆 방인데 불쾌할 정도로 시끄럽지는 않았어요.\n바닥은 대리석으로 신발을 신고 생활하는 구조 인데, 아이들이다보니\u0026hellip; 첫날 팁을 주고 하우스킵핑 할때 팁을 주고 바닥 닦아달라고 부탁하고 신발 벗고 생활했어요. 둘째가 걸음이 빠른 편이라 12개월 인데도 걸어다녀요. 그리고 자주 넘어져요. 대리석 바닥이다보니 넘어질까봐 걱정이 많이 되더라구요.\n침구는 확실히 축축해요. 9월의 세부는 새벽에 약간 쌀쌀한데, 작은 이불을 가져가서 이불하고 가져간 비치타올을 아이들만 덥어줬어요. 어른들은 그냥 잤어요.\n단점들만 적은 것 같은데, 룸컨디션 나쁘지 않고 괜찮아요.\n벌레 룸안에서 개미 한마리 발견\u0026hellip; 하지만 개미 걱정은 안하셔도 될 거예요. 개미는 비치에서 모래 놀이하거나 그럴때 신경 쓰여요. 모기는 눈에 보이지 않지만 있어요. 훈증제 3개 풀가동하고 나갈때마다 홈키파 뿌리고 나갔어요. 여행중에 애들이 몇방 물렸는데, 룸보다는 택시이동이나 식당등에서 물린게 아닐까 싶어요. 탁탁 거리면서 모기 잡는 전기 채를 가져갔는데, 한번도 사용안했어요. 있는것 같은데 모기가 보이진 않아요.\n수질 샤워필터 챙겨가서 실치해서 쓰긴 했어요. 4일 지나서 필터가 20% 정도 갈색으로 변해요. 이전에 전 25년된 아파트에 살았었는데\u0026hellip; 그 아파트 보단 낳네요. ㅡ.ㅡ..\n아무마스파는 커다란 욕조가 있는데 수영끝나고 애들 씼기기 너무 좋아요. 그런데 여기에는 샤워필터 설치가 안되요. 첫날은 샤워필터에서 샤워 시켰는데, 그 이후부터는 욕조에서 그냥 씼겼어요. 수영 끝나고 아빠랑 애들 같이 욕조에 있고, 엄마 샤워하고, 애들 닦이고, 아빠 샤워하고 이러면 애들 씼기는 것도 스트레스 덜 받아요.\n다음에 또 간다면 샤워 필터 안 챙겨갈래요.\n수영장 수영장 수질은 락스 냄새가 나긴 해요. 하지만 수영 못할 물은 아니예요. 매일 아침 수영장 이물질 걷어내던데, 나무들이 많아서 낙엽이 떠다니긴해요.\n마리바고엔 3개의 풀이 있고, 저희는 아무마 스파 앞쪽풀이랑 알레그로 레스토랑 앞쪽 풀을 이용했어요. 알레그로 레스토랑 쪽 풀은 영유아가 놀만은 수심이 몇십센티 정도 되는 조그마한 풀이 존재해요. 저희는 아무마스파의 풀을 이용했는데, 4피트 풀과 5피트 풀로 나뉘어져 있어요. 수심이 깊긴 해도 튜브 태우고 엄마 아빠가 항상 옆에 있어서 괜찮았어요.\n알레그로 레스토랑 쪽 풀은 주변에 나무가 아무마스파 쪽보다 많아서 물이 좀 더 차가워요. 아무마쪽의 수영장에서는 아이들이 저녁 7시까지 혹은 더 늦게 까지 해도 감기 걸릴정도로 차갑지 않아요. 역시나 나무가 많아서 인지 레스토랑 쪽 풀은 바닥에 가끔 따라울 만한 것들이 밟히기도 했어요.\n리조트내 세탁 서비스 절대로 이용하지 마세요! 하하하\u0026hellip; 너무 비싸요. 사설업체 대비 10배 차이나나봐요. 빨래 갯수당 돈을 받기 때문에 애기 손수건 맡기는데도 일이천원 정도 들어가요. 최대 하루 소요되고 5시간 이내 받길 원하면 돈을 두배로 내야되요. 헉!!!\n식당, 마트, 마사지 모닝글로리, 탑스그릴, 김떡순 배달, 예스마트 배달, 세이브모어, 오스파, 플라워트리, 그렌드네일\n모닝글로리, 픽드랍 카톡ID morningglory101\n워낙 유명한 곳이라서\u0026hellip; 비싸긴 하더라구요. 음식도 맛있고 사장님도 친절하고, 한켠에 키즈카페 같은게 있어요. 직원이 4~5명 정되 되던데, 아이들이랑 놀아주기도 해요. 첫째는 엄마 아빠 없으면 잘 안노는데, 놀아주는 직원이 있어서 그런지 놀겠다고 해서 저희도 깝놀!! 모닐글로리 식사하시면 20% 할인되고, 30분/1시간 이렇게 있는데, 금액이 가물가물하네요. 할인전 30분 200페소, 1시간 350페소 이었던듯, 안비싸요. 덕분에 세부여행 첫음으로 짝꿍이랑 단둘이 음료 마시며 얘기 할 수 있는 시간이었어요.\n탑스그릴, 드랍 50페소 카톡ID topsgrill\n립과 칠리소스 새우 요리 먹었는데, 칠리소스새우요리가 세부에서 먹은 것중에 가장 맞있었어요. 보라카이 가서도 느꼈지만, 세부도 오토바이 많이 타고 그래서 인지 공기가 안좋아요. 탑스 그릴은 4층에 위치해 있고, 실외라서 그게 좀 신경 쓰였어요. 하지만 음식이 너무 맛있더라구요. 다음에는 배달 시킬래요.\n더테라스 카톡ID terracecebu\n블리스 호텔내에 있어요. 스테이크와 김치찌개 안어울리는 조합이지만 맛있더라구요. 김치찌개는 양이 정말 많아서 2인이 드셔도 될 정도예요. 픽드랍이 되는지는 모르겠지만 지배인으로 보이시는 분이 호텔쪽에 얘기해서 드랍해주시더라구요. 가격은 탑스그릴 수준 같아요.\n김떡순, 배달 카톡ID kimttoksun\n김밥, 떡볶이, 오징어튀김, 떡만두국 배달시켰어요. 한국분식집 맛 그대로 예요. 괜찮아요. 배추김치, 파김치가 조금 짠게 흠이라면..\n예스마트, 배달 카톡ID yesmart2\n1000 페소 이상이면 배달해주는데, 여행기간내에 3번이나 배달시켰어요. 가격은 한국 편의점 수준.. 삼다수 물을 주로 시켰고, 즉석식품과 컵라면, 그리고 마지막날 선물하기 위한 과자류\u0026hellip; 카사바칩이 배달대행보다 여기가 싸더라구요. 컵라면은 여기보다 세이브모어가 더 싸다는걸 마지막에 알았어요. 신라면 큰컵 10페소 정도의 차이?\n마사지 카톡ID 오스파 cebuospa, 플라워트리 flowerspa\n제가 세부에 다시 여행온다면 마사지 때문이예요. 아이들 재우고 짝꿍이랑 교대로 받아야해서 마리바고 가깝고 픽트랍 되는 곳으로 다녔어요\n오스파는 배드마다 커튼으로 분리되어 있고 시설이 좋은 편은 아니예요. 하지만 사장님이 친절하시고 마시지를 잘 해주시네요.\n플라워트리는 24시간 운영하고 시설이 깨끗해요. 오스파 만큼 친절하지는 않아요. 발 씼겨주실때 자리에 앉아서 1분정도 기다렸는데\u0026hellip; 아마 제가 오스파에서 마사지 않받았더라면 씼겨주는 걸 몰라서\u0026hellip; 제가 직접 씼었을 것 같아요. 방으로 분리되어 있고 방마다 2개의 배드가 있어요.\n전 오스파 마사지가 정말 시원했어요. 근육의 구조를 잘 이해하고 있다고나 할까? 짝꿍은 플라워트리가 더 좋았다고 하네요. 비용은 90분 스톤마사지 기준 800 ~ 850 사이 비슷해요.\n그랜드네일 카톡ID 01088877493, 픽드랍, 0.5박 공항 픽드랍 등 여러가지 패키지가 있어요.\n다른 네일 샵들을 알아봤었는데, 남자 블라질리언왁싱(어머!!! )을 같이 한다고 해서 여기서 했어요. 엄마 네일/패티 2800 페쇼, 아이 네일 700페소, 아빠 왁싱 1400 페소 적용되는 이벤트 없냐고 물어봤어요.(깍아달라는 얘기로 들으셨겠죠? ㅎㅎ\u0026hellip;) 엄마 네일/페티 하실경우 아이 네일 200 페소 해주신다고 하셨어요.\n친절히 잘해주셨어요. 여행끝나고 보니 네일이 살짝 뜯어졌네요. ㅠㅠ 남자 블라질리언 왁싱은 사장님이 직접하진 않으시고 필리핀 직원분들이 해주는데 생애 첫 경험이라 잘한건지 어쩐건지\u0026hellip; 한가지 확실한건 하나도 안아프다는 것?\n보노보노, 구매대행 카톡ID cebubono\n주변분들 간단한 선물사려고 구매대행했어요. 과자는 카사바칩과 스펀지구매 했는데, 카사바칩이 많이 안달고 맛있더라구요. 스펀지는 처음엔 달고 맛있는데 먹다보면 물려요. 너무 달거든요. 카사바 칩은 예스마트가 더 싸더라구요. 캐리어에 공간도 있어서 카사바칩은 예스마트 배달시키고, 나머지는 보노보노 이용했어요. 짝궁이 과자 이외에도 뭔가 사던데 뭘 산건지 모르겠어요. 수화물로 보낼수 있게 박스 포장 잘 해서 갔다 주셨어요.\n막탄공항 출국 체크아웃시간이 10시라서 남는 시간을 어떻게 보내야 하나? 공항엔 몇시까지 가야하나 고민 했어요. 체크아웃하는데 룸차지 지불하면서 리스트 꼼꼼하게 확인하고 몇번 물어봤더니\u0026hellip; 직원이 짜증내더군요. 리조트 있는동안 다들 친절해서 좋았는데, 이때 기분 살짝 나빴다죠. 체크아웃하고 알레그로 레스토랑에서 잠깐 시간 보내다가 11시 좀 넘어 공항으로 출발했어요.\n공항세 지불하고 출국 심사하는데도 오래 걸린다는 후기들이 있는데, 공항세 지불할때 줄이 없어서 바로 진행하고 출국 심사도 꼼꼼하게 살피긴 하는데\u0026hellip; 전체 적으로 사람들이 많이 없어서 2시간 전이면 충분 한 것 같더라구요.\n 2019년 9월 어느날 부터 공항세는 항공권에 포함되도록 바뀌었다고 합니다. 따로 공항세 지불을 안해요.\n 막탄 공항 면세는 확실히 비싸서 살게 없더라구요. 공항에 시간 보낼 데가 많이 없다는 후기가 있는데\u0026hellip; 많이 없긴 하지만 없지도 않아요. 버거킹과 몇개의 커피숍 식당이 있어요. 커피숍에는 편한 의자도 있구요. 커피 가격은 리조트 음료 가격 정도 한답니다.\n여름휴가를 마치고 귀국 비행기 에서 유심칩을 갈아끼워야 하는데\u0026hellip; 아치 핀이 없네요. 주차대행 연락하려면 갈아끼워야 하는데\u0026hellip; 한가지 팁을 드리자면 기내에 책자 있자나요. 책자의 스탭플러를 이용해 보세요. 저는 성공했어요. ^^\n다음에는 새벽비행기 이용 안할래요.\n세부100배즐기기 카페에 보면 임아트 라는 이름 사용하시는 분께서 세부 공항편에 대해 상세히 설명하신 글이 있어요. 간략 요약하면 한국 항공사는 비행기의 막탄공항 주차비를 아끼기 위해 그리고 한국 여행객들이 새벽편을 선호한다고 해서 새벽시간대에 항공편을 집중배치 해요. 그래서! 입국심사가 오래 걸린다는 거예요.\n또한 귀국할때 아이들은 이동하거나 비행기 안에서 꿀잠을 자는데 어른들은 이동하느라.. 아니들 보느라\u0026hellip; 잠을 못자니 귀국하고 집에 돌아와서 에너지 충전된 아이들 상대하는게 너무 힘들어요. 나이 먹었나 봐요. ㅠㅠ\u0026hellip;\n마리바고 블루워터 리조트 두번은 안갈래요. 리조트 총평은 SoSo~ 이지만 다른 리조트도 많잖아요~\n마지막으로 여행전부터 아이들도 아프고 짝꿍도 컨디션이 좋지 않아서, 저도 살짝 짜증이 났나봐요. 짝꿍에게 짜증을 좀 부렸어요.\n여러분들 짝꿍에게 잘해주세요\n이번 여행은 여유가 없어서 그런지\u0026hellip; 사진을 많이 못찍었네요. 마리바고 리조트에 상어가 산다는거 아시나요? 베이베 샤크 뚜뚜루 뚜뚜루 ~\nYour browser does not support the video tag.  "
},
{
	"uri": "https://hahafamilia.github.io/about/",
	"title": "About Me",
	"tags": [],
	"description": "",
	"content": " Juil Cho About Me \n\nEmail octchristmas@naver.com\nGitHub https://github.com/hahafamilia\n이전 블로그 https://tjstory.tistory.com/ \n"
},
{
	"uri": "https://hahafamilia.github.io/",
	"title": "Developement and Life Blog",
	"tags": [],
	"description": "",
	"content": " Developement and Life Blog  Bigdata    클러스터 네트워크 일시 장애로 인한 Kafka/Zookeeper 문제해결   IntelliJ maven scala 프로젝트 설정   Apache Pig Latin   Cloudera CDH Configuration   Apache Zeppelin Project Build   Apache Zeppelin on CDH, Yarn   Apache Zeppelin Upgrade from 0.8.1 to 0.8.2   Cloudera CDH 6.1.1 설치하기   Kafka Manager 설치   Apache Zeppelin Interpreter, Hive, Impala   Apache Zeppelin Usage   Apache Zeppelin 설치, QuickStart   Oozie Workflow Email 알림 설정   AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집   Cloudera Manager 알람 설정, Gmail SMPT 서버 사용   Hive Java UDF, 유니코드   Kafka Broker 디스크 증설, RAID구성, OS 재설치    Python    Python 개발환경, Pyenv, Anaconda3    HowTo    FFMPEG를 이용해 음악 플레이리스트 동영상 만들기   휴고 설치 및 설정, Learn 테마, Hugo Website   Markdown 작성법   Jekyll, Github.io, Minimal mistakes 블로그 만들기, 목차 한글링크 버그   Git    Book    스파크 완벽 가이드   하이브 핵심 정리, Apache Hive Essentials   카프카, 데이터 플랫폼의 최강자   모든 주식을 소유하라   하둡 애플리케이션 아키텍처    Life    필리핀 세부 마리바고 블루워터 여름휴가    "
},
{
	"uri": "https://hahafamilia.github.io/tags/hugo-staticgen/",
	"title": "hugo-staticgen",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/howto/hugo-staticgen/",
	"title": "휴고 설치 및 설정, Learn 테마, Hugo Website",
	"tags": ["2019", "hugo-staticgen"],
	"description": "",
	"content": " Jekyll 을 사용하다 이번에 Hugo 로 블로그를 이전하게 되었어요. Jekyll 과 Hugo 를 비교하는 글들이 많은데, 제 이유는 Category 관리가 Hugo 가 좀 더 직관적이여서 예요.\nHugo 를 설치하고 Learn Theme 를 적용하는 방법을 살펴볼게요. 또 Disqus 댓글, 검색어 노출을 위해 Google Analystics, Google Search, 네이버 웹마스터와 연동하는 방법, 초안(Draft) 작성을 위한 설정 등을 살펴 볼게요.\nEnvironment \u0026amp; Requirement  Hugo Static Site Generator v0.57.2 Mac Git  Quick Start Install Mac 에서 Hugo Install Doc 따라서 설치는 쉽게 진행 가능해요.\n Mac이 아닐경우 Hugo Install\n brew install hugo hugo version  Directory Structure\n. ├── archetypes ├── config.toml ├── content ├── data ├── layouts ├── static └── themes  몇 개만 살펴보면 content 작성한 글, layouts Custom html 파일, static 는 css, image 등이 저장되요.\n웹사이트 생성 # Site 생성 hugo new site \u0026lt;site directory\u0026gt; # Website server 실행 cd \u0026lt;site directory\u0026gt; hugo server -D   Hugo의 CLI 명령어는 웹사이트의 Root \u0026lt;site directory\u0026gt; 에서 수행해 주세요. 어떠한 명령어들은 Root 디렉토리가 아닐경우 정상 동작하지 않아요.\n 설정, config.toml baseURL = \u0026quot;https://hahafamilia.github.io/\u0026quot; languageCode = \u0026quot;ko-kr\u0026quot; title = \u0026quot;haha family's happy blog\u0026quot; theme = \u0026quot;learn\u0026quot;  글 작성 컨텐츠 추가\nhugo new content/posts/my-first-post.md   hugo new 명령어로 생성되는 파일은 archetypes/default.md 파일에 템플릿화 되어 있어요.\n 글은 최상단에 Front Matter 를 추가하고 Markdown 으로 써 내려 가요.\nTheme, hugo-theme-learn Hugo Theme 다양한 테마가 존재하네요. Jekyll 에 비해 조금 부족한 듯 보이긴 해요.\nGithub Hugo Theme Stars hugo-academic 테마가 압도적으로 많이 사용되고 있네요. 전 hugo-theme-learn 테마를 사용하도록 하겠습니다. 아무래도 개발 관련 포스트 들이 주이기에 조금 올드한 트리구조의 메뉴가 편할 것 같거든요.\nGit submodule 로 등록하는 것을 추천합니다. 테마는 언제든지 바뀔 수 있고, 업데이트 될 수 있으니까요.\n테마추가\ncd \u0026lt;site directory\u0026gt; git init git submodule add https://github.com/matcornic/hugo-theme-learn.git themes/learn # themes/ 디렉토리 이하 테마 디렉토리 명 echo 'theme = \u0026quot;learn\u0026quot;' \u0026gt;\u0026gt; config.toml   이후 부터는 hugo-theme-learn 에서 재공하는 shortcode 나 설정들에 따라 테마 종속적인 것들이 있어요. 그리 많지는 않으니 다른 테마를 사용해도 많이 달라지지는 않아요.\n 메뉴 hugo-heme-learn 테마는 content 디렉토리 이하의 디렉토리, .md 파일을 자동으로 좌측 메뉴에 트리 구조로 표시해줘요.\ncontent 디렉토리 포함하여, 하나의 디렉토리 마다 _index.md 파일을 작성해 주세요. 디렉토리 이하의 _index.md 메뉴에서 디렉토리 클릭시 표시되는 페이지 예요.\n디렉토리 index 페이지에서 이하의 포스트들을 나열하고 싶으면 children shortcode 를 사용해 보세요.\n좌측 메뉴에 카테고리 이하 글들을 노출하고 싶지 않으면 hidden Front Matter 필드를 사용해 보세요.\n메뉴에 별도의 Link 를 연결하길 원할 경우(Git 주소등) config.toml 파일에 menu.shortcuts 을 사용하면되요.\n# config.toml [[menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-tags'\u0026gt;\u0026lt;/i\u0026gt; Tags\u0026quot; url = \u0026quot;/tags\u0026quot;  favicon static/images/favicon.png 파일명으로 저장\nlogo layouts/partials/logo.html 편집\n\u0026lt;a id=\u0026quot;logo\u0026quot; href=\u0026quot;{{ .Site.BaseURL }}\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/logo.png\u0026quot; alt=\u0026quot;logo.png\u0026quot;\u0026gt; \u0026lt;/a\u0026gt;  Menu Footer layouts/partials/menu-footer.html 편집\n themes/layouts/partials 디렉토리를 보시면 이 외에도 설정 가능한 html 들이 있어요. themes 디렉토리에서 설정하지 마시고, website 루트 디렉토리에서 설정해야 관리가 편해요.\n Font Hugo 에서 font-familiy 를 변경할 수 있는 설정은 없어요. 엄밀히 말하면 있긴 해요. 각 테마에서 Style 편집을 해주는 게 손쉬운 방법 이에요. hugo-theme-learn Custom Style 문서에 Custom Style 설정 방법이 나와있어요.\nstatic/css/theme-custom.css 파일을 생성하고 기본 Style 값을 복사 해주세요.\n[params] themeVariant = \u0026quot;custom\u0026quot;   파일명의 theme- 는 고정이고, custom 은 변수명 처럼 사용가능해요.\n font-family 변경은 더 좋은 방법이 있을 것으로 보이지만, 우선 포스트 영역만 변경 했어요.\n@import url('https://fonts.googleapis.com/css?family=Inconsolata:400,700\u0026amp;display=swap'); body { font-family: 'Inconsolata', monospace; } code { font-family: 'Inconsolata', monospace; }   더 상세히 Style 조정을 하려면, themes/learn//static/css/ 디렉토리를 확인해 보세요.\n font-size 는 테마에서 rem 단위를 사용하기 때문에 html 요소의 font-size 변경해주세요.\nhtml { font-size: 14px; }  추가기능 Hugo Website 가 hugo-theme-learn 테마를 사용해서 조금 깔끔해 졌네요. 이제 블로그 운영을 위해 필수적으로 필요한 추가 기능들을 적용해 봐요. Disqus, Google Analystics, Google Search, 네이버 웹마스터 의 계정이 필요하고 각 사이트 설정 방법에 대해서는 생략할게요. 연동에 필요한 것들을 구성하는 방법 이예요.\nGoogle Analystics # config.toml googleAnalytics = \u0026quot;\u0026lt;your tracking id\u0026gt;\u0026quot;  layouts/partials/custom-header.thml Google Analystics Internal Template 삽입\n{{ template \u0026quot;_internal/google_analytics.html\u0026quot; . }}  Disqus 댓글 # config.toml disqusShortname = \u0026quot;\u0026lt;disqus shortname\u0026gt;\u0026quot;  Hugo Disqus Docs 에 Disqus 댓글을 조건에 따라 설정하는 방법이 나와있어요. layouts/partials/disqus.html 에 문서에서 제공하는 스크립트를 추가해주세요. 예를 들어 _index.md 파일에서는 Disqus 댓글을 안보이게 할 수도 있겠어요.\nvar logicalName = '{{ .File.LogicalName }}'; if (logicalName == \u0026quot;_index.md\u0026quot;) return;  검색노출 정적 HTML 생성기로 만들어진 블로그는 검색 사이트에 노출되지 않기에 노출될 수 있도록 설정해줘야 되요. Google Search, 네이버 웹마스터 등록에 필요한 것은 robots, sitemap, rss feed 링크에요.\n다른 설정을 하기 전에 우선 config.toml 에 outputs 설정을 해줘야 해요.\n# config.toml [outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;RSS\u0026quot;, \u0026quot;JSON\u0026quot;]  어서오세요. 로봇님. robots.txt\n# config.toml enableRobotsTXT = true  http://localhost:1313/robots.txt\nsitemap.xml\n# config.toml [sitemap] changefreq = \u0026quot;weekly\u0026quot; filename = \u0026quot;sitemap.xml\u0026quot;  http://localhost:1313/sitemap.xml\nRSS Template 여기 를 보면 Hugo 에서 자동으로 RSS 파일을 생성하는데 다양하게 있어요. 모든 컨텐츠를 포함할 수 있도록 최상단의 RSS 를 사용해요.\nhttp://localhost:1313/index.xml\nGithub 호스팅 Github Repository 우선 Github 에 2개의 저장소를 만들어야 합니다. Hugo 프로젝트 소스를 저장할 저장소를 생성하고 Hugo 프로젝트 소스를 업로드 해서 유실에 대비하세요. GitHub Pages 호스팅 방법은 Github Pages 와 Hugo on Github Doc 에 잘 설명되어 있어요.\nHugo on Github Doc 문서를 요약하면\n Hugo Project 리포지토리 생성\n Git Username 리포지토리 생성\n 새로운 디렉토리에 git clone 하라고 하는데 지금까지 작업한 디렉토리에 연동해도 되요.\ncd \u0026lt;site directory\u0026gt; git init git remote add origin \u0026lt;Hugo Project Repository\u0026gt; git add . git commit -m 'first commit' git push -u origin master  public 디렉토리가 있다면 삭제해주세요.\n 루트에서 hugo 명령어를 수행하면 public 디렉토리가 생성되고 정적파일들이 생성되요.\n submodule 로 public 디렉토리를 Github Repository 에 등록\ngit submodule add -b master \u0026lt;Username Repository\u0026gt; public   배포 deploy.sh 쉘을 작성해주세요. depoly.sh 를 실행하면 정적파일을 생성하고 Repository 로 commit 합니다. https://\u0026lt;git username\u0026gt;.github.io 주소가 블로그 주소가 됩니다.\n 포스트를 삭제하거나 카테고리 디렉토리를 삭제해도 hugo 명령어를 통해 정적 파일을 생성할때, public 디렉토리에서 삭제되지 않아요. 이럴때 public 디렉토리를 삭제후 정적 파일을 재생성 해야 하는데요. 이때 public 디렉토리의 .git 파일이 삭제 되지 않도록 하세요.\n 팁, 게시글 초안 Jekyll 에서는 _drafts 디렉토리를 사용해서 작성중인 포스트를 관리 했었는데, Hugo 에서는 Front Matter 의 draft: true 값으로 관리 되요.\n전 Jekyll 의 방식이 더 좋아서 Jekyll 처럼 구성해 봤어요. 간단히 설명드리면 2개의 환경을 구성해서 초안작성 환경에서 초안작성용 Config 파일이 초안이 있는 Content 디렉토리를 바라보게 해서 Hugo Server 실행할 때 초안 환경을 지정해 주는 방식이에요\nHugo Configuration Directory Doc 에 Config 관리 방식이 나와있어요.\n draft/content 초안 작성 디렉토리를 생성해주세요. _index.md 파일도 생성하고 children shortcode 로 작성글도 리스트업 해주세요.\n 지금까지의 설정이 저장된 config.toml파일을 config/_default/config.toml 로 옮겨주세요.\n config/draft/config.toml 빈 파일을 생성하고 contentDir 디렉토리를 초안작업 디렉토리로 설정하세요.\ncontentDir = \u0026quot;draft\u0026quot;  draft 환경으로 hugo 서버를 시작하세요.\nhugo server -e draft   Draft Production 마치며 Jekyll 과 Hugo 를 잠깐씩 써본 경험상 성능의 이슈는 제외하고 Hugo 가 셋팅하기에 아주 약간 수월했어요. Hugo 테마가 좀 적어 아쉽긴 하지만 만족합니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/bigdata/zeppelin-interpreter/",
	"title": "Apache Zeppelin Interpreter, Hive, Impala",
	"tags": ["2019", "zeppelin"],
	"description": "",
	"content": " Apache Zeppelin 과 Cloudera CDH 의 Hive, Impala 를 연동하는 방법을 알아볼게요.\nZeppelin Posts  Zeppelin Install \u0026amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1 Cloudera CDH 6.1.1 Hive 2.1.1 Impala 3.1.0 Impala JDBC Driver 2.6.12  Hive Zeppelin Hive Interpreter Document 문서를 보면 Jdbc Interpreter 를 사용하라고 되어있네요. 기본으로 PostgreSQL Connector 지원하고 그외는 Connector 는 추가를 해줘야 해요.\nMaven Repository Zeppelin 콘솔에서 우측 상단의 메뉴에서 interpreter 메뉴를 클릭하여 Interpreter 설정 화면으로 이동해요. Repository 버튼을 클릭하면 등록되어져 있는 Repository 를 확인 할 수 있어요. 그 옆으로 + 버튼 클릭해서 Cloudera Maven Repository https://repository.cloudera.com/artifactory/cloudera-repos/ 를 추가 해주세요.\nHive Interpreter 추가 Create 버튼을 클릭하여 Interpreter 를 추가 해요. Interpreter Group 은 jdbc 로하고 아래의 Properties, Dependencies 값 조정해 주세요.\nProperties  default.driver : org.apache.hive.jdbc.HiveDriver default.url : jdbc:hive2://\u0026lt;HiveServer2\u0026gt;:10000  Dependencies artifact  org.apache.hive:hive-jdbc:2.1.1-cdh6.1.1 org.apache.hadoop:hadoop-common:3.0.0-cdh6.1.1   CDH 6.1.x Maven Artifacts\n Impala Cloudera 는 Impala JDBC Connector 를 Maven 으로 제공하고 있지 않아요. Zeppelin 설치 경로에 external-lib/impala 디렉토리를 생성하고 Impala JDBC Download 링크를 통해 다운로드 해주세요.\nInterpreter Name 은 impala 로, Interpreter Group 은 jdbc 로 Interpreter 를 생성하고 Properties, Dependencies 값을 조정해 주세요.\nProperties  default.driver : com.cloudera.impala.jdbc41.Driver default.url : jdbc:impala://\u0026lt;ImpalaServer\u0026gt;:21050/scdh;AuthMech=0; \u0026gt; Properties default.user 에 기본값이 들어가 있네요. 저는 삭제 했어요.  Denpendies artifact  /opt/zeppelin/external-lib/impala/ImpalaJDBC41.jar (Download 한 jar 파일의 경로) \u0026gt; AuthMech=0 권한 설정을 하지 않았어요. Impala JDBC 권한 설정은 Impala JDBC Document 문서를 참고해 주세요.  Notebook 잘 연동 되었느지 확인해 볼게요. Note 를 생성하고 Interpreter binding 메뉴에서 impala, hive Interpreter 를 상단으로 올려주세요.\nHive 와 Impala 쿼리가 잘 동작하네요.\nSpark Zeppelin 은 Spark 가 임베디드 되어있는데, 버전 이 2.2.1 이네요. 새로운 버전의 Spark 를 설치하고 /opt/zeppelin/conf/zeppelin-env/sh 파일에서 SPARK_HOME 을 설정해 주시면 되요. Spark Interpreter Doc 문서에 잘 설명되어 있어요.\nexport SPARK_HOME=\u0026lt;스파크설치경로\u0026gt;  "
},
{
	"uri": "https://hahafamilia.github.io/bigdata/zeppelin-usage/",
	"title": "Apache Zeppelin Usage",
	"tags": ["2019", "zeppelin"],
	"description": "",
	"content": " Apache Zeppelin 은 노트북 방식의 시각화 툴이예요.\nZeppelin Posts  Zeppelin Install \u0026amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1  Dynamic Form Zeppelin 에서는 Dynamic Form 을 제공하고 있어서 Form 을 통해 입력받은 값으로 조건을 주는 형태로 사용 가능해요. Dynamic Form 은 Paragraph scope 와 Note scope 에서 사용 문법의 차이가 있고, 또한 Programmatically 하게 추가하실 수 있어요. 예제에서는 text, select, checkbox 를 소개하고 있네요.\nParagraph scope Text input form ${formName=defaultValue} 의 형태예요.\n%md Hello ${name} %md Hello ${name=Michelle}  Select form ${formName=defaultVallue,option1(displayName)|option2(displayName)|...} 의 형태예요\n%md This is ${day=mon,mon|tue|wed|thu|fri|sat|sun} %md This is ${day=mon,1(mon)|2(tue)|3(wed)|4(thu)|5(fri)|6(sat)|7(sun)}  Checkbox form {checkbox(delimiter):formName=defaultValue1|defaultValue2...,option1|option2...} 의 형태에요. 구분자 delemiter 의 기본값은 , 이고, 지정 할 수 있어요.\n%md select ${checkbox:fields=name|age,name|age|salary|gender} from employees # name, age %md select ${checkbox( and ):fruit=apple|banana,apple|orange|banana} from employees # name and age  Note scope Paragraph 에서와 사용법은 동일하고 $$ 로 시작해요.\nParagraph scope, Programmatically Text input form z.textbox(String formName, String defaultValue) 의 형태예요. textbox 대신에 input 을 사용 할 수 있어요.\n%spark println(\u0026quot;Hello\u0026quot;, + z.textbox(\u0026quot;name\u0026quot;, \u0026quot;Michelle\u0026quot;)) println(\u0026quot;Hello\u0026quot;, + z.input(\u0026quot;name\u0026quot;))  Select form z.select(String formName, Seq((String option, String displayName), ...)) 형태예요.\n%spark println(\u0026quot;Hello \u0026quot;+z.select(\u0026quot;day\u0026quot;, Seq((\u0026quot;1\u0026quot;,\u0026quot;mon\u0026quot;), (\u0026quot;2\u0026quot;,\u0026quot;tue\u0026quot;), (\u0026quot;3\u0026quot;,\u0026quot;wed\u0026quot;), (\u0026quot;4\u0026quot;,\u0026quot;thurs\u0026quot;), (\u0026quot;5\u0026quot;,\u0026quot;fri\u0026quot;), (\u0026quot;6\u0026quot;,\u0026quot;sat\u0026quot;), (\u0026quot;7\u0026quot;,\u0026quot;sun\u0026quot;))))  Checkbox form z.checkbox(String formName, Seq((String option, String displayName), ...)).mkString(String delimiter) 형태예요.\n%spark val options = Seq((\u0026quot;apple\u0026quot;,\u0026quot;Apple\u0026quot;), (\u0026quot;banana\u0026quot;,\u0026quot;Banana\u0026quot;), (\u0026quot;orange\u0026quot;,\u0026quot;Orange\u0026quot;)) println(\u0026quot;Hello \u0026quot;+z.checkbox(\u0026quot;fruit\u0026quot;, options).mkString(\u0026quot; and \u0026quot;))  Note scope, Programmatically Note scope 에서는 noteTextbox, noteSelect, noteCheckbox 로 사용해요.\nDisplay System Zeppelin 은 Display System 이 있는데, Text Display System 을 기본 값으로 HTML, Table, Network, Angular Display System 을 통해서 결과를 출력할 수 있어요. %displaySystemName 의 형태로 Display System 을 명시 하여 사용해요.\nText # 기본값으로 Text Display System 을 사용 %sh echo \u0026quot;Hello Zeppelin\u0026quot; # Text Display System 명시 %sh echo \u0026quot;%text Hello Zeppelin\u0026quot;  HTML %sh echo \u0026quot;%html \u0026lt;h3\u0026gt;Hello Zeppelin\u0026lt;/h3\u0026gt;\u0026quot;  Methematical expressions MathJax\nTable \\t 으로 칼럼을 구분하고, \\n 으로 행을 구분해줘요.\n%sh echo -e \u0026quot;%table name\\tsize\\nsun\\t100\\nmoon\\t10\u0026quot;  Table 의 내용이 %html 일 경우 HTML Display System 을 사용해요.\n%sh echo -e \u0026quot;%table name\\tsize %html \u0026lt;img src='http://...sun.png'/\u0026gt;sun\\t100 %html \u0026lt;img src='http://...moon.png'/\u0026gt; moon\\t10\u0026quot;  Network %network Display System 은 Graph 로 처리되요. \u0026gt; Graph 는 연관된 객체들의 집합, Vertex, Edge 를 가집니다.\n%spark print(s\u0026quot;\u0026quot;\u0026quot; %network { \u0026quot;nodes\u0026quot;: [{\u0026quot;id\u0026quot;: 1, \u0026quot;label\u0026quot;: \u0026quot;User\u0026quot;, \u0026quot;data\u0026quot;: {\u0026quot;fullName\u0026quot;:\u0026quot;Andrea Santurbano\u0026quot;}},{\u0026quot;id\u0026quot;: 2, \u0026quot;label\u0026quot;: \u0026quot;User\u0026quot;, \u0026quot;data\u0026quot;: {\u0026quot;fullName\u0026quot;:\u0026quot;Lee Moon Soo\u0026quot;}},{\u0026quot;id\u0026quot;: 3, \u0026quot;label\u0026quot;: \u0026quot;Project\u0026quot;, \u0026quot;data\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;Zeppelin\u0026quot;}}], \u0026quot;edges\u0026quot;: [{\u0026quot;source\u0026quot;: 2, \u0026quot;target\u0026quot;: 1, \u0026quot;id\u0026quot; : 1, \u0026quot;label\u0026quot;: \u0026quot;HELPS\u0026quot;},{\u0026quot;source\u0026quot;: 2, \u0026quot;target\u0026quot;: 3, \u0026quot;id\u0026quot; : 2, \u0026quot;label\u0026quot;: \u0026quot;CREATE\u0026quot;},{\u0026quot;source\u0026quot;: 1, \u0026quot;target\u0026quot;: 3, \u0026quot;id\u0026quot; : 3, \u0026quot;label\u0026quot;: \u0026quot;CONTRIBUTE_TO\u0026quot;, \u0026quot;data\u0026quot;: {\u0026quot;oldPR\u0026quot;: \u0026quot;https://github.com/apache/zeppelin/pull/1582\u0026quot;}}], \u0026quot;labels\u0026quot;: {\u0026quot;User\u0026quot;: \u0026quot;#8BC34A\u0026quot;, \u0026quot;Project\u0026quot;: \u0026quot;#3071A9\u0026quot;}, \u0026quot;directed\u0026quot;: true, \u0026quot;types\u0026quot;: [\u0026quot;HELPS\u0026quot;, \u0026quot;CREATE\u0026quot;, \u0026quot;CONTRIBUTE_TO\u0026quot;] } \u0026quot;\u0026quot;\u0026quot;)  Angular Zeppelin 과 AngularJS 사이의 게이트웨이를 제공해요. Backend / Frontend API 제공합니다.\n마치며 Zepplin 대시보드 만들기 라는 유튜브 동영상 이예요. Zeppelin 프로젝트 참여자이신 것 같네요.\n"
},
{
	"uri": "https://hahafamilia.github.io/bigdata/zeppelin-quickstart/",
	"title": "Apache Zeppelin 설치, QuickStart",
	"tags": ["2019", "zeppelin"],
	"description": "",
	"content": " Apache Zeppelin 은 노트북 방식의 시각화 툴이예요. 다양한 시각화 툴이 존재하지만 \u0026lsquo;가장 좋은 것\u0026rsquo;이 아니라 \u0026lsquo;나에게 맞는 것\u0026rsquo; 을 선택했어요. 제가 Zeppelin을 선택한 이유는 아래와 같아요.\n 설치와 사용법이 쉬워야 한다. 요구사항을 유연하게 처리 할 수 있어야 한다. BI 웹 어드민을 개발 하지 않아도 되도록 정적 HTML 을 제공해야 한다.  Zeppelin Posts  Zeppelin Install \u0026amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1  Zeppelin 와우! Zeppelin~ 아파치 오픈 소스 프로젝트에 채택된 국내 프로젝트네요. 공식 문서를 보고 Quick Start 부터 진행 해볼게요.\nInstall Oracle JDK 1.7 를 필요로 하네요. 그리고 JAVA_HOME 이 필요하다고 하네요. 제가 사용중인 클러스터는 Cloudera CDH 6.1.x 으로 Oracle JDK 1.8 라이센스를 보유하고 있어서, JDK 1.8 환경에서 설치 진행해요. \u0026gt; Oracle JDK 1.8 이 상용화 되어서 사용하지 못하는게 아닐까요? 오픈소스에서 사용시 무료 라이센스 주면 안되나\u0026hellip; Oracle\u0026hellip;\n JAVA_HOME 설정은 readlink -f $(which java) 의 경로를 /etc/profile 파일에 export 명령문으로 저장해주시면 되요. source /etc/profile 해주셔야 현재의 터미널에 반영됩니다.\n 두 가지 버전의 Download 를 제공하고 있네요. all interpreter 버전으로 다운로드 진행 했어요. 제 설치 경로는 /opt 이예요.\n# 사용자 추가 useradd -s /sbin/nologin zeppelin # 설치 디렉토리 cd /opt tar -xvf zeppelin-0.8.1-bin-all.tgz # 권한, 링크 chown -R zeppelin:zeppelin zeppelin-0.8.1-bin-all ln -s zeppelin-0.8.1-bin-all zeppelin chown -h zeppelin:zeppelin zeppelin  Zeppelin 설치하였으니 /opt/zeppelin/bin/zeppelin-daemon.sh start 시작 명령어로 실행시시켜 볼게요. http://localhost:8080 접속하시면 시작화면을 보실 수 있어요. Stop 시켜주시고, 서비스 등록을 할게요.\nService 등록 /usr/lib/systemd/system/zeppelin.service 파일을 생성해 주시고, 아래의 내용을 작성해 주세요.\n# CentOS 7 [Unit] Description=Zeppelin Service After=syslog.target network.target [Service] Type=forking User=zeppelin Group=zeppelin Restart=always Environment=\u0026quot;JAVA_HOME=\u0026lt;java home path\u0026gt;\u0026quot; WorkingDirectory=/opt/zeppelin ExecStart=/opt/zeppelin/bin/zeppelin-daemon.sh start ExecStop=/opt/zeppelin/bin/zeppelin-daemon.sh stop ExecReload=/opt/zeppelin/bin/zeppelin-daemon.sh reload [Install] WantedBy=multi-user.target  zeppelin.service 파일을 작성했으면, systemctl daemon-reload 명령어로 반영시켜준후, 서비스 enable 시켜 주세요.\nsystemctl enable zeppelin systemctl start zeppelin  Account Zeppelin 에 접속해 보면 anonymous 익명 사용자로 접속 되는데요. 익명 사용자 접근을 제한하고 계정을 생성해 볼게요.\nDisable Anonymous Access cd /opt/zeppelin cp conf/zeppelin-site.xml.template conf/zeppelin-site.xml vi zeppelin-site.xml  \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;zeppelin.anonymous.allowed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;false\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;zeppelin.notebook.public\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;false\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;zeppelin.notebook.default.owner.username\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;admin\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt;  Enable Shiro Authentication cd /opt/zeppelin cp conf/shiro.ini.template conf/shiro.ini vi shiro.ini  [users] admin = password1234, admin user1 = password1234, role1, role2 # user2 = password3, role3 # user3 = password4, role2  Explore UI Explore UI 섹션에는 Layout, Menu, Notebook, Paragraph 에 관한 UI 사용법이 있네요.\nTutorial Tutorial 에서는 LocalFile 을 사용하는 예제와 Twitter Stream 데이터를 사용하는 예제가 있어요.\n샘플데이터 bank.zip 을 다운로드해서 간단히 따라해 볼 수 있어요. \u0026gt; Zeppelin 에서 Spark Interpreter 가 기본 값이어서 샘플 코드에 Interperter 지정을 안해주고 있어요. 만약 예제가 동작하지 않는다면 RDD 생성 코드에 %spark Interpreter 를 지정해 주세요.\n마치며 다음 포스트에 계속해서 Usage 문서에 대해서 알아 볼게요.\n여기 에 Zeppelin 설치에 관해서 잘 정리되어져 있네요.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/hue/",
	"title": "hue",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/monitoring/",
	"title": "monitoring",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/oozie/",
	"title": "oozie",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/oozie-workflow-email/",
	"title": "Oozie Workflow Email 알림 설정",
	"tags": ["2019", "oozie", "monitoring", "hue"],
	"description": "",
	"content": " Oozie 에서 Workflow 의 결과에 따른 Email 알림을 받는 방법에 대해서 알아볼게요.\nWorkflow 를 1회성으로 실행시키는 경우와 Schedule 로 등록하여 주기적으로 실행하는 경우가 있을 수 있을텐데요. 1회성으로 Workflow 만 실행할때는 성공/실패에 대한 처리 결과를 받도록 하고, Schedule 로 등록하여 주기적으로 실행하는 경우에는 실패에 대한 알림 만을 받도록 합니다.\nVersion  Cloudera 6.1.1 Oozie 5.0.0 Hue 4.3.0  Oozie SMTP 설정 Cloudera Manager \u0026gt; Oozie \u0026gt; 구성 탭 에서 mail 을 검색해서, oozie.email.smtp.host, oozie.email.from.address 설정에 SMTP 의 도메인과 발신인 메일 주소를 설정해주세요. Oozie, Hue 서비스의 재시작이 필요합니다.\n 아쉽게도 Oozie 5.0.0 버전에서는 SSL 설정을 할 수 없네요. JIRA OOZIE-1393 를 확인해 보니 5.1.0 버전부터 Fixed 되었습니다.\n Workflow 처리 결과 알림 Oozie 서비스에 Mail 설정이 되어 있다면 Workflow 를 제출 할 때 처리 결과에 Email 받기 체크박스를 확인 할 수 있어요. 체크 해줌으로써 간단히 Mail 수신이 가능해요.\nWorkflow 실패시 알림 Hue Workflow Editor 에서 신규 Workflow 를 작성하는 레이아웃 이예요. 종료 Action을 지정하는 Action에서(맨 마지막의 네모모양 레이어의 톱니바퀴 버튼) 실패에 대한 메일 알림 설정을 할 수 있습니다.\n수신 대상 Mail 주소를 , 구분자로 넣어주세요. 제목과 내용에 EL Function 을 사용할 수 있어요. ${wf:name()} 는 Workflow 의 이름, ${wf:errofMessage(wf:lastErrorNode())} 는 실패 액션의 오류 원인 이예요.\n특정 Action 의 결과 알림 만약 특정 Action 의 처리 결과에 대한 알림을 받고 싶을 경우, Email Action 을 사용 해야 해요. Hue Workflow Editor 에서 선행 Action 의 수행후 전환 설정에서 KO 시에 Kill 이 아닌 Email Aciton 으로 전환 하게되면 Mail 을 수신할 수 있습니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/avroflumeevent/",
	"title": "AvroFlumeEvent",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/spring-kafka-flume/",
	"title": "AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집",
	"tags": ["2019", "flume", "AvroFlumeEvent"],
	"description": "",
	"content": "다음과 같은 데이터 파이프 라인을 가정해 볼게요.\n 사용자의 Activity 이벤트가 발생 API 서버를 통해 Kafka 에 Produce Flume 을 통해 Kafka 의 메시지를 HDFS 로 적재 HDFS 에는 일자 별로 생성된 디렉토리에 저장  Flume 을 퉁한 데이터 수집시에 Hdfs Sink 는 useLocalTimestamp 설정은 제공 해요. 하지만 이 설정은 이벤트의 수집 시각을 기준으로 해요.\n예제 그림에서 API 에서 시작된 데이터는 파이프라인을 거쳐 HDFS 에 도달하기까지 2초의 시간이 소요된다고 가정하면, 2019-08-01 23:59:59 시각에 발생한 이벤트는 useLocalTimestamp 설정에 의해 2019-08-02 00:00:01 의 시각으로 2019-08-02 디렉토리에 적재됩니다.\n데이터 수집 파이프라인에서 이벤트의 발생시각에 따른 수집이 필요한데요. Flumg NG 라이브러리는 AvroFlumeEvent 클래스를 제공 해요.\nKafka 에 저장하는 이벤트 메시지에 Flume Ng 의 헤더 데이터로 Timestamp 추가하고, Flume 에서 이 헤더의 Timestamp 값으로 데이터를 저장하면 되요. AvroFlumeEvent 는 Header 를 추가할 수 있게 해주는 클래스 라고 보시면 되요.\npublic void send(String topic, ActivityEvent message) throws IOException { Optional\u0026lt;Long\u0026gt; optionalTs = Optional.ofNullable(message.getActivityTime()); long ts = optionalTs.orElse(Instant.now().toEpochMilli()); // Flume message header Map\u0026lt;CharSequence, CharSequence\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); headers.put(\u0026quot;timestamp\u0026quot;, Long.toString(ts)); // Avro message bytes byte[] bytes = ActivityEvent.serializeByte(message); // Attatch flume message header with avro message. bytes = packFlumeMessage(headers, bytes); // 카프카 레코드 작성 ProducerRecord\u0026lt;Long, byte[]\u0026gt; record = new ProducerRecord\u0026lt;\u0026gt;(topic, ts, bytes); // 카프카 전송 ListenableFuture\u0026lt;SendResult\u0026gt; future = kafkaTemplate.send(record); future.addCallback(new ListenableFutureCallback\u0026lt;SendResult\u0026gt;() { @Override public void onFailure(Throwable e) { log.warn(\u0026quot;failed after send to kafka: exception={}, record={}\u0026quot;, e.getMessage(), message, e); } @Override public void onSuccess(SendResult sendResult) { log.info(\u0026quot;success after send to kafka: record={}\u0026quot;, message); } }); } /** * Kafka 전송 메시지에 Flume 의 헤더 값을 추가합니다. * eventTime 을 Flume 에 추가하기 위함입니다. * Flume 은 수집시간이 아닌 이벤트 발생시간 기준으로 파티션되어 저장합니다. * @param headers \u0026quot;timestamp\u0026quot; 밀리초, String * @param message * @return * @throws IOException */ private byte[] packFlumeMessage(Map\u0026lt;CharSequence, CharSequence\u0026gt; headers, byte[] message) throws IOException { AvroFlumeEvent avroFlumeEvent = new AvroFlumeEvent(headers, ByteBuffer.wrap(message)); ByteArrayOutputStream out = new ByteArrayOutputStream(); BinaryEncoder encoder = EncoderFactory.get().directBinaryEncoder(out, null); SpecificDatumWriter\u0026lt;AvroFlumeEvent\u0026gt; writer = new SpecificDatumWriter\u0026lt;\u0026gt;(AvroFlumeEvent.class); writer.write(avroFlumeEvent, encoder); encoder.flush(); return out.toByteArray(); }  보셔야 할 코드는 send 함수의 packFlumeMessage 함수 호출 부분 이예요. Kafka 에 메시지를 byte 로 저장하고 packFlumeMessage 함수에서 Timestamp 헤더를 추가하고 있어요.\n// Attatch flume message header with avro message. bytes = packFlumeMessage(headers, bytes);  전체 예제 소스는 Github 를 통해서 보실 수 있어요. 코드에는 Avro 데이터 처리는 Jackson 을 사용하고 있어요. 테스트는 EmbeddedKafka 테스트와 CloudKafka 테스트 가 있습니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/bigdata/cloudera-alert-email/",
	"title": "Cloudera Manager 알람 설정, Gmail SMPT 서버 사용",
	"tags": ["2019", "cloudera-manager-alert", "monitoring"],
	"description": "",
	"content": " Cloudera Manager 알림을 보내는 방법은 SMTP, SNMP, Custom Script 세가지를 제공하고 있어요. 여기서 SNMP, Custom Script 는 Enterprise 버전에서만 지원해요. 별도의 SMTP 서버를 운영하고 있지 않다면 Gmail 을 이용할 수 있어요.\nCloudera Version Cloudera 6.1\nGmail 설정 우선 Gmail 설정에서 IMAP 사용이 허용되어야 해요. 그리고 Google 계정 설정 \u0026gt; 보안 \u0026gt; 보안 수준이 낮은 앱의 액세스 가 허용되어야 합니다.\n 이 방법은 보안상 권장하지 않는 방법 이예요. 하지만 제가 근무하는 회사의 G Suite 에서는 액세스키에 의한 접근 기능이 제공되고 있지 안아서 이 방법을 사용하고 있어요.\n Cloudera Alert Publisher Mail 환경설정 Email 구성 문서 문서를 참조해서 간단하게 구성이 가능 합니다.\nCloudera Manager Service \u0026gt; Configuration \u0026gt; Filter(Alert Pulisher \u0026amp; Main) 에서 설정이 가능해요. 아래의 항목들을 변경해요.\n 메일 서버 프로토콜 : smtps 메일 서버 호스트 이름 : smtp.gmail.com 메일 서버 사용자 이름 : 보내는 메일 주소 메일 서버 암호 : 보내는 메일 주소의 로그인 비밀번호 보낸 사람 주소 : 받는 사람 주소 :   Cloudera Manager 의 상단 메뉴의 관리 메뉴에서 테스트 알림 전송 기능을 제공하고 있어요.\n Alert, Trigger 설정 어떤 알림을 받을 수 있을까요? Cloudera 의 경고 관리 문서 를 보면 클러서터의 상태/로그/활동에 대한 경고들이 설정되어 있다고 합니다. Cloudera Manager \u0026gt; 관리 \u0026gt; 알림 메뉴에 알림 항목들이 설정되어 있어요. 편집 버튼을 통해 각 서비스의 구성 에서 설정을 변경 할 수 있습니다.\nTrigger 원하는 조건에 해당하는 알림을 받고 싶으면 Trigger 를 구성할 수 있어요. 트리거는 클러스터의 각 서비스의 관리 페이지에 트리거 생성 버튼을 통해서 만들수 있습니다.\n트리거 문서 를 보면 Trigger 는 이름/표현/임계값/활성화여부 로 구성되요. Trigger 표현은 아래처럼 조건과 액션으로 작성합니다.\nIF (CONDITIONS) DO HEALTH_ACTION  IF ((SELECT fd_open WHERE roleType=DataNode AND last(fd_open) \u0026gt; 500) OR (SELECT fd_open WHERE roleType=NameNode AND last(fd_open) \u0026gt; 500)) DO health:bad  "
},
{
	"uri": "https://hahafamilia.github.io/tags/cloudera-manager-alert/",
	"title": "cloudera-manager-alert",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/flume/",
	"title": "flume",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/python/",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/python/python-pyenv-anaconda-mac/",
	"title": "Python 개발환경, Pyenv, Anaconda3",
	"tags": ["python"],
	"description": "",
	"content": " Mac 에서 Homebrew 통해서 Python 가상화 환경을 구성하려고 합니다. 우선 Mac 버전이 모하비라면 모하비 brew error 글을 한번 읽어보세요.\nPython 가상환경 구성방법은 여러가지가 있지만, pyenv/virtualenv 를 사용할거예요. 대략적인 과정은 pyenv 설치, anaconda3 설치, 가상환경 구성의 순서예요. pyenv 는 가상화 관리를 위해서 pyenv-virtual 패키지를 사용하는데, anaconda3 정도만 사요할 예정이면 설치 하지 않아요 되요.\npyenv brew help brew update brew install pyenv pyenv -v pyenv 1.2.13 pyenv install -list | grep anaconda ... pyenv install anaconda3-2019.03 coffee time... pyenv versions * system.... anaconda3-2019.03 pyenv activate anaconda3-2019.03 pyenv deactivate conda update conda # zshell ~/.zshrc # bash ~/.bashrc eval \u0026quot;$(pyenv init -)\u0026quot; source ~/.zshrc   zshell 만 그런진 모르겠지만, PATH 설정은 안해줘도 pyenv 명령어 사용이 가능했어요. anaconda3 설치후 conda 명령어는 사용이 불가능 했어요. activate 로 가상환경 들어갔다나오니 사용 가능해지더라고요.\n default Python 만약 특정 버전만 사용 하고, 가상화 activate 가 귀찮다면, default python(2.7) 을 변경 시킬 수 있어요.\npyenv global anaconda3-2019.03 python -V python versions  pyenv-virtualenv brew install pyenv-virtualenv pyenv virtualenv \u0026lt;인터프리터명\u0026gt; \u0026lt;가상화명\u0026gt; pyenv versions pyenv virtualenvs pyenv activate \u0026lt;가상화명\u0026gt; pyenv deactivate # anaconda3 pyenv virtualenv anaconda3-2019.03 conda3 conda activate conda3 which python conda deactivate # zshell ~/.zshrc # bash ~/.bashrc eval \u0026quot;$(pyenv virtualenv-init -)\u0026quot; source ~/.zshrc   anaconda3 를 사용할경우 pyenv activate conda3 이렇게 사용이 안되요.\n uninstall  pyenv uninstall anaconda3-2019.03 pyenv uninstall conda3  pyenv 가상환경 구성 방법, 그 외의 방법들까지 상세 하게 정리 해놓으신 블로그 입니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/bigdata/hive-java-udf/",
	"title": "Hive Java UDF, 유니코드",
	"tags": ["2019", "hive-udf", "unicode"],
	"description": "",
	"content": " 개요 Cloudera Document 6.1 Hive UDF 문서를 참고하여 Cloudera CDH 플랫폼에서 HIVE UDF 를 작성하는 방법을 알아봅니다.\n또한 MySQL의 Collate 와 문자열 유니코드에 대해서도 간단히 알아보겠습니다.\n저의 이번 경우는 HIVE로 집계된 데이터를 SQOOP으로 export 시에 오류가 발생하였습니다.\n기존에 설계된 MySQL 디비의 테이블 칼럼 Collate 속성이 utf8-general-ci 로 설계되어 있어 Key 칼럼에 Accent 문자열을 포함하는 문자열 데이터 자정시에 상황에 따라 키중복이 발생했던 것이었습니다.\n칼럼의 Collate 속성이 utf8-general-ci 일경우 아래와 같은 경우 ã 문자열은 저장이 되겠지만 a 문자열 저장시 Key 중복 오류가 발생합니다.\ninsert into test(word) values ('ã'); insert into test(word) values ('a');  왜 그럴까요? Collate 는 문자열 정렬에 관련한 속성으로 값의 비교정책입니다. utf-general-ci 는 대소문자, 악센트 문자등을 같은 값으로 비교판단합니다. 그렇기 때문에 ã 문자는 a 취급되고 키중복이 발생합니다.\n제 경우에 테이블의 변경할 수 없는 상황으로 HIVE 쿼리 수행시에 악센트 문자열을 제거 하는 작업을 수행했습니다.\nUDF JAR Maven 에 HIVE dependency를 추가합니다. \u0026gt; 묶여진 Jar 파일은 모든 디펜던시를 포함하고 있어야 하는데요. Uber Jar 로의 빌드가 필요합니다. maven-shade-plugin 을 사용합니다.\n\u0026lt;dependency\u0026gt; \u0026lt;groupid\u0026gt;org.apache.hive\u0026lt;/groupid\u0026gt; \u0026lt;artifactId\u0026gt;hive-exec\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  NaverD2 한글인코딩 에 잘 설명되어 있어 있어 많은 참고가 되었습니다. 우선 악센트를 포함하는 문자열을 정준분해(NFD) 한후 정규식을 통해 캐릭터를 치환한후 다시 정준결합(NFC) 하는 HIVE UDF 함수를 작성합니다. 각 이라는 문자열을 정준분해 분해 할경우 ㄱㅏㄱ 이 됩니다.\nstring = Normalizer.normalize(string, Normalizer.Form.NFD); string = string.replaceAll(\u0026quot;\\\\p{InCombiningDiacriticalMarks}+\u0026quot;,\u0026quot;\u0026quot;); string = Normalizer.normalize(string, Normalizer.Form.NFC);  package bigdata.hive.udf; import lombok.extern.slf4j.Slf4j; import org.apache.hadoop.hive.ql.exec.Description; import org.apache.hadoop.hive.ql.exec.UDFArgumentException; import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException; import org.apache.hadoop.hive.ql.metadata.HiveException; import org.apache.hadoop.hive.ql.udf.generic.GenericUDF; import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector; import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory; import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector; import java.text.Normalizer; @Slf4j @Description( name=\u0026quot;str_normal\u0026quot;, value=\u0026quot;remove special character. ex) accent\u0026quot;, extended=\u0026quot;step1. Normalizer.Form.NFD\u0026quot; + \u0026quot;step2. replaceAll regular InCombiningDiacriticalMarks\u0026quot; + \u0026quot;step3. Normalizer.Form.NFC\u0026quot; ) public final class StringNormalize extends GenericUDF { StringObjectInspector stringOI; @Override public ObjectInspector initialize(ObjectInspector[] objectInspectors) throws UDFArgumentException { if (objectInspectors.length != 1) { throw new UDFArgumentLengthException(\u0026quot;required string argument.\u0026quot;); } ObjectInspector objectInspector = objectInspectors[0]; if (false == objectInspector instanceof StringObjectInspector) { throw new UDFArgumentException(String.format( \u0026quot;argument must be a string. class=%s\u0026quot;, objectInspector.getClass())); } this.stringOI = (StringObjectInspector) objectInspector; return PrimitiveObjectInspectorFactory.javaStringObjectInspector; } @Override public Object evaluate(DeferredObject[] deferredObjects) throws HiveException{ DeferredObject deferredObject = deferredObjects[0]; String string = this.stringOI.getPrimitiveJavaObject(deferredObject.get()); if (string == null || string == \u0026quot;\u0026quot;) { return string; } string = Normalizer.normalize(string, Normalizer.Form.NFD); string = string.replaceAll(\u0026quot;\\\\p{InCombiningDiacriticalMarks}+\u0026quot;,\u0026quot;\u0026quot;); string = Normalizer.normalize(string, Normalizer.Form.NFC); return string; } @Override public String getDisplayString(String[] strings) { return \u0026quot;String normalize. \u0026quot;; } }  Hive UDF Jar 파일을 HADOOP 파일시스템 hdfs:///app/hive-udf/hive-udf.jar 경로에 복사합니다. 또한 HIVE SERVER2 를 서비스 하고 있는 호스트의 로컬 파일 시스템에도 /usr/local/bigdata/hive-udf/hive-udf.jar 저장합니다. \u0026gt; 빌드된 jar 파일은 HADOOP과 HIVE SERVER2의 서버에 모두 등록되어이 있어야 합니다.\nHIVE 서비스가 Jar 를 classpath 에 등록하기 위해서는 아래의 설정값을 변경해 주어야 합니다. 설정값을 변경 한후 HIVE 구성파일을 재배포 하고 서비스를 재시작 합니다. \u0026gt; reloadable 속성을 정의 할경우 추후 Jar 파일이 변경될 경우 reload; 명령어를 사용할 수 있습니다.\nCloudera Manager \u0026gt; Hive \u0026gt; Configuration \u0026gt; Filter : Hive Serivce-Wide Advanced \u0026gt; Hive Service Advanced Configuration Snipped(Safety Valve) for hive-site.xml Click(+)\nName : hive.reloadable.aux.jars.path Value : /usr/local/bigdata/hive-udf  beeline 혹은 hue 의 HIVE Editor 에서 함수를 등록 합니다.\ncreate function str_normal as 'bigdata.hive.udf.StrignNormalize' using jar 'hdfs:///app/hive-udf/hive-udf.jar'; describe function extended str_normal; show functions; select str_normal('ã')); --- result a  UDF 함수 업데이트 먼저 HIVE UDF 함수를 제거합니다.\ndrop function if exists str_normal;  HADOOP 과 HIVESERVER2 의 Jar 파일을 업데이트 한 후 beeline 혹은 Hue 에서 reload; 명령어를 수행합니다.\n HUE Editor 에서 SQL을 작성하실 때 HIVESERVER2 의 호스트 서버에 Jar 파일을 등록하지 않고 진행 않아도 UDF 를 사용할 수 있습니다. 하지만 이럴경우 Oozie Workflow 를 실행하거나 Schedule 로 등록시 UDF 함수를 찾을 수 없다는 오류가 발생합니다.\n "
},
{
	"uri": "https://hahafamilia.github.io/tags/hive-udf/",
	"title": "hive-udf",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/unicode/",
	"title": "unicode",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/bigdata/kafka-broker-reinstall/",
	"title": "Kafka Broker 디스크 증설, RAID구성, OS 재설치",
	"tags": ["2019", "kafka"],
	"description": "",
	"content": " Kafka Broker 재설치 Kafka Broker 서버의 디스크 용량을 증설하는 작업을 진행 하게 되었습니다. RAID 10으로 디스크 구성을 변경하다보니 불가피하게 OS를 재설치 합니다. Kafka는 Broker 서버의 장애 상황에서도 서비스를 유지 할 수 있도록 설계되어 있어요. Broker 서버를 1대씩 순차적으로 RAID 구성 및 OS 재설치 진행후에 Partition을 Reassign 할 계획입니다.\nEnvironment  CentOS 7.6 Cloudera CDH 6.1.1 Cloudera Manager Kafka 2.0.0-cdh6.1.1 Kafka Manager Kafka Broker 3대 Replication fector 3  HowTo Cloudera Manager 에서 작업대상 Broker 서버를 서비스에서 제거해요. Cloudera Manager의 Host 메뉴에서 해당 서버를 제거하여 CDH 플랫폼에서 호스트를 완전 제거 해요. RAID 를 구성하고 OS를 재설치 진행해요. Cloudera Manager 에서 호스트를 클러스터에 추가하고, Kafka 서비스에서 역할을 할당 해요.\n여기까지 진행하고 Broker를 투입하게 되면 Cloudera Manager 에서 나머지 2대의 Broker 서버에 경고가(Lagging Replicas Test) 표시 되요. Kafka 는 Broker가 재투입 되더라도 Partition을 자동으로 재조정 하지 않기 때문이예요.\nKafka Manager 의 Topic 리스트에는 Under Replication 으로 표시되네요.\n파티션을 재조정 하려면 각 Broker에 위치할 파티션들과 Replication 들을 Json 형식으로 일일이 작성해 Kafka Tool 명령어를 사용해야 해요. 이 작업은 매우 번거로울 수 있어요. 다행이 Kafka Manager 가 손쉽게 작업 할 수 있게 도와 주네요.\nKafka Manager 의 Topic 리스트에 작업할 Topic 의 상세 정보에 보면 Operation 들이 보입니다. Generate Partition Assignments 작업을 수행합니다. 위에서 말한 Json 파일을 만들어 준다고 보시면 되요. 이후 Reassign Partitions 작업을 수행합니다. Broker 서버로 파티션들을 옮기는 작업이예요. 용량에 따라 수분, 수십분이 소요 됩니다.\n아래는 2번째 Topic의 Reassign Partition 작업을 진행하고 6번째 Topic에서 Reassign Partition 작업을 진행 중입니다. 진행 중인 Topic에 대해 하일라이트 표시를 해주고 있네요. Reassign Partition 작업이 완료된 Topic는 Broker 가 3으로 표기되고, Under Replication 은 0으로 표기 되고 있습니다.\n그런데 Borker Leader Skew 가 발생 했네요. Skew는 사전적 의미로 왜곡된 이란 뜻이고, 파티션의 ISR Leader 선출에 문제가 있음을 말해요.\n모든 Topic에 대해 Reassign Partition 작업이 완료 되면 투입된 Broker 디렉토리에 파티션이 할당되었을 거예요. Kafka Data 디렉토리에서 du -hs 명령어로 데이터 들이 잘 복제 되었음을 확인 할 수 있어요.\n이제 Leader Skew를 해결 합니다. 파티션은 각 Broker로 분배 되어 투입된 Broker에 할당되었지만 투입된 Broker는 아직 파티션의 Leader 역할을 가지고 있지 않기 때문에 Skew가 발생해요. Kafka Manager 에서 Preferred Replica Election 작업을 수행 합니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/markdown/",
	"title": "markdown",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/howto/markdown/",
	"title": "Markdown 작성법",
	"tags": ["2019", "markdown"],
	"description": "",
	"content": " # header ## header ### header #### header ##### header ###### header  header header header header header header *** --- ===  ===\n# header ## header ### header #### header ##### header ###### header  header header header header header header 1. List 1. List 1. Sub List 1. List  * List * List * List * List - List + List   List  List  List   List List List\nthis is `code`   this is code\n\u0026gt; This is a blockQuote \u0026gt;\u0026gt; This is a blockQuote \u0026gt;\u0026gt; * List \u0026gt;\u0026gt; * List \u0026gt;\u0026gt;\u0026gt; This is a blockQuote   This is a blockQuote \u0026gt; This is a blockQuote \u0026gt; * List \u0026gt; * List \u0026gt;\u0026gt; This is a blockQuote\n |header 1|header 2 | |:-------|:-------| |row 1 col 1| row1 col 2| |row 2| row 2|     header 1 header 2     row 1 col 1 row1 col 2   row 2 row 2    [Go Naver][naverLink] Link: [Naver][naverLink] [naverLink]: http://www.naver.com \u0026quot;Go Naver\u0026quot;  Go Naver Link: Naver\nsyntax: [Go Naver](http://naver.com)  syntax: Go Naver\n\u0026lt;http://www.naver.com\u0026gt; \u0026lt;octchristmas@naver.com\u0026gt;  http://www.naver.com octchristmas@naver.com\n![Title](/assets/images/2019/babyelephant.png) \u0026lt;img src=\u0026quot;/assets/images/2019/babyelephant.png\u0026quot; width=\u0026quot;50px\u0026quot;\u0026gt;  {: .align-left}\n*asterisks* **asterisks** _underscores_ __underscores__ ++underline++ ~~cancelline~~  asterisks asterisks underscores underscores ++underline++ cancelline\n참고 : ihoneymon Github\n"
},
{
	"uri": "https://hahafamilia.github.io/book/%ED%95%98%EC%9D%B4%EB%B8%8C-%ED%95%B5%EC%8B%AC%EC%A0%95%EB%A6%AC/",
	"title": "하이브 핵심 정리, Apache Hive Essentials",
	"tags": ["book"],
	"description": "",
	"content": " 하둡 기반 대용량 데이터 저장, 관리의 핵심 솔루션 라는 부제를 가지고 있는 이 책에서는 HIVE(1.0.0) 에 대해서 설명하고, HQL, 성능, 보안, 다른 툴과의 연동에 대해서 설명하고 있어요.\n교보문고 링크\n출판  저자 : 다융 두, 김용환 옮김 출판사 : 에이콘출판 출간일 : 2017.02.28  목차  1장. 빅데이터와 하이브 소개 2장. 하이브 환경 설정 3장. 데이터 정의와 설명 4장. 데이터 선택과 범위 5장. 데이터 조작 6장. 데이터 집계와 샘플링 7장. 성능 고려 사항 8장. 확장성 고려 사항 9장. 보안 고려 사항 10장. 다른 툴과의 연동  개인평 SQL 에 익숙하다면 HQL 을 다루는데 큰 어려움은 없을 거예요. 빅데이터를 다루는데 HQL 을 상당히 많이 쓰이고 있어요. 책 구매 목적은 HQL 보다도 HIVE 에 대해서 놓치고 있는게 없을까? 많이 쓰이기 때문에 꼼꼼히 알아야 할 필요성이 있어 이 책을 구매하게 되었어요. 하지만 이 책의 대부분은 HQL 을 직접 사례로 들어가며 쿼리의 결과를 통해 HQL 을 사용법을 설명하고 있어요.\n저는 이 책에서 얻고자 했던 것을 얻지 못했어요. SQL을 다뤄본 독자라면 HQL은 공식 문서나 웹 검색을 통해 익히는 것이 낳은 것 같아요.\n"
},
{
	"uri": "https://hahafamilia.github.io/book/%EC%B9%B4%ED%94%84%EC%B9%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%8C%EB%9E%AB%ED%8F%BC%EC%9D%98-%EC%B5%9C%EA%B0%95%EC%9E%90/",
	"title": "카프카, 데이터 플랫폼의 최강자",
	"tags": ["book"],
	"description": "",
	"content": " 실시간 비동기 스트리밍 솔루션 Kafka의 기본부터 확장 응용까지 라는 부제를 가지고 있는 이 책에서는 카프카 메시지 큐(버전 1.0.0)의 컨슈머, 프로듀서, 주키퍼, 카프카 모니터링, 카프카 매니저 등의 개념과 운영에 대해서 설명하고, 확장하여 카프카 스트림즈 API, 카프카SQL, 파일비트, 나이파이, 키반, 엘라스틱서치, 구글 펍/섭, 아마존 키네시스, 도커 등의 키워드를 설명하고 있어요.\n교보문고 링크\n출판  저자 : 고승범, 공용준 출판사 : 책만 출간일 : 2018.04.26  목차  1부 카프카를 시작하며  1장 카프카란 무엇인가 2장 카프카와 주키퍼 설치  2부 기본 개념과 운영 가이드  카프카 디자인 카프카 프로듀서 카프카 컨슈머 카프카 운영 가이드  3부 카프카의 확장과 응용  카프카를 활용한 데이터 파이프라인 구축 카프카 스트림즈 API 카프카 SQL을 이용한 스트리밍 처리 그 밖의 클라우드 기반 메시징 서비스  부록 도커를 이용한 카프카 설치  개인평 빅데이터 플랫폼 고도화 과정의 일환으로 RabbitMQ 3.0.1 로 운영해 오던 메시지 큐를 Kafka 로 전환하게 되었어요. 실시간 메시지 큐는 데이터의 길목으로 장애 발생시 서비스에 파급력이 큰 부분이기에, 한번 더 확인하자는 취지로 책을 구매했어요.\n저 같은 경우 항상 새로운 어플리케이션을 도입 할때 가장 어려운 점은 Best Practice 찾는 것이예요. 이건 정답이 없고 각각의 플랫폼에 따라 달라지는 것이니 많은 테스트 와 시행착오를 거치게 되는 부분이죠. 이 시간을 줄여 줄 수 있는 플랫폼 성격에 맞는 Best Practice 에 대한 가이드를 찾았을때는 소화제를 먹은 것처럼 뻥 뚤리는 시원함이 느껴집니다.\n대부분의 기술 문서에서는 어플리케이션의 설계 개념 및 각각의 설정 값들이 하는 역할들을 설명하고 있지만, 어떤 설정이 구축하려는 플랫폼에 적합한 설정인지를 결정하는 일은 개념을 이해하는 것 보다도 더 어려운 일 같아요. 사실 카프카의 개념에 대해서는 책이 아니여도 이해하기 어려운 부분은 아니예요. Best Practice, 이것이 제가 이 책을 선택한 이유 이기도 합니다.\n역시나 책에서는 다년간 Kafka 운영 실무를 경험하신 저자로 설정값들의 가이드를 제공하고 있어요. 이 책에 아쉬운 점이 있다면 그것도 이 부분 입니다. 책에서는 Kafka 외에서 메시지 처리 및 데이터 파이프 라인에 관련한 키워들 다루고 있는데요. 이부분이 Kafka 구축 및 운영의 실무에서 발생할 수 있는 다양한 경우에 대한 가이드 였더라면\u0026hellip; 하는 아쉬움 입니다. 혹은 Kafka 가 그만큼 심플해서 다루지 않으셨을지도 모르겠네요.\n예를들어 메시지의 순서가 중요한 플랫폼, 유실을 감안할 수 있는 플랫폼, 절대 유실되어서는 안되는 플랫폼, 처리량이 많은 플랫폼, 처리량이 적은 플랫폼 등의 구축하려는 플랫폼들의 성격에 맞는 설정에 대한 Best Practice 가이드라던가. 이 책에서도 설명하고 있지만 더 많은 장애 상황들에 대한 가이드가 있었다면 책의 출판 목적에 더 부합하지 않았을까? 하는 개인적인 생각입니다.\n가까이 두고 자주 꺼내볼 책은 아닐지라도, 시간이 아깝지는 않은 책이예요. Kafka 도입을 생각하신다면 이 책을 추천합니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/book/%EB%AA%A8%EB%93%A0%EC%A3%BC%EC%8B%9D%EC%9D%84%EC%86%8C%EC%9C%A0%ED%95%98%EB%9D%BC/",
	"title": "모든 주식을 소유하라",
	"tags": ["book"],
	"description": "",
	"content": " Description 세계 4대 투자의 거장, 존 보글의 투자 법칙.\n2015년 워렌 버핏이 주주들에게 주천한 책!\n교보문고\n우화, 고트락스 가문 고트락스라는 부자 가문이 여러 대에 걸쳐 번창하여 형제, 자매, 삼촌, 사촌이 수천명이나 되었고, 미국의 모든 주식을 100% 소유하게 되었다. 얼마 후 브로커가 나타나서 다른 친척들보다 돈을 더 많이 벌 수 있는 방법이 있다고 속삭였다. 브로커들은 친척에게 보유 주식을 사고 팔게 했다. 브로커들은 대가로 수수료를 받고, 가문 사람들은 주식을 거래하는데 발생하는 자본이득에 대해서도 세금을 내야 했다.\n개인평 이 책은 고트락스 가문의 우화에 책의 모든 내용이 담겨져 있어요. 모든 주식을 소유하고 있다면, 경제의 성장이 개인의 수익이 되는 이기는 투자를 하게 된다는 것이예요. 그런 투자 개념에 맞게 주식투자에 앞서 투자 수익을 높이기 이전에 수수료 및 세금을 최소화 해야 한다고 말하고 있어요. 또한 지수를 따라가는 인덱스 펀드와 ETF, 장기 투자 방식에 대해 말하고 있습니다. 전 이 책을 읽고 제 투자 방향을 결정했습니다. 애초에 주식을 하게 된 이유도 대박의 이익을 노리고 시작한게 것이 아니었거든요.\n이제 주식을 시작하시려는 분들이게 이 책을 추천합니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/tags/github.io/",
	"title": "github.io",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/tags/jekyll/",
	"title": "jekyll",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/howto/jekyll-github-mistakes-blog/",
	"title": "Jekyll, Github.io, Minimal mistakes 블로그 만들기, 목차 한글링크 버그",
	"tags": ["2019", "jekyll", "github.io"],
	"description": "",
	"content": " 개발자 초창기에는 블로그(이전의 블로그) 활동도 열심히 했었는데\u0026hellip; 너무 잊고 살았었네요. 새롭게 블로그를 시작 할 생각에 Jekyll, Github.io 로 블로그를 구성하게 되었어요.\n간단히 Jekyll 은 정적파일 생성기, Github.io 는 호스팅, Minimal mistakes 는 수많은 Jekyll 테마중의 하나예요.\n선택의 기준은 markdown 에디터 때문이에요. 개발자는 에디터 툴을 가장 많이 다루는데요. 아무래도 markdown 으로 글을 작성하고 Git 으로 Push 하여 포스팅을 하는 구조라면 블로그 활동량이 많아지지 않을까 합니다.\n그럼 Github.io, Jekyll, Minimal mistakes theme 를 이용해 블로그를 만들어 봐요. 쭉~ 진행해본후 복기하여 글을 작성해서 순서가 바뀐부분이 있음을 감안해주세요.\nGit Git 은 형상관리 솔루션의 발전딘 형태로, 형상관리 외에도 많은 걸 해주고 있어요. 혹시 글을 읽으시는 분께서 Git을 모르시는\u0026hellip; 비 개발자라면 GitHub 사이트에서 파일을 생성/편집을 진행하셔도 되요. 그렇게 진행하시다 Git에 대해서 알아가셔도 됩니다.\nGithub.io GitHub 에 새로운 저장소를 생성해요. 저장소의 이름은 \u0026lt;github username\u0026gt;.github.io 로 생성하고 저장소의 이름이 도메인이 되요. 맘에 드는 Jekyll 테마 테마를 선택하시면되요. 저는 Minimal mistakes 를 선택했어요.\ntheme 설치 Minimal mistakes 의 가이드를 참고하면서 구성했어요. minimal-mistakes Quick Start 두가지 방법이 있어요. * 테마를 설치하는 방법 : local 에서 페이지 결과를 확인해 볼 수 있어요. * 테마를 원격으로 사용하는 방법 : 설치 과정이 없어요.\n저 같은 경우는 markdown 이니 preview 는 에디터 에서 가능하고, 초기 셋팅이 끝나면 설정하는 작업이 드물것이라 생각해서 원격 테마를 사용하는 방식으로 구성했어요. 하지만 조금 다른 방법으로 구성해 볼게요.\nQuick Start 에는 Minimal mistakes Github Project fork 하여 hahafamilia.github.io 로 이름 변경하라고 되어있어요.\n우선 mistakes 저장소를 이름 그대로 포크 합니다. 그림과 같이 Github에 2개의 Repository 가 있게 되요. Quick Start 불필요한 파일들을 삭제하라고 되어있어요. 삭제 하셔도 되고 안하셔도 됩니다.\nremove the unnecessary .editorconfig .gitattributes .github /docs /test CHANGELOG.md minimal-mistakes-jekyll.gemspec README.md screenshot-layouts.png screenshot.png  mmistakes Repository 에서 _config.yml 파일을 .github.io Repository 로 복사하고 remote_theme 항목을 수정해요.\n#_config.yml remote_theme : hahafamilia/minimal-mistakes  Hello world! 블로그 이렇게 연동 작업이 끝났어요. Git commit, push 하시면 블로그 주소에 접속하시면 기본 화면을 보실 수 있어요.\n_config.yml 에서 블로그에 관한 몇가지 정보들을 수정해 볼게요.\n#_config.yml title : \u0026quot;HaHa Familia\u0026quot; title_separator : \u0026quot;-\u0026quot; name : \u0026quot;HaHaFam\u0026quot; description : \u0026quot;HaHaFam Blog\u0026quot; url : \u0026quot;https://hahafamilia.github.io\u0026quot; repository : \u0026quot;hahafamilia/hahafamilia.github.io\u0026quot; logo : \u0026quot;/assets/images/logo.jpg\u0026quot; # Site Author author: name : \u0026quot;HaHaFam\u0026quot; avatar : \u0026quot;/assets/images/author.png\u0026quot; # path of avatar image, e.g. \u0026quot;/assets/images/bio-photo.jpg\u0026quot; bio : \u0026quot;Github.io Blog\u0026quot; location : \u0026quot;Seoul, Korea\u0026quot;  First Post 첫번째 글을 작성해 보도록 해요. github.io Repository 에 _drafts, _posts 두 개의 디렉토리를 생성해주세요. _posts 디렉토리에 년-월-일-글제목.md 형식으로 글을 작성하고 Git commit, push 하시면 블로그에 글이 게시 되요. _drafts 디렉토리는 작성중인 임시 글들을 저장하는 곳이라고 생각하시면 되요.\n_posts 디렉토리에 2019-01-25-first-post.md 라는 파일을 생성해 줍니다. 글을 작성하는 방법은 Front Matter 를 최상단에 작성하고, 이후 Markdown 형식으로 써내려 가면되요. Front Matter 는 일종의 설정값이라고 생각하면되요.\n# Front Matter --- date: 2019-01-25 title: \u0026quot;Jekyll 첫번째 글\u0026quot; categories: blog tags: jekyll # 목차 toc: true toc_sticky: true ---  글 내용으로 이미지를 첨부 하고 싶다면 github.io Repository aassets/images 라는 디렉토리에 보관해주세요.\n_config.yml _config.yml 에 몇가지 설정을 추가해 볼게요.\n검색은 google 검색을 비롯해 다양한 연동 설정을 제공하고 있는데요. 우선은 기본만 설정하고 추후에 다루도록 할게요.\nauthor, footer 의 links 설정에 블로그 주인장의 email, twitter, git, facebook 등의 링크들을 설정할 수 있어요.\ndefaults 는 글에 대한 기본 설정값이예요. 동일하게 글의 Front Matter 에서 개별적으로 설정이 가능해요.\nlocale : \u0026quot;ko-KR\u0026quot; search : true # true, false (default) # Site Author author: links: # Site Footer footer: links: # Defaults defaults: # _posts - scope: path: \u0026quot;\u0026quot; type: posts values: layout: single author_profile: true read_time: true  Category, Tags 블로그 활동이 왕성해지만 글들도 많아지게 되고, 글들에 대한 분류 작업이 필요해져요. 그래서 블로그에 카테고리와 테그, 연도 아카이브로 분류하는 설정을 해 줄게요.\n우선 github.io Repository 에 _pages 디렉토리를 생성하고, category-archive.md, year-archive.md, tag-archive.md 파일을 생성해주세요. 각각의 파일에 작성해야할 내용 이예요. 이렇게 되면 작성한 글의 Front Matter 설정값을 토대로 분류되요.\n# category-archive.md --- title: \u0026quot;Posts by Category\u0026quot; layout: categories permalink: /categories/ author_profile: true --- # year-archive.md --- title: \u0026quot;Posts by Year\u0026quot; permalink: /year-archive/ layout: posts author_profile: true --- # tag-archive.md --- title: \u0026quot;Posts by Tag\u0026quot; permalink: /tags/ layout: tags author_profile: true ---  fork 해온 minimal mistakes Repository 에서 _data/navigation.yml 파일을 복사해서 동일한 디렉토리를 생성하고 저장해주세요. 이 설정은 블로그의 상단 메뉴에 관한 설정이예요. 카테고리, 테그, 연도 아카이브 메뉴를 생성해 주세요. 예를 들어 카테고리라면..\n- title: \u0026quot;Categories\u0026quot; url: /categories/  Stylesheet minimal mistakes repository 에서 assets/css/main.scss 파일을 복사해서 동일한 경로의 디렉토리를 생성하고 저장해주세요. 대부분의 Style 수정은 main.scss 에서 이루어져요.\nFont main.scss 파일을 수정하여 변경할 웹폰트를 import 합니다.\n@charset \u0026quot;utf-8\u0026quot;; @import \u0026quot;minimal-mistakes/skins/{{ site.minimal_mistakes_skin | default: 'default' }}\u0026quot;; // skin @import \u0026quot;minimal-mistakes\u0026quot;; // main p // Font 변경 @import url('https://fonts.googleapis.com/css?family=Inconsolata');  전 Inconsolata 를 선택했습니다. Inconsolata 프로그래머들이 사용하는 Font 랭크 ( Best Programming fonts) 순위권 안에 드는 고정폭 폰트 입니다.\n그리고 import 다음 라인으로 폰트 변수에 폰트를 할당해 줍니다.\n$serif : \u0026quot;Inconsolata\u0026quot;, monospace, \u0026quot;PT Serif\u0026quot;, Georgia, Times, serif; $sans-serif-narrow : \u0026quot;Inconsolata\u0026quot;, monospace, \u0026quot;PT Sans Narrow\u0026quot;, -apple-system, BlinkMacSystemFont, \u0026quot;Roboto\u0026quot;, \u0026quot;Segoe UI\u0026quot;, \u0026quot;Helvetica Neue\u0026quot;, \u0026quot;Lucida Grande\u0026quot;, Arial, sans-serif; $global-font-family : $serif; $header-font-family : $sans-serif-narrow; $caption-font-family: $serif !default;   css 변수에 대한 기본값은 minimal mistakes repository 의 _sass/minimal-mitakes/_variables.scss 에서 확인 가능해요.\n Font Size main.scss 파일을 수정하여 폰트의 크기를 조정해요. 이렇게 설정할경우 블로그의 전체 폰트 크기가 일정한 폭으로 변경됩니다.\nhtml { font-size: 12px; // originally 16px @include breakpoint($medium) { font-size: 14px; // originally 18px } @include breakpoint($large) { font-size: 16px; // originally 20px } @include breakpoint($x-large) { font-size: 18px; // originally 22px } }  Title Link Style 포스트의 목록에서 타이틀의 언더라인이 깔끔해 보이지 않네요. main.scss 파일을 수정합니다.\n// list title link remove underline .archive a { color: inherit; text-decoration: none; }  댓글(Disqus), 방문자통계(Google Analystics) Disqus, Google Analystics 계정이 있다면 설정은 간단하게 이루어 저요.\nGoogle Analystics 는 트래킹 코드가 필요합니다. Disqus 댓글 설정시에는 shortname 필요합니다. shortname 은 Disqus 에서 사이트 생성시 할당되는 이름이예요. 저 같은 경우 hahafamilia.disqus.com 의 hahafamilia 가 shorname 이 됩니다.\n# _config.yml comments: provider : \u0026quot;disqus\u0026quot; # false (default), \u0026quot;disqus\u0026quot;, \u0026quot;discourse\u0026quot;, \u0026quot;facebook\u0026quot;, \u0026quot;google-plus\u0026quot;, \u0026quot;staticman\u0026quot;, \u0026quot;staticman_v2\u0026quot;, \u0026quot;utterances\u0026quot;, \u0026quot;custom\u0026quot; disqus: shortname : \u0026quot;hahafamilia\u0026quot; # https://help.disqus.com/customer/portal/articles/466208-what-s-a-shortname-  # _config.yml analytics: provider : \u0026quot;google\u0026quot; # false (default), \u0026quot;google\u0026quot;, \u0026quot;google-universal\u0026quot;, \u0026quot;custom\u0026quot; google: tracking_id : \u0026quot;UA-145448356-1\u0026quot;   Disqus 는 Git push 하고 반영 되는데 꽤 오랜 시간이 걸리네요.\n 목차(toc), 한글 링크 이동하지 않는 버그 Front Matter toc: true 를 설정하게 되면 친절하게 markdown 헤더들로 목차를 만들어 줘요. 그런데 목차를 한글로 입력하니 클릭 해도 링크로 이동하질 않는 버그가 있어요.\n해결책 찾는 과정에서 해결해서 프로젝트 기여하신 분이 계시네요. 이전 버전 사용하시는 분은 Bugfix 수정해서 사용하시면 되겠어요.\n마치며 여기까지 Jekyll, Github.io, Minimal mistakes 를 이용해서 블로그 만드는 방법에 대해 알아 봤습니다. 블로그 활동량이 많아져 그들이 많아지게 되면, 추가적인 구성들을 더 해볼 생각입니다. 먼저, 글을 꾸준히 올리는 습관을 들여야겠네요.\n"
},
{
	"uri": "https://hahafamilia.github.io/howto/git/",
	"title": "Git",
	"tags": ["2019", "git"],
	"description": "",
	"content": " Git 기본개념 파일상태  Committed : 커밋상태, git commit Modified : 수정상태 Staged : 커밋대기상태, git add  사용영역  Git directory(Local repository) : git init 으로 지정, .git 디렉토리가 생성 Working directory : branch 를 checkout 한 내용 Staging Area  환경설정  $GIT_HOME/[installed_path]/gitconfig : 시스템의 모든 사용자 설정, git config --system $USER_HOME : 특정 사용자 설정, git config --global .git/config : 특정 저장소 설정  Getting Started cd /your/project/home touch readme.md git init # make git directory git status git add readme.md git status git commit -m 'commit message'  Branch  목록 : git branch, git branch -a 생성 : git branch [branch_name] 변경 : git checkout [branch_name]  Branch merge git branch [another_branch] another_branch를 현재 Branch에 병합 같은 파일의 같은 곳 수정되었을 경우 conflict가 발생하고, 수정작업이 필요\n.gitignore gitignore.io\nRemote Repository GitHub 대표적인 GitHub 는 추가적인 기능으로 fork, pull request 제공\n Fork : 다른 사용자 Repository를 내 계정으로 복제 Pull Request : Fork한 Repository를 수정한 후 원본 Repository 로 병합 요청  Remote Repository관리목적의 Git 명령어  git clone : Remote에서 Local로 복사 git remote : Local Repository를 Remote Repository와 연결 git push : Local의 변경내용을 Remote Repository에 저장 git fetch : Remote와 Local이 다를 때 충돌을 해결하고 최신데이터 반영 git pull : Remote의 변경내용을 Local로 가져오면서 merge하는데 conflict 발생시 추적이 어려우므로 Fetch 수행후 Local 파일을 수정하고 Commit/Push 한 후 Pull\ngit remote add origin remote_repository_url git push -u origin branch_name[master] git remote -v git cloen https://github.com/path/pproject.git    clone하게되면 자동으로 master를 origin/master(업스트림 브랜치)의 트래킹브랜치로 생성, -u, --set-upstream는 트래킹 브랜치 이름을 대체\n Remote Branck 가져오기 git remote update ## Remote branch list, -a : All Branch remote/local git branch -r git checkout -t remote_branch_name ## 다른이름으로 가져올 때 git checkout -b local_branch_name remote_branch_name  Submodule 삭제 git submodule add https://github.com/chaconinc/DbConnector\ncd \u0026lt;projejct dir\u0026gt; # delete module on .gitmodules vi .gitmodules git rm --cached \u0026lt;module\u0026gt; git submodule deinit \u0026lt;module\u0026gt; rm -rf .git/modules/\u0026lt;module\u0026gt; rm -rf \u0026lt;module\u0026gt; git commit -m 'delete module' git push  HowTo Mac Github 비밀번호 재설정 git config --local --unset credential.helper  "
},
{
	"uri": "https://hahafamilia.github.io/tags/git/",
	"title": "git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hahafamilia.github.io/book/%ED%95%98%EB%91%A1-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/",
	"title": "하둡 애플리케이션 아키텍처",
	"tags": ["book"],
	"description": "",
	"content": " 하둡 에코시스템을 활용한 빅데이터 처리 라는 부제을 가지고 있는 이 책에서는 HDFS/HBASE 스키마 디자인, 데이터 파이프라인, 맵리듀스, 스파크, 피크, 크런치, 하이브, ETL, 스트리밍, 근접 실시간, 데이터 웨어하우스, 사례연구 등 데이터의 수집에서 분석까지의 빅데이터 아키텍처에 대해 설명하고 있어요.\n교보문고 링크\n출간  저자 : 마크 그로버, 테드 멀래스커, 조나단 사이드먼, 그웬 사피라 옮김 : 정동식, 홍다경, 우지현 출판사 : 비제이퍼블릭 출간일 : 2016.05.30  목차  1부. 하둡 애플리케이션의 아키텍처 고려사항  1장. 하둡 데이터 모델링 2장. 데이터 이동 3장. 하둡 데이터 프로세싱 4장. 하둡의 일반적인 프로세싱 패턴들 5장. 하둡 그래프 프로세싱 6장. 오케스트레이션 7장. 하둡을 활용한 근접 실시간 프로세싱  2부. 사례 연구  8장. 클릭스트림 분석 9장. 부정거래 탐지 10장. 데이터 웨어하우스   개인평 이 책에는 하둡을 기반으로 하는 빅데이터 플랫폼 아키텍처에 대해 설명하고 있어요. 아키텍처에 대한 책이다보니 각 어플리케이션의 설치 방법 등의 내용은 포함하고 있지 않아요.\n데이터의 수집, 이동, 분석, 시각화까지 플랫폼을 구축하는데 있어서 하둡 에코 시스템내의 어플리케이션들이 어떤 것들이 있고, 어떻게 배치 할 것인가? 각각의 경우에 어떠한 어플리케이션을 선택해야 하는가? 등의 아키텍처에 대해 설명하고 있어요.\n아쉬운 점이라면 2016년 출간 이후 하둡 에코 시스템은 계속 변화 하였고, 새로운 어플리케이션들이 다양하게 있는데, 이러한 부분은 담고 있지 않아요. 책을 통해서 아키텍처를 흐름을 이해하고, 구축하려는 플랫폼에 맞게 재구성할 필요가 있어요.\n큰 주제를 다루다보니 뜬 구름 일 수도 있어 보이는 내용은 하둡 에코시스템에 대한 지식이 부족하고, 하둡 아키테처 설계에 대한 기초 지식을 쌓아야 하는 분에게 이 책을 추천합니다.\n"
},
{
	"uri": "https://hahafamilia.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
}]