<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2013 on haha family&#39;s happy blog</title>
    <link>https://hahafamilia.github.io/tags/2013/</link>
    <description>Recent content in 2013 on haha family&#39;s happy blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Thu, 12 Dec 2013 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hahafamilia.github.io/tags/2013/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Memcache 개념과 설치 / 운영</title>
      <link>https://hahafamilia.github.io/development/memcache-install-management/</link>
      <pubDate>Thu, 12 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/memcache-install-management/</guid>
      <description>아키텍처 데이터 구조  캐시 항목을 찾기 위한 해쉬 테이블(burket list) 캐시 항목 제거(eviction) 순서를 결정하는 LRU(least recently used) list 키 (key), 데이터 (value), 플래그 및 포인터들을 담고 있는 캐시 데이터 구조 캐시 항목 데이터 메모리 관리자인 슬랩 할당자 (slab allocator) 캐시항목  해쉬 테이블에서 bucket 당 single linked-list를 가르키는 포인터 LRU에서 double linked-list에 사용되는 포인터 캐시 항목에 동시에 접근하는 스레드 수를 나타내는 reference counter 캐시 항목 상태 플래그 키 (key) 값 길이 (바이트) 값 (value)   프로세스 흐름  NIC에 요청 packet이 도착하고 libevent에 의해 처리 worker thread  연결 및 데이터 패킷을 받기 명령 및 데이터를 확인  Hash 값은 키 데이터에서 생성 해쉬 테이블과 LRU 처리를 위해 global cache lock 획득 (Critical Section 시작)  캐시 항목 메모리 할당 캐시 항목 데이터 구조에 데이터를 저장 (플래그, 키, 값) 해쉬 테이블에서 캐시 항목을 GET, STORE, DELETE하기 위해 해쉬 테이블을 탐색 캐시 항목을 LRU 앞에 삽입 (GET, STORE) 또는 제거 (DELETE) 하면서 LRU 수정 캐시 항목 플래그를 업데이트  Global cache lock 해제 (Critical Section 끝) 응답 구성 (GET만 해당) global cache lock 확인 (assert)  캐시 항목 ref count를 1 감소 global cache lock 해제  요청한 클라이언트 (프론트엔드 웹 서버)로 응답 전송  성능  성능 = 싱글코어 &amp;lt; 멀티코어 &amp;lt; 하이퍼스레딩 Global cache lock은 스레드가 4개 이상일 경우 병목 현상이 발생하는 주요 원인 Global cache lock은 워쿼 스레드 간의 lock 경합이 높을 수 있음 Global cache lock의 성능 향상을 위한 1.</description>
    </item>
    
  </channel>
</rss>