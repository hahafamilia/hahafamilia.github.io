<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bigdata on haha family&#39;s happy blog</title>
    <link>https://hahafamilia.github.io/development/</link>
    <description>Recent content in Bigdata on haha family&#39;s happy blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Mon, 16 Sep 2019 16:32:12 +0900</lastBuildDate>
    
	<atom:link href="https://hahafamilia.github.io/development/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Presto 설치, PrestoDB, PrestoSQL</title>
      <link>https://hahafamilia.github.io/development/presto-installation/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/presto-installation/</guid>
      <description>Cloudera CDH 위에서 Presto 엔진을 싱글 서버로 사용할 계획에 Presto 를 설치하려는데, 0.230 버전, 328 버전이 어떤걸 써야 할지 모르겠어요. 좀 더 알아보니 PrestoDB, PrestoSQL 두개로 나뉘는군요. Presto, PrestoDB, PrestoSQL 의 차이를 설명한 문서예요. 요약하자면 PrestoDB를 사용하라는 겁니다. * Facebook에서 Presto 오픈소스 프로젝트를 공개했고 이것이 PrestoDB(https://prestodb.io/) * Fracebook에서 3인의 개발자가 분사하여 만든 프로젝트가 PrestoSQL(https://prestosql.io/)
Version  PrestoDB 0.230 CentOS Java8  Presto 설치 Download Link
tar xvzf presto-server-0.230.tar.gz cd presto-server-0.</description>
    </item>
    
    <item>
      <title>할아버지 클러스터의 엉망진창 HBase 문제해결</title>
      <link>https://hahafamilia.github.io/development/hbase-troubleshooting/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/hbase-troubleshooting/</guid>
      <description>입사초기에 있었던 경험에 대해서 적어볼게요. 빅데이터 플랫폼 개발자 포지션으로 입사를 했어요. 면접과정에서 플랫폼에 장애가 빈번하다. 직원들이 많이 빠져나갔다는 얘기는 들었어요. 전 과거 4년간 Apache Hadoop 1.x 버전에서 2.x 버전으로 업그레이드를 진행하면서 운영한 경험이 있어요. 당시 많은 문제들을 경험했고 Hell의 문앞에도 가 보았기 때문에&amp;hellip; 다 해결해 주겠어! 라는 각오로 입사했어요. 막상 입사해보니 그나마 있던 담당자 마저 퇴사&amp;hellip; 뭔가 싸늘한 기운이 느껴집니다? 그래도 파이팅 해봅니다.
클러스터는 Cloudera CDH 4, 2012년에 릴리즈 되었던 버전이예요.</description>
    </item>
    
    <item>
      <title>클러스터 네트워크 일시 장애로 인한 Kafka/Zookeeper 문제해결</title>
      <link>https://hahafamilia.github.io/development/kafka-zookeeper-troubleshooting/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/kafka-zookeeper-troubleshooting/</guid>
      <description>장애알림으로 시작하는 상쾌한 월요일입니다? 빅데이터 플랫폼의 클러스터 일부 서버에서 경고 알림이 보고 되었어요. Cloudra Manager 의 서비스 리스트에는 Kafka 서비스에서 Lagging Replicas Test 실패 발생되었다고 경고를 보여주고 있네요. 이번 경우도 문제의 원인은 눈에 보이는 것과는 다르네요. 어떤 일이 있었던걸까요?
Version  Cloudera CDH 6.1.1 Cloudera Kafka 2.11-2.0.0-cdh6.1.1  현상파악 Cloudera Manager 확인 3대의 Kafka Broker 중에 01~02 서버에서 경고가보여지고, 03 서버는 정상으로 보여져요. 문제발생한 시간대에 Kafka 로부터 유입되는 데이터의 유실은 다행히 발생하지 않았어요.</description>
    </item>
    
    <item>
      <title>IntelliJ maven scala 프로젝트 설정</title>
      <link>https://hahafamilia.github.io/development/intellij-maven-scala/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/intellij-maven-scala/</guid>
      <description>IntelliJ IDE 에서 spark streaming 개발을 위해 scala maven 프로젝트 생성 방법을 알아봐요. scala 프로젝트는 sbt 를 기본으로 사용하지만, maven 에 익숙하여 maven 으로 프로젝트를 생성해요. scala-archetype-simple 으로 프로젝트 생성이 가능한데, 제가 직접 구성하는게 좋아요.
Version  Spark 2.4.0 Scala 2.11 Hadoop 2.7 Java 8 Window  Spark, Hadoop 설치 Spark Download 에서 Spark 를 다운로드해요. 운영중인 클러스터의 스파크버전과 맞추어 2.4.0 버전의 Pre-built for Apache Hadoop2.7 을 다운로드 했어요. 다운로드한 파일을 압축해제 하고 SPARK_HOME 환경변수로 등록후 PATH 설정해요.</description>
    </item>
    
    <item>
      <title>Apache Pig Latin</title>
      <link>https://hahafamilia.github.io/development/apache-piglatin/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/apache-piglatin/</guid>
      <description>Apache Pig Yahoo 에서 공개한 걸로 알고 있어요. 최근 버전은 Hive on Spark 처럼 Pig on Spark 으로 사용하는군요. 새로운 Flow 코드 작성시 잘 사용하진 않지만, SQL 사용시 함수와 프로시져를 만들어야 하는 경우가 있는데, 그런 경우 Pig 를 사용하고 있어요. ASIS Flow 에서 사용되어지고 있는 코드 들이 있어서 간단히 문법에 대해 정리 해봐요.
Pig Latin Basic 연산자 및 명령어들은 대소문자를 구분하지만, 별칭 및 함수 이름은 대소문자를 구분해요.
Data types int, long, float, double, chararray, Bytearray, Boolean, Datetime, Biginteger, Bigdecimal, Tuple, Bag(collection of tuples), Map</description>
    </item>
    
    <item>
      <title>고급 분석과 머신러닝 개요</title>
      <link>https://hahafamilia.github.io/development/machine-learning-spark-guide/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/machine-learning-spark-guide/</guid>
      <description>스파크 완벽가이드 Part 6 고급 분석과 머신러닝 내용을 요약했어요.
Part 6 24장 고급 분석과 머신러닝 24장 고급 분석과 머신러닝 개요 머신러닝 머신러닝의 방법론들은 예측과 묶음
 지도학습 : 레이블을 예측하는 분류/회귀 문제를 포함한 추천엔진 : 사용자의 과거 행동에 기반하는 비지도 : 군집 분석, 이상징후 탐지, 토픽 모델링과 같이 데이터 구조 파악을 위한 학습 그래프 학습 : 소셜 네트워크 상에서 유의미한 패턴을 찾는  지도학습 답(label, 종속변수)이 주어지고 답을 찾는 학습</description>
    </item>
    
    <item>
      <title>Cloudera CDH Configuration</title>
      <link>https://hahafamilia.github.io/development/cloudera-cdh-configuration/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/cloudera-cdh-configuration/</guid>
      <description>Bigdata 플랫폼으로 Cloudera CDH 6.1.x 를 운영중 트러블슈팅과 설정에 대해 이야기 해볼게요.
Version  Cloudera CDH 6.1 Oracl Java 1.8  YARN Turning YARN YARN 의 리소스 관련 설정의 기본 값 Default Memory Setting
YARN 리소스 튜닝 방법 Turning YARN
노드의 전체 가용 리소스에서 서비스 데몬들의 리소스 사용량을 제하고 리소스를 할당 해요. 튜닝 문서와는 다르게 Cloudera Manager 에서 각 호스트들의 리소스 사용량은 상이해요. 튜닝 문서와 Cloudera Manager &amp;gt; Host &amp;gt; Worker &amp;gt; Resource 리소스 사용량을 참고하여 Yarn 에 할당할 CPU, Memory 를 결정한 후, 아래의 프로퍼티에 값을 설정해요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Project Build</title>
      <link>https://hahafamilia.github.io/development/zeppelin-project-build/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/zeppelin-project-build/</guid>
      <description>Zeppelin 소스 코드를 빌드해봐요. 오픈소스 수정은 선호하진 않지만, Frontend 화면 수정은 필요할 것 같아요.
Personalized 기능이 필요한데 0.8.2 버전에서 Bug ZEPPELIN-3065 가 있어요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Versions  Zeppelin 0.8.2 Git Any Maven 3.1 or igher JDK 1.7 Mac, IntelliJ   제환경은 OpenJDK 1.8 이예요. 빌드는 잘 되요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin on CDH, Yarn</title>
      <link>https://hahafamilia.github.io/development/zeppelin-on-cdh/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/zeppelin-on-cdh/</guid>
      <description>Apache Zeppelin 과 CDH 를 연동해요.
Yarn 리소스 매니저 관리하에 Spark 어플리케이션을 실행시킬 수 있어요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Version  Zeppelin 0.8.2 Cloudera CDH 6.1.x  Zeppelin Zeppelin on CDH 공식 문서를 참고해요.
설정 /conf/zeppelin-env.sh 파일을 수정해요. 설치 환경에 따라서 경로는 다를 수 있어요.
export MASTER=yarn-client export SPARK_HOME=&#39;/opt/cloudera/parcels/CDH/lib/spark` export HADOOP_CONF_DIR=&#39;etc/hadoop/conf&#39;  Cloudera Manager &amp;gt; Yarn &amp;gt; Application 목록에서 Zeppelin 이 실행중인걸 확인 할 수 있어요.</description>
    </item>
    
    <item>
      <title>FFMPEG를 이용해 음악 플레이리스트 동영상 만들기</title>
      <link>https://hahafamilia.github.io/development/ffmpeg-music-youtube/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/ffmpeg-music-youtube/</guid>
      <description>음원의 플레이리스트를 앨범 자켓 이미지를 포함시켜 동영상으로 만들 수 있나요? 라는 얘기를 듣게 되었어요. 의도는 Youtube 에는 음악등록을 할 수 없어서, 동영상으로 만들어서 업로드 해야된다고 하네요.
그래서 간단하게 프로토타입을 만들어 봤어요. FFMPEG 검색을 해보니 이러한 시도를 하는 분들이 꽤 있나 보군요.
프로토타입  하나의 음원을 이미지를 포함시켜 동영상으로 제작 각 동영상들을 이어 붙히기
ffmpeg -loop 1 -i Happy.jpg -i Happy.mp3 -shortest -acodec copy 2.mp4 ffmpeg -loop 1 -i StellaJang.jpg -i StellaJang.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Upgrade from 0.8.1 to 0.8.2</title>
      <link>https://hahafamilia.github.io/development/zeppelin-upgrade-0.8.2/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/zeppelin-upgrade-0.8.2/</guid>
      <description>Apache Zeppelin 0.8.2 버전이 2019.11.29 일에 Release 되었어요. 0.8.1 버전에서 발견되었던 버그들도 수정이 되었으니 업그레이드를 진행 해보도록 할게요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Apache Zeppelin 0.8.2 Upgrading 문서를 보니 0.8.x 버전에서의 업그레이드는 conf 와 notebook 디렉토리를 복사해주기만 하면 된다고 하니 손쉽게 진행 될 것으로 예상되요.
업그레이드 Apache Zeppelin Download 다운로드 사이트에서 바이너리 파일을 다운로드 해서, 0.</description>
    </item>
    
    <item>
      <title>Cloudera CDH 6.1.1 설치하기</title>
      <link>https://hahafamilia.github.io/development/cloudera-cdh-6_1-intall/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/cloudera-cdh-6_1-intall/</guid>
      <description>ASIS 플랫폼의 고도화 일환으로 빅데이터 플랫폼을 신규로 구축하게 되었어요. 구축과정의 일환인 Cloudera CDH 6.1.1 설치과정을 뒤늦게사나마 정리해볼게요. 설치를 진행하기 전에 플랫폼 아키텍처의 설계와 물리서버 사양의 선택, 랙 배치 등이 우선되었겠죠? 이것에 대해서는 또 정리하도록 할게요.
설치 과정은 크게 3단계로 진행되요.
 설치하기 전에 Cloudera Manager 설치 CDH 구성요소 설치  Cloudera CDH 6.1 버전의 공식 문서를 참고해서 진행했어요.
Cloudera Enterprise 6.1 Document
Cloudera Installation Guide
버전  CentOS 7.6.1810 Java 1.</description>
    </item>
    
    <item>
      <title>Kafka Manager 설치</title>
      <link>https://hahafamilia.github.io/development/kafka-manager-installation/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/kafka-manager-installation/</guid>
      <description>KafkaManager 설치 Kafka Manager 를 설치해 볼게요. Kafka Manager 는 Yahoo 의 오픈소스 인데, Kafka 서비스의 상태를 확인하거나, Skew 등이 발생했을때 Reassign Partitoin 등을 할 수 있는 기능을 제공해줘요.
https://hahafamilia.github.io/bigdata/kafka-broker-reinstall/ Github 에서 다운로드 한 후, Scala 빌드 빌드툴 sbt 로 빌드 해줘요.
tar -xvzf kafka-manager-1.3.3.22.tar.gz cd kafka-manager-1.3.3.22 PATH=/usr/java/jdk1.8.0_141-cloudera/bin:$PATH JAVA_HOME=/usr/java/jdk1.8.0_141-cloudera \ ./sbt -java-home /usr/java/jdk1.8.0_141-cloudera clean dist cp target/universal/kafka-manager-1.3.3.22.zip /usr/local cd /usr/local unzip kafka-manager-1.3.3.22.zip  conf/application.conf 설정파일에 Zookeeper 호스트 주소를 설정해 줘요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Interpreter, Hive, Impala</title>
      <link>https://hahafamilia.github.io/development/zeppelin-interpreter/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/zeppelin-interpreter/</guid>
      <description>Apache Zeppelin 과 Cloudera CDH 의 Hive, Impala 를 연동하는 방법을 알아볼게요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1 Cloudera CDH 6.1.1 Hive 2.1.1 Impala 3.1.0 Impala JDBC Driver 2.6.12  Hive Zeppelin Hive Interpreter Document 문서를 보면 Jdbc Interpreter 를 사용하라고 되어있네요. 기본으로 PostgreSQL Connector 지원하고 그외는 Connector 는 추가를 해줘야 해요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Usage</title>
      <link>https://hahafamilia.github.io/development/zeppelin-usage/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/zeppelin-usage/</guid>
      <description>Apache Zeppelin 은 노트북 방식의 시각화 툴이예요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1  Dynamic Form Zeppelin 에서는 Dynamic Form 을 제공하고 있어서 Form 을 통해 입력받은 값으로 조건을 주는 형태로 사용 가능해요. Dynamic Form 은 Paragraph scope 와 Note scope 에서 사용 문법의 차이가 있고, 또한 Programmatically 하게 추가하실 수 있어요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin 설치, QuickStart</title>
      <link>https://hahafamilia.github.io/development/zeppelin-quickstart/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/zeppelin-quickstart/</guid>
      <description>Apache Zeppelin 은 노트북 방식의 시각화 툴이예요. 다양한 시각화 툴이 존재하지만 &amp;lsquo;가장 좋은 것&amp;rsquo;이 아니라 &amp;lsquo;나에게 맞는 것&amp;rsquo; 을 선택했어요. 제가 Zeppelin을 선택한 이유는 아래와 같아요.
 설치와 사용법이 쉬워야 한다. 요구사항을 유연하게 처리 할 수 있어야 한다. BI 웹 어드민을 개발 하지 않아도 되도록 정적 HTML 을 제공해야 한다.  Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.</description>
    </item>
    
    <item>
      <title>Oozie Workflow Email 알림 설정</title>
      <link>https://hahafamilia.github.io/development/oozie-workflow-email/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/oozie-workflow-email/</guid>
      <description>Oozie 에서 Workflow 의 결과에 따른 Email 알림을 받는 방법에 대해서 알아볼게요.
Workflow 를 1회성으로 실행시키는 경우와 Schedule 로 등록하여 주기적으로 실행하는 경우가 있을 수 있을텐데요. 1회성으로 Workflow 만 실행할때는 성공/실패에 대한 처리 결과를 받도록 하고, Schedule 로 등록하여 주기적으로 실행하는 경우에는 실패에 대한 알림 만을 받도록 합니다.
Version  Cloudera 6.1.1 Oozie 5.0.0 Hue 4.3.0  Oozie SMTP 설정 Cloudera Manager &amp;gt; Oozie &amp;gt; 구성 탭 에서 mail 을 검색해서, oozie.</description>
    </item>
    
    <item>
      <title>AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집</title>
      <link>https://hahafamilia.github.io/development/spring-kafka-flume/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/spring-kafka-flume/</guid>
      <description>다음과 같은 데이터 파이프 라인을 가정해 볼게요.
 사용자의 Activity 이벤트가 발생 API 서버를 통해 Kafka 에 Produce Flume 을 통해 Kafka 의 메시지를 HDFS 로 적재 HDFS 에는 일자 별로 생성된 디렉토리에 저장  Flume 을 퉁한 데이터 수집시에 Hdfs Sink 는 useLocalTimestamp 설정은 제공 해요. 하지만 이 설정은 이벤트의 수집 시각을 기준으로 해요.
예제 그림에서 API 에서 시작된 데이터는 파이프라인을 거쳐 HDFS 에 도달하기까지 2초의 시간이 소요된다고 가정하면, 2019-08-01 23:59:59 시각에 발생한 이벤트는 useLocalTimestamp 설정에 의해 2019-08-02 00:00:01 의 시각으로 2019-08-02 디렉토리에 적재됩니다.</description>
    </item>
    
    <item>
      <title>Cloudera Manager 알람 설정, Gmail SMPT 서버 사용</title>
      <link>https://hahafamilia.github.io/development/cloudera-alert-email/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/cloudera-alert-email/</guid>
      <description>Cloudera Manager 알림을 보내는 방법은 SMTP, SNMP, Custom Script 세가지를 제공하고 있어요. 여기서 SNMP, Custom Script 는 Enterprise 버전에서만 지원해요. 별도의 SMTP 서버를 운영하고 있지 않다면 Gmail 을 이용할 수 있어요.
Cloudera Version Cloudera 6.1
Gmail 설정 우선 Gmail 설정에서 IMAP 사용이 허용되어야 해요. 그리고 Google 계정 설정 &amp;gt; 보안 &amp;gt; 보안 수준이 낮은 앱의 액세스 가 허용되어야 합니다.
 이 방법은 보안상 권장하지 않는 방법 이예요. 하지만 제가 근무하는 회사의 G Suite 에서는 액세스키에 의한 접근 기능이 제공되고 있지 안아서 이 방법을 사용하고 있어요.</description>
    </item>
    
    <item>
      <title>Python 개발환경, Pyenv, Anaconda3</title>
      <link>https://hahafamilia.github.io/development/python-pyenv-anaconda-mac/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/python-pyenv-anaconda-mac/</guid>
      <description>Mac 에서 Homebrew 통해서 Python 가상화 환경을 구성하려고 합니다. 우선 Mac 버전이 모하비라면 모하비 brew error 글을 한번 읽어보세요.
Python 가상환경 구성방법은 여러가지가 있지만, pyenv/virtualenv 를 사용할거예요. 대략적인 과정은 pyenv 설치, anaconda3 설치, 가상환경 구성의 순서예요. pyenv 는 가상화 관리를 위해서 pyenv-virtual 패키지를 사용하는데, anaconda3 정도만 사요할 예정이면 설치 하지 않아요 되요.
pyenv brew help brew update brew install pyenv pyenv -v pyenv 1.2.13 pyenv install -list | grep anaconda .</description>
    </item>
    
    <item>
      <title>Hive Java UDF, 유니코드</title>
      <link>https://hahafamilia.github.io/development/hive-java-udf/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/hive-java-udf/</guid>
      <description>개요 Cloudera Document 6.1 Hive UDF 문서를 참고하여 Cloudera CDH 플랫폼에서 HIVE UDF 를 작성하는 방법을 알아봅니다.
또한 MySQL의 Collate 와 문자열 유니코드에 대해서도 간단히 알아보겠습니다.
저의 이번 경우는 HIVE로 집계된 데이터를 SQOOP으로 export 시에 오류가 발생하였습니다.
기존에 설계된 MySQL 디비의 테이블 칼럼 Collate 속성이 utf8-general-ci 로 설계되어 있어 Key 칼럼에 Accent 문자열을 포함하는 문자열 데이터 자정시에 상황에 따라 키중복이 발생했던 것이었습니다.
칼럼의 Collate 속성이 utf8-general-ci 일경우 아래와 같은 경우 ã 문자열은 저장이 되겠지만 a 문자열 저장시 Key 중복 오류가 발생합니다.</description>
    </item>
    
    <item>
      <title>Kafka Broker 디스크 증설, RAID구성, OS 재설치</title>
      <link>https://hahafamilia.github.io/development/kafka-broker-reinstall/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/kafka-broker-reinstall/</guid>
      <description>Kafka Broker 재설치 Kafka Broker 서버의 디스크 용량을 증설하는 작업을 진행 하게 되었습니다. RAID 10으로 디스크 구성을 변경하다보니 불가피하게 OS를 재설치 합니다. Kafka는 Broker 서버의 장애 상황에서도 서비스를 유지 할 수 있도록 설계되어 있어요. Broker 서버를 1대씩 순차적으로 RAID 구성 및 OS 재설치 진행후에 Partition을 Reassign 할 계획입니다.
Environment  CentOS 7.6 Cloudera CDH 6.1.1 Cloudera Manager Kafka 2.0.0-cdh6.1.1 Kafka Manager Kafka Broker 3대 Replication fector 3  HowTo Cloudera Manager 에서 작업대상 Broker 서버를 서비스에서 제거해요.</description>
    </item>
    
    <item>
      <title>Git</title>
      <link>https://hahafamilia.github.io/development/git/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/git/</guid>
      <description>Git 기본개념 파일상태  Committed : 커밋상태, git commit Modified : 수정상태 Staged : 커밋대기상태, git add  사용영역  Git directory(Local repository) : git init 으로 지정, .git 디렉토리가 생성 Working directory : branch 를 checkout 한 내용 Staging Area  환경설정  $GIT_HOME/[installed_path]/gitconfig : 시스템의 모든 사용자 설정, git config --system $USER_HOME : 특정 사용자 설정, git config --global .git/config : 특정 저장소 설정  Getting Started cd /your/project/home touch readme.</description>
    </item>
    
    <item>
      <title>Apache Hadoop 롤링 업그레이드 2.4.1 to 2.6.0</title>
      <link>https://hahafamilia.github.io/development/apache-hadoop-rollingupgrade-2.4-2.6/</link>
      <pubDate>Sun, 01 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/apache-hadoop-rollingupgrade-2.4-2.6/</guid>
      <description>예전 하둡 플랫폼으로 10PB(2 peplica) 의 컨텐츠를 운영했던 경험이 있는데요. Apache Hadoop 1.x 버전에서 2.2 버전으로 서비스 중단 업그레이드, 2.2 버전에서 2.4 버전으로 2.6 버전으로 무중단 업그레이드를 진행했었습니다. Apache Hadoop 2.4.1 버전에서 2.6.0 버전으로 Rolling Upgrade 진행했을때의 문서가 남아 있네요. 내용이 잘 정리되어 있진 않지만, 당시 작성내용을 우선 옮겨 두려고 합니다.
 네임노드 /data 디렉토리 백업 관리용 쉘 종료
/monitor/daemon_hdfs_status.sh	- 유지 /monitor/daemon_hdfs_balancer.sh	- 종료 /monitor/daemon_hdfs_namenode.sh	- 종료  2.6.0 설치(모든 노드에 설치하고, 환경설정을 이전버전과 동일하게 맞춥니다)</description>
    </item>
    
    <item>
      <title>Apache Hadoop 2.4 운영</title>
      <link>https://hahafamilia.github.io/development/apache-hadoop-2.4/</link>
      <pubDate>Sun, 01 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/apache-hadoop-2.4/</guid>
      <description>과거 하둡 플랫폼 운영 당시 메모 형식으로 작성하였던 문서들을 옮겨 놓았어요. 당시 운영했던 플랫폼의 구성들과 운영을 위한 가이드 들을 작성했었네요. Hadoop CLI Command 에 익숙하지 않은 운영/관리자를 위해 Shell 들도 개발해 놓았고, 나중의 담당자를 위한 배려도 담겨있네요.
Version  Apache Hadoop 2.4.1  Cluster 구성  Replication : 2 Block size : 128M Public / Private Neetwork 클러스터 상태 확인  http://[namenode-ip]:40070/dfsclusterhealth.jsp http://[namenode-ip]:40070/dfshealth.jsp   Nodes  Namenode * 2Ea Journalnode * 3Ea ZKFC * 3Ea Datanode  Namenode 하둡 메타데이터 저장/관리 노드 , Namenode, DFSZKFailoverController 데몬 실행</description>
    </item>
    
    <item>
      <title>Apache Hadoop 2.2 운영</title>
      <link>https://hahafamilia.github.io/development/apache-hadoop-2.2/</link>
      <pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/development/apache-hadoop-2.2/</guid>
      <description>과거 하둡 플랫폼 운영당시 메모 형식으로 작성하였던 문서들을 옮겨 놓았어요. 내용이 잘 정리되어 있진 않아도 다시 읽어보니 하둡 1.X 버전으로 플랫폼 운영중에 하둡 2.X 버전으로 업그레이드 하면서 테스트했던 내용들을 메모 했었네요. Federation, HA, fencing, Snapshot, Journalnode, Datanode 성능 등을 테스트 했었군요.
Federation 에 Namenode 추가 namenode01-02 서버가 HA 구성되어 있고 Federation 구성되어있을경우 namenode03-04 를 추가합니다.
 namenode03, namenode04 에서 core-site.xml hdfs-site.xml namespace 관련 설정을 추가 namenode03 의 네임노드를 기존 cluster id 로 포맷, bin/hdfs namenode -format -clusterId [clusterID] namespace의 zookeeper 초기화, namenode03 의 zkfc 시작</description>
    </item>
    
  </channel>
</rss>