<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Developement and Life Blog on haha family&#39;s happy blog</title>
    <link>https://hahafamilia.github.io/</link>
    <description>Recent content in Developement and Life Blog on haha family&#39;s happy blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Mon, 16 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hahafamilia.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>클러스터 네트워크 일시 장애로 인한 Kafka/Zookeeper 문제해결</title>
      <link>https://hahafamilia.github.io/bigdata/kafka-zookeeper-troubleshooting/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/kafka-zookeeper-troubleshooting/</guid>
      <description>장애알림으로 시작하는 상쾌한 월요일입니다? 빅데이터 플랫폼의 클러스터 일부 서버에서 경고 알림이 보고 되었어요. Cloudra Manager 의 서비스 리스트에는 Kafka 서비스에서 Lagging Replicas Test 실패 발생되었다고 경고를 보여주고 있네요. 이번 경우도 문제의 원인은 눈에 보이는 것과는 다르네요. 어떤 일이 있었던걸까요?
Version  Cloudera CDH 6.1.1 Cloudera Kafka 2.11-2.0.0-cdh6.1.1  현상파악 Cloudera Manager 확인 3대의 Kafka Broker 중에 01~02 서버에서 경고가보여지고, 03 서버는 정상으로 보여져요. 문제발생한 시간대에 Kafka 로부터 유입되는 데이터의 유실은 다행히 발생하지 않았어요.</description>
    </item>
    
    <item>
      <title>IntelliJ maven scala 프로젝트 설정</title>
      <link>https://hahafamilia.github.io/bigdata/intellij-maven-scala/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/intellij-maven-scala/</guid>
      <description>IntelliJ IDE 에서 spark streaming 개발을 위해 scala maven 프로젝트 생성 방법을 알아봐요. scala 프로젝트는 sbt 를 기본으로 사용하지만, maven 에 익숙하여 maven 으로 프로젝트를 생성해요. scala-archetype-simple 으로 프로젝트 생성이 가능한데, 제가 직접 구성하는게 좋아요.
Version  Spark 2.4.0 Scala 2.11 Hadoop 2.7 Java 8 Window  Spark, Hadoop 설치 Spark Download 에서 Spark 를 다운로드해요. 운영중인 클러스터의 스파크버전과 맞추어 2.4.0 버전의 Pre-built for Apache Hadoop2.7 을 다운로드 했어요. 다운로드한 파일을 압축해제 하고 SPARK_HOME 환경변수로 등록후 PATH 설정해요.</description>
    </item>
    
    <item>
      <title>Apache Pig Latin</title>
      <link>https://hahafamilia.github.io/bigdata/apache-piglatin/</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/apache-piglatin/</guid>
      <description>Apache Pig Yahoo 에서 공개한 걸로 알고 있어요. 최근 버전은 Hive on Spark 처럼 Pig on Spark 으로 사용하는군요. 새로운 Flow 코드 작성시 잘 사용하진 않지만, SQL 사용시 함수와 프로시져를 만들어야 하는 경우가 있는데, 그런 경우 Pig 를 사용하고 있어요. ASIS Flow 에서 사용되어지고 있는 코드 들이 있어서 간단히 문법에 대해 정리 해봐요.
Pig Latin Basic 연산자 및 명령어들은 대소문자를 구분하지만, 별칭 및 함수 이름은 대소문자를 구분해요.
Data types int, long, float, double, chararray, Bytearray, Boolean, Datetime, Biginteger, Bigdecimal, Tuple, Bag(collection of tuples), Map</description>
    </item>
    
    <item>
      <title>Cloudera CDH Configuration</title>
      <link>https://hahafamilia.github.io/bigdata/cloudera-cdh-configuration/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/cloudera-cdh-configuration/</guid>
      <description>Bigdata 플랫폼으로 Cloudera CDH 6.1.x 를 운영중 트러블슈팅과 설정에 대해 이야기 해볼게요.
Version  Cloudera CDH 6.1 Oracl Java 1.8  YARN Turning YARN YARN 의 리소스 관련 설정의 기본 값 Default Memory Setting
YARN 리소스 튜닝 방법 Turning YARN
노드의 전체 가용 리소스에서 서비스 데몬들의 리소스 사용량을 제하고 리소스를 할당 해요. 튜닝 문서와는 다르게 Cloudera Manager 에서 각 호스트들의 리소스 사용량은 상이해요. 튜닝 문서와 Cloudera Manager &amp;gt; Host &amp;gt; Worker &amp;gt; Resource 리소스 사용량을 참고하여 Yarn 에 할당할 CPU, Memory 를 결정한 후, 아래의 프로퍼티에 값을 설정해요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Project Build</title>
      <link>https://hahafamilia.github.io/bigdata/zeppelin-project-build/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/zeppelin-project-build/</guid>
      <description>Zeppelin 소스 코드를 빌드해봐요. 오픈소스 수정은 선호하진 않지만, Frontend 화면 수정은 필요할 것 같아요.
Personalized 기능이 필요한데 0.8.2 버전에서 Bug ZEPPELIN-3065 가 있어요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Versions  Zeppelin 0.8.2 Git Any Maven 3.1 or igher JDK 1.7 Mac, IntelliJ   제환경은 OpenJDK 1.8 이예요. 빌드는 잘 되요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin on CDH, Yarn</title>
      <link>https://hahafamilia.github.io/bigdata/zeppelin-on-cdh/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/zeppelin-on-cdh/</guid>
      <description>Apache Zeppelin 과 CDH 를 연동해요.
Yarn 리소스 매니저 관리하에 Spark 어플리케이션을 실행시킬 수 있어요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Version  Zeppelin 0.8.2 Cloudera CDH 6.1.x  Zeppelin Zeppelin on CDH 공식 문서를 참고해요.
설정 /conf/zeppelin-env.sh 파일을 수정해요. 설치 환경에 따라서 경로는 다를 수 있어요.
export MASTER=yarn-client export SPARK_HOME=&#39;/opt/cloudera/parcels/CDH/lib/spark` export HADOOP_CONF_DIR=&#39;etc/hadoop/conf&#39;  Cloudera Manager &amp;gt; Yarn &amp;gt; Application 목록에서 Zeppelin 이 실행중인걸 확인 할 수 있어요.</description>
    </item>
    
    <item>
      <title>FFMPEG를 이용해 음악 플레이리스트 동영상 만들기</title>
      <link>https://hahafamilia.github.io/howto/ffmpeg-music-youtube/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/howto/ffmpeg-music-youtube/</guid>
      <description>음원의 플레이리스트를 앨범 자켓 이미지를 포함시켜 동영상으로 만들 수 있나요? 라는 얘기를 듣게 되었어요. 의도는 Youtube 에는 음악등록을 할 수 없어서, 동영상으로 만들어서 업로드 해야된다고 하네요.
그래서 간단하게 프로토타입을 만들어 봤어요. FFMPEG 검색을 해보니 이러한 시도를 하는 분들이 꽤 있나 보군요.
프로토타입  하나의 음원을 이미지를 포함시켜 동영상으로 제작 각 동영상들을 이어 붙히기
ffmpeg -loop 1 -i Happy.jpg -i Happy.mp3 -shortest -acodec copy 2.mp4 ffmpeg -loop 1 -i StellaJang.jpg -i StellaJang.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Upgrade from 0.8.1 to 0.8.2</title>
      <link>https://hahafamilia.github.io/bigdata/zeppelin-upgrade-0.8.2/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/zeppelin-upgrade-0.8.2/</guid>
      <description>Apache Zeppelin 0.8.2 버전이 2019.11.29 일에 Release 되었어요. 0.8.1 버전에서 발견되었던 버그들도 수정이 되었으니 업그레이드를 진행 해보도록 할게요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Apache Zeppelin 0.8.2 Upgrading 문서를 보니 0.8.x 버전에서의 업그레이드는 conf 와 notebook 디렉토리를 복사해주기만 하면 된다고 하니 손쉽게 진행 될 것으로 예상되요.
업그레이드 Apache Zeppelin Download 다운로드 사이트에서 바이너리 파일을 다운로드 해서, 0.</description>
    </item>
    
    <item>
      <title>Cloudera CDH 6.1.1 설치하기</title>
      <link>https://hahafamilia.github.io/bigdata/cloudera-cdh-6_1-intall/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/cloudera-cdh-6_1-intall/</guid>
      <description>ASIS 플랫폼의 고도화 일환으로 빅데이터 플랫폼을 신규로 구축하게 되었어요. 구축과정의 일환인 Cloudera CDH 6.1.1 설치과정을 뒤늦게사나마 정리해볼게요. 설치를 진행하기 전에 플랫폼 아키텍처의 설계와 물리서버 사양의 선택, 랙 배치 등이 우선되었겠죠? 이것에 대해서는 또 정리하도록 할게요.
설치 과정은 크게 3단계로 진행되요.
 설치하기 전에 Cloudera Manager 설치 CDH 구성요소 설치  Cloudera CDH 6.1 버전의 공식 문서를 참고해서 진행했어요.
Cloudera Enterprise 6.1 Document
Cloudera Installation Guide
버전  CentOS 7.6.1810 Java 1.</description>
    </item>
    
    <item>
      <title>Kafka Manager 설치</title>
      <link>https://hahafamilia.github.io/bigdata/kafka-manager-installation/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/kafka-manager-installation/</guid>
      <description>KafkaManager 설치 Kafka Manager 를 설치해 볼게요. Kafka Manager 는 Yahoo 의 오픈소스 인데, Kafka 서비스의 상태를 확인하거나, Skew 등이 발생했을때 Reassign Partitoin 등을 할 수 있는 기능을 제공해줘요.
https://hahafamilia.github.io/bigdata/kafka-broker-reinstall/ Github 에서 다운로드 한 후, Scala 빌드 빌드툴 sbt 로 빌드 해줘요.
tar -xvzf kafka-manager-1.3.3.22.tar.gz cd kafka-manager-1.3.3.22 PATH=/usr/java/jdk1.8.0_141-cloudera/bin:$PATH JAVA_HOME=/usr/java/jdk1.8.0_141-cloudera \ ./sbt -java-home /usr/java/jdk1.8.0_141-cloudera clean dist cp target/universal/kafka-manager-1.3.3.22.zip /usr/local cd /usr/local unzip kafka-manager-1.3.3.22.zip  conf/application.conf 설정파일에 Zookeeper 호스트 주소를 설정해 줘요.</description>
    </item>
    
    <item>
      <title>스파크 완벽 가이드</title>
      <link>https://hahafamilia.github.io/book/%EC%8A%A4%ED%8C%8C%ED%81%AC%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/book/%EC%8A%A4%ED%8C%8C%ED%81%AC%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C/</guid>
      <description>스파크 창시자가 알려주는 스파크 활용과 배포, 유지 보수의 모든 것 오픈소스 클러스터 컴퓨팅 프레임워크인 스파크의 창시자가 쓴 스파크에 대한 종합 안내서입니다. 스파크 사용법부터 배포, 유지 보수하는 방법까지 포괄적으로 익힐 수 있습니다. 스파크 2의 개선점과 새로운 기능을 자세히 설명합니다. 구조화된 스파크 API의 특징과 공통 기능은 물론이고, 엔드 투 엔드 스트리밍 애플리케이션을 구축하는 새로운 고수준 API인 구조적 스트리밍을 함께 살펴봅니다. 이 책을 읽으면 스파크를 모니터링, 튜닝, 디버깅하는 데 필요한 기본 지식을 습득할 수 있습니다.</description>
    </item>
    
    <item>
      <title>필리핀 세부 마리바고 블루워터 여름휴가</title>
      <link>https://hahafamilia.github.io/life/travel-cebu-2019/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/life/travel-cebu-2019/</guid>
      <description>이번 여름 휴가는 필리핀 세부(Cebu) 막탄으로 다녀오게되었어요. 향공권, 마리바고 블루워터 리조트, 세부날씨, 그랩, 유심칩, 모닝글로리, 탑스그릴, 김떡순, 예스마트, 더테라스, 오스파, 플라워트리, 그랜드네일, 보노보노 구매대행, 그리고 브라질리언 왁싱 등의 여행을 준비하면서 다녀오고 나서의 후기를 간략히 남겨보려합니다.
2019년 09월, 필리핀 세부, 블루워터 마리바고 여름휴가 어른 2명, 5살 아이 1명, 돌된 아이 1명 이렇게 4인 가족의 9월 21 ~ 9월 26 일까지의 일정 이었어요. 가기전에 날씨 검색해보니 이틀 정도 소나기 예상이였는데, 여행 기간 중에 비가 오진 않았어요.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://hahafamilia.github.io/about/</link>
      <pubDate>Mon, 16 Sep 2019 15:26:00 +0900</pubDate>
      
      <guid>https://hahafamilia.github.io/about/</guid>
      <description>Juil Cho About Me 

Email octchristmas@naver.com
GitHub https://github.com/hahafamilia
이전 블로그 https://tjstory.tistory.com/</description>
    </item>
    
    <item>
      <title>휴고 설치 및 설정, Learn 테마, Hugo Website</title>
      <link>https://hahafamilia.github.io/howto/hugo-staticgen/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/howto/hugo-staticgen/</guid>
      <description>Jekyll 을 사용하다 이번에 Hugo 로 블로그를 이전하게 되었어요. Jekyll 과 Hugo 를 비교하는 글들이 많은데, 제 이유는 Category 관리가 Hugo 가 좀 더 직관적이여서 예요.
Hugo 를 설치하고 Learn Theme 를 적용하는 방법을 살펴볼게요. 또 Disqus 댓글, 검색어 노출을 위해 Google Analystics, Google Search, 네이버 웹마스터와 연동하는 방법, 초안(Draft) 작성을 위한 설정 등을 살펴 볼게요.
Environment &amp;amp; Requirement  Hugo Static Site Generator v0.57.2 Mac Git  Quick Start Install Mac 에서 Hugo Install Doc 따라서 설치는 쉽게 진행 가능해요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Interpreter, Hive, Impala</title>
      <link>https://hahafamilia.github.io/bigdata/zeppelin-interpreter/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/zeppelin-interpreter/</guid>
      <description>Apache Zeppelin 과 Cloudera CDH 의 Hive, Impala 를 연동하는 방법을 알아볼게요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1 Cloudera CDH 6.1.1 Hive 2.1.1 Impala 3.1.0 Impala JDBC Driver 2.6.12  Hive Zeppelin Hive Interpreter Document 문서를 보면 Jdbc Interpreter 를 사용하라고 되어있네요. 기본으로 PostgreSQL Connector 지원하고 그외는 Connector 는 추가를 해줘야 해요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin Usage</title>
      <link>https://hahafamilia.github.io/bigdata/zeppelin-usage/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/zeppelin-usage/</guid>
      <description>Apache Zeppelin 은 노트북 방식의 시각화 툴이예요.
Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.8.2   Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1  Dynamic Form Zeppelin 에서는 Dynamic Form 을 제공하고 있어서 Form 을 통해 입력받은 값으로 조건을 주는 형태로 사용 가능해요. Dynamic Form 은 Paragraph scope 와 Note scope 에서 사용 문법의 차이가 있고, 또한 Programmatically 하게 추가하실 수 있어요.</description>
    </item>
    
    <item>
      <title>Apache Zeppelin 설치, QuickStart</title>
      <link>https://hahafamilia.github.io/bigdata/zeppelin-quickstart/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/zeppelin-quickstart/</guid>
      <description>Apache Zeppelin 은 노트북 방식의 시각화 툴이예요. 다양한 시각화 툴이 존재하지만 &amp;lsquo;가장 좋은 것&amp;rsquo;이 아니라 &amp;lsquo;나에게 맞는 것&amp;rsquo; 을 선택했어요. 제가 Zeppelin을 선택한 이유는 아래와 같아요.
 설치와 사용법이 쉬워야 한다. 요구사항을 유연하게 처리 할 수 있어야 한다. BI 웹 어드민을 개발 하지 않아도 되도록 정적 HTML 을 제공해야 한다.  Zeppelin Posts  Zeppelin Install &amp;amp; QuickStart Zeppelin Usage Zeppelin interpreter Zeppelin on CDH Zeppelin Project Build Zeppelin Project Upgrade 0.</description>
    </item>
    
    <item>
      <title>Oozie Workflow Email 알림 설정</title>
      <link>https://hahafamilia.github.io/bigdata/oozie-workflow-email/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/oozie-workflow-email/</guid>
      <description>Oozie 에서 Workflow 의 결과에 따른 Email 알림을 받는 방법에 대해서 알아볼게요.
Workflow 를 1회성으로 실행시키는 경우와 Schedule 로 등록하여 주기적으로 실행하는 경우가 있을 수 있을텐데요. 1회성으로 Workflow 만 실행할때는 성공/실패에 대한 처리 결과를 받도록 하고, Schedule 로 등록하여 주기적으로 실행하는 경우에는 실패에 대한 알림 만을 받도록 합니다.
Version  Cloudera 6.1.1 Oozie 5.0.0 Hue 4.3.0  Oozie SMTP 설정 Cloudera Manager &amp;gt; Oozie &amp;gt; 구성 탭 에서 mail 을 검색해서, oozie.</description>
    </item>
    
    <item>
      <title>AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집</title>
      <link>https://hahafamilia.github.io/bigdata/spring-kafka-flume/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/spring-kafka-flume/</guid>
      <description>다음과 같은 데이터 파이프 라인을 가정해 볼게요.
 사용자의 Activity 이벤트가 발생 API 서버를 통해 Kafka 에 Produce Flume 을 통해 Kafka 의 메시지를 HDFS 로 적재 HDFS 에는 일자 별로 생성된 디렉토리에 저장  Flume 을 퉁한 데이터 수집시에 Hdfs Sink 는 useLocalTimestamp 설정은 제공 해요. 하지만 이 설정은 이벤트의 수집 시각을 기준으로 해요.
예제 그림에서 API 에서 시작된 데이터는 파이프라인을 거쳐 HDFS 에 도달하기까지 2초의 시간이 소요된다고 가정하면, 2019-08-01 23:59:59 시각에 발생한 이벤트는 useLocalTimestamp 설정에 의해 2019-08-02 00:00:01 의 시각으로 2019-08-02 디렉토리에 적재됩니다.</description>
    </item>
    
    <item>
      <title>Cloudera Manager 알람 설정, Gmail SMPT 서버 사용</title>
      <link>https://hahafamilia.github.io/bigdata/cloudera-alert-email/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/cloudera-alert-email/</guid>
      <description>Cloudera Manager 알림을 보내는 방법은 SMTP, SNMP, Custom Script 세가지를 제공하고 있어요. 여기서 SNMP, Custom Script 는 Enterprise 버전에서만 지원해요. 별도의 SMTP 서버를 운영하고 있지 않다면 Gmail 을 이용할 수 있어요.
Cloudera Version Cloudera 6.1
Gmail 설정 우선 Gmail 설정에서 IMAP 사용이 허용되어야 해요. 그리고 Google 계정 설정 &amp;gt; 보안 &amp;gt; 보안 수준이 낮은 앱의 액세스 가 허용되어야 합니다.
 이 방법은 보안상 권장하지 않는 방법 이예요. 하지만 제가 근무하는 회사의 G Suite 에서는 액세스키에 의한 접근 기능이 제공되고 있지 안아서 이 방법을 사용하고 있어요.</description>
    </item>
    
    <item>
      <title>Python 개발환경, Pyenv, Anaconda3</title>
      <link>https://hahafamilia.github.io/python/python-pyenv-anaconda-mac/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/python/python-pyenv-anaconda-mac/</guid>
      <description>Mac 에서 Homebrew 통해서 Python 가상화 환경을 구성하려고 합니다. 우선 Mac 버전이 모하비라면 모하비 brew error 글을 한번 읽어보세요.
Python 가상환경 구성방법은 여러가지가 있지만, pyenv/virtualenv 를 사용할거예요. 대략적인 과정은 pyenv 설치, anaconda3 설치, 가상환경 구성의 순서예요. pyenv 는 가상화 관리를 위해서 pyenv-virtual 패키지를 사용하는데, anaconda3 정도만 사요할 예정이면 설치 하지 않아요 되요.
pyenv brew help brew update brew install pyenv pyenv -v pyenv 1.2.13 pyenv install -list | grep anaconda .</description>
    </item>
    
    <item>
      <title>Hive Java UDF, 유니코드</title>
      <link>https://hahafamilia.github.io/bigdata/hive-java-udf/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/hive-java-udf/</guid>
      <description>개요 Cloudera Document 6.1 Hive UDF 문서를 참고하여 Cloudera CDH 플랫폼에서 HIVE UDF 를 작성하는 방법을 알아봅니다.
또한 MySQL의 Collate 와 문자열 유니코드에 대해서도 간단히 알아보겠습니다.
저의 이번 경우는 HIVE로 집계된 데이터를 SQOOP으로 export 시에 오류가 발생하였습니다.
기존에 설계된 MySQL 디비의 테이블 칼럼 Collate 속성이 utf8-general-ci 로 설계되어 있어 Key 칼럼에 Accent 문자열을 포함하는 문자열 데이터 자정시에 상황에 따라 키중복이 발생했던 것이었습니다.
칼럼의 Collate 속성이 utf8-general-ci 일경우 아래와 같은 경우 ã 문자열은 저장이 되겠지만 a 문자열 저장시 Key 중복 오류가 발생합니다.</description>
    </item>
    
    <item>
      <title>Kafka Broker 디스크 증설, RAID구성, OS 재설치</title>
      <link>https://hahafamilia.github.io/bigdata/kafka-broker-reinstall/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/bigdata/kafka-broker-reinstall/</guid>
      <description>Kafka Broker 재설치 Kafka Broker 서버의 디스크 용량을 증설하는 작업을 진행 하게 되었습니다. RAID 10으로 디스크 구성을 변경하다보니 불가피하게 OS를 재설치 합니다. Kafka는 Broker 서버의 장애 상황에서도 서비스를 유지 할 수 있도록 설계되어 있어요. Broker 서버를 1대씩 순차적으로 RAID 구성 및 OS 재설치 진행후에 Partition을 Reassign 할 계획입니다.
Environment  CentOS 7.6 Cloudera CDH 6.1.1 Cloudera Manager Kafka 2.0.0-cdh6.1.1 Kafka Manager Kafka Broker 3대 Replication fector 3  HowTo Cloudera Manager 에서 작업대상 Broker 서버를 서비스에서 제거해요.</description>
    </item>
    
    <item>
      <title>Markdown 작성법</title>
      <link>https://hahafamilia.github.io/howto/markdown/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/howto/markdown/</guid>
      <description># header ## header ### header #### header ##### header ###### header  header header header header header header *** --- ===  ===
# header ## header ### header #### header ##### header ###### header  header header header header header header 1. List 1. List 1. Sub List 1. List  * List * List * List * List - List + List   List  List  List   List List List</description>
    </item>
    
    <item>
      <title>하이브 핵심 정리, Apache Hive Essentials</title>
      <link>https://hahafamilia.github.io/book/%ED%95%98%EC%9D%B4%EB%B8%8C-%ED%95%B5%EC%8B%AC%EC%A0%95%EB%A6%AC/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/book/%ED%95%98%EC%9D%B4%EB%B8%8C-%ED%95%B5%EC%8B%AC%EC%A0%95%EB%A6%AC/</guid>
      <description>하둡 기반 대용량 데이터 저장, 관리의 핵심 솔루션 라는 부제를 가지고 있는 이 책에서는 HIVE(1.0.0) 에 대해서 설명하고, HQL, 성능, 보안, 다른 툴과의 연동에 대해서 설명하고 있어요.
교보문고 링크
출판  저자 : 다융 두, 김용환 옮김 출판사 : 에이콘출판 출간일 : 2017.02.28  목차  1장. 빅데이터와 하이브 소개 2장. 하이브 환경 설정 3장. 데이터 정의와 설명 4장. 데이터 선택과 범위 5장. 데이터 조작 6장. 데이터 집계와 샘플링 7장.</description>
    </item>
    
    <item>
      <title>카프카, 데이터 플랫폼의 최강자</title>
      <link>https://hahafamilia.github.io/book/%EC%B9%B4%ED%94%84%EC%B9%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%8C%EB%9E%AB%ED%8F%BC%EC%9D%98-%EC%B5%9C%EA%B0%95%EC%9E%90/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/book/%EC%B9%B4%ED%94%84%EC%B9%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%8C%EB%9E%AB%ED%8F%BC%EC%9D%98-%EC%B5%9C%EA%B0%95%EC%9E%90/</guid>
      <description>실시간 비동기 스트리밍 솔루션 Kafka의 기본부터 확장 응용까지 라는 부제를 가지고 있는 이 책에서는 카프카 메시지 큐(버전 1.0.0)의 컨슈머, 프로듀서, 주키퍼, 카프카 모니터링, 카프카 매니저 등의 개념과 운영에 대해서 설명하고, 확장하여 카프카 스트림즈 API, 카프카SQL, 파일비트, 나이파이, 키반, 엘라스틱서치, 구글 펍/섭, 아마존 키네시스, 도커 등의 키워드를 설명하고 있어요.
교보문고 링크
출판  저자 : 고승범, 공용준 출판사 : 책만 출간일 : 2018.04.26  목차  1부 카프카를 시작하며  1장 카프카란 무엇인가 2장 카프카와 주키퍼 설치  2부 기본 개념과 운영 가이드  카프카 디자인 카프카 프로듀서 카프카 컨슈머 카프카 운영 가이드  3부 카프카의 확장과 응용  카프카를 활용한 데이터 파이프라인 구축 카프카 스트림즈 API 카프카 SQL을 이용한 스트리밍 처리 그 밖의 클라우드 기반 메시징 서비스  부록 도커를 이용한 카프카 설치  개인평 빅데이터 플랫폼 고도화 과정의 일환으로 RabbitMQ 3.</description>
    </item>
    
    <item>
      <title>모든 주식을 소유하라</title>
      <link>https://hahafamilia.github.io/book/%EB%AA%A8%EB%93%A0%EC%A3%BC%EC%8B%9D%EC%9D%84%EC%86%8C%EC%9C%A0%ED%95%98%EB%9D%BC/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/book/%EB%AA%A8%EB%93%A0%EC%A3%BC%EC%8B%9D%EC%9D%84%EC%86%8C%EC%9C%A0%ED%95%98%EB%9D%BC/</guid>
      <description>Description 세계 4대 투자의 거장, 존 보글의 투자 법칙.
2015년 워렌 버핏이 주주들에게 주천한 책!
교보문고
우화, 고트락스 가문 고트락스라는 부자 가문이 여러 대에 걸쳐 번창하여 형제, 자매, 삼촌, 사촌이 수천명이나 되었고, 미국의 모든 주식을 100% 소유하게 되었다. 얼마 후 브로커가 나타나서 다른 친척들보다 돈을 더 많이 벌 수 있는 방법이 있다고 속삭였다. 브로커들은 친척에게 보유 주식을 사고 팔게 했다. 브로커들은 대가로 수수료를 받고, 가문 사람들은 주식을 거래하는데 발생하는 자본이득에 대해서도 세금을 내야 했다.</description>
    </item>
    
    <item>
      <title>Jekyll, Github.io, Minimal mistakes 블로그 만들기, 목차 한글링크 버그</title>
      <link>https://hahafamilia.github.io/howto/jekyll-github-mistakes-blog/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/howto/jekyll-github-mistakes-blog/</guid>
      <description>개발자 초창기에는 블로그(이전의 블로그) 활동도 열심히 했었는데&amp;hellip; 너무 잊고 살았었네요. 새롭게 블로그를 시작 할 생각에 Jekyll, Github.io 로 블로그를 구성하게 되었어요.
간단히 Jekyll 은 정적파일 생성기, Github.io 는 호스팅, Minimal mistakes 는 수많은 Jekyll 테마중의 하나예요.
선택의 기준은 markdown 에디터 때문이에요. 개발자는 에디터 툴을 가장 많이 다루는데요. 아무래도 markdown 으로 글을 작성하고 Git 으로 Push 하여 포스팅을 하는 구조라면 블로그 활동량이 많아지지 않을까 합니다.
그럼 Github.io, Jekyll, Minimal mistakes theme 를 이용해 블로그를 만들어 봐요.</description>
    </item>
    
    <item>
      <title>Git</title>
      <link>https://hahafamilia.github.io/howto/git/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/howto/git/</guid>
      <description>Git 기본개념 파일상태  Committed : 커밋상태, git commit Modified : 수정상태 Staged : 커밋대기상태, git add  사용영역  Git directory(Local repository) : git init 으로 지정, .git 디렉토리가 생성 Working directory : branch 를 checkout 한 내용 Staging Area  환경설정  $GIT_HOME/[installed_path]/gitconfig : 시스템의 모든 사용자 설정, git config --system $USER_HOME : 특정 사용자 설정, git config --global .git/config : 특정 저장소 설정  Getting Started cd /your/project/home touch readme.</description>
    </item>
    
    <item>
      <title>하둡 애플리케이션 아키텍처</title>
      <link>https://hahafamilia.github.io/book/%ED%95%98%EB%91%A1-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://hahafamilia.github.io/book/%ED%95%98%EB%91%A1-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/</guid>
      <description>하둡 에코시스템을 활용한 빅데이터 처리 라는 부제을 가지고 있는 이 책에서는 HDFS/HBASE 스키마 디자인, 데이터 파이프라인, 맵리듀스, 스파크, 피크, 크런치, 하이브, ETL, 스트리밍, 근접 실시간, 데이터 웨어하우스, 사례연구 등 데이터의 수집에서 분석까지의 빅데이터 아키텍처에 대해 설명하고 있어요.
교보문고 링크
출간  저자 : 마크 그로버, 테드 멀래스커, 조나단 사이드먼, 그웬 사피라 옮김 : 정동식, 홍다경, 우지현 출판사 : 비제이퍼블릭 출간일 : 2016.05.30  목차  1부. 하둡 애플리케이션의 아키텍처 고려사항  1장.</description>
    </item>
    
  </channel>
</rss>