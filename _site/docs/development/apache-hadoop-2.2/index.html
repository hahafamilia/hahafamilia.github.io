<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-145448356-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-145448356-1', { 'anonymize_ip': true }); </script> <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Apache Hadoop 2.2 운영 | HAHAFAM</title><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Apache Hadoop 2.2 운영" /><meta property="og:locale" content="en_US" /><meta name="description" content="hahafamilia" /><meta property="og:description" content="hahafamilia" /><link rel="canonical" href="http://localhost:4000/docs/development/apache-hadoop-2.2/" /><meta property="og:url" content="http://localhost:4000/docs/development/apache-hadoop-2.2/" /><meta property="og:site_name" content="HAHAFAM" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Apache Hadoop 2.2 운영" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"hahafamilia","headline":"Apache Hadoop 2.2 운영","url":"http://localhost:4000/docs/development/apache-hadoop-2.2/"}</script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> HAHAFAM </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="http://localhost:4000/docs/configuration/" class="nav-list-link">Configuration</a><li class="nav-list-item"><a href="http://localhost:4000/docs/customization/" class="nav-list-link">Customization</a><li class="nav-list-item"><a href="http://localhost:4000/about/" class="nav-list-link">About</a><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/book/" class="nav-list-link">book</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%EB%AA%A8%EB%93%A0%EC%A3%BC%EC%8B%9D%EC%9D%84%EC%86%8C%EC%9C%A0%ED%95%98%EB%9D%BC/" class="nav-list-link" style="font-size: small !important">모든 주식을 소유하라</a><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%EB%B3%B4%EB%8F%84%EC%84%80%ED%8D%BC%EC%9D%98%EB%8F%88/" class="nav-list-link" style="font-size: small !important">보도섀퍼의돈</a><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%EC%8A%A4%ED%8C%8C%ED%81%AC%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C/" class="nav-list-link" style="font-size: small !important">스파크 완벽 가이드</a><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%EC%9D%B4%EC%9B%83%EC%A7%91%EB%B0%B1%EB%A7%8C%EC%9E%A5%EC%9E%90-%EB%B3%80%ED%95%98%EC%A7%80%EC%95%8A%EB%8A%94%EB%B6%80%EC%9D%98%EB%B2%95%EC%B9%99/" class="nav-list-link" style="font-size: small !important">이웃집백만장자 변하지않는부의법칙</a><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%EC%B9%B4%ED%94%84%EC%B9%B4%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%94%8C%EB%9E%AB%ED%8F%BC%EC%9D%98%20%EC%B5%9C%EA%B0%95%EC%9E%90/" class="nav-list-link" style="font-size: small !important">카프카, 데이터 플랫폼의 최강자</a><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%ED%95%98%EB%91%A1%20%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/" class="nav-list-link" style="font-size: small !important">하둡 애플리케이션 아키텍처</a><li class="nav-list-item "><a href="http://localhost:4000/docs/book/%ED%95%98%EC%9D%B4%EB%B8%8C%20%ED%95%B5%EC%8B%AC%EC%A0%95%EB%A6%AC/" class="nav-list-link" style="font-size: small !important">하이브 핵심 정리, Apache Hive Essentials</a></ul><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/development/" class="nav-list-link">development</a><ul class="nav-list "><li class="nav-list-item active"><a href="http://localhost:4000/docs/development/apache-hadoop-2.2/" class="nav-list-link active" style="font-size: small !important">Apache Hadoop 2.2 운영</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/apache-hadoop-2.4/" class="nav-list-link" style="font-size: small !important">Apache Hadoop 2.4 운영</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/apache-hadoop-rollingupgrade-2.4-2.6/" class="nav-list-link" style="font-size: small !important">Apache Hadoop 롤링 업그레이드 2.4.1 to 2.6.0</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/apache-piglatin/" class="nav-list-link" style="font-size: small !important">Apache Pig Latin</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zeppelin-interpreter/" class="nav-list-link" style="font-size: small !important">Apache Zeppelin Interpreter, Hive, Impala</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zeppelin-project-build/" class="nav-list-link" style="font-size: small !important">Apache Zeppelin Project Build</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zeppelin-upgrade-0.8.2/" class="nav-list-link" style="font-size: small !important">Apache Zeppelin Upgrade from 0.8.1 to 0.8.2</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zeppelin-usage/" class="nav-list-link" style="font-size: small !important">Apache Zeppelin Usage</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zeppelin-on-cdh/" class="nav-list-link" style="font-size: small !important">Apache Zeppelin on CDH, Yarn</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zeppelin-quickstart/" class="nav-list-link" style="font-size: small !important">Apache Zeppelin 설치, QuickStart</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/spring-kafka-flume/" class="nav-list-link" style="font-size: small !important">AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/cloudera-cdh-6_1-intall/" class="nav-list-link" style="font-size: small !important">Cloudera CDH 6.1.1 설치하기</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/cloudera-cdh-configuration/" class="nav-list-link" style="font-size: small !important">Cloudera CDH Configuration</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/cloudera-alert-email/" class="nav-list-link" style="font-size: small !important">Cloudera Manager 알람 설정, Gmail SMPT 서버 사용</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/ffmpeg-music-youtube/" class="nav-list-link" style="font-size: small !important">FFMPEG를 이용해 음악 플레이리스트 동영상 만들기</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/git/" class="nav-list-link" style="font-size: small !important">Git</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/hive-java-udf/" class="nav-list-link" style="font-size: small !important">Hive Java UDF, 유니코드</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/intellij-maven-scala/" class="nav-list-link" style="font-size: small !important">IntelliJ maven scala 프로젝트 설정</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/kafka-broker-reinstall/" class="nav-list-link" style="font-size: small !important">Kafka Broker 디스크 증설, RAID구성, OS 재설치</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/kafka-manager-installation/" class="nav-list-link" style="font-size: small !important">Kafka Manager 설치</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/memcache-install-management/" class="nav-list-link" style="font-size: small !important">Memcache 개념과 설치 / 운영</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/oozie-workflow-email/" class="nav-list-link" style="font-size: small !important">Oozie Workflow Email 알림 설정</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/presto-installation/" class="nav-list-link" style="font-size: small !important">Presto 설치, PrestoDB, PrestoSQL</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/python-pyenv-anaconda-mac/" class="nav-list-link" style="font-size: small !important">Python 개발환경, Pyenv, Anaconda3</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/zabbix-install-memo/" class="nav-list-link" style="font-size: small !important">Zabbix 모니터링 메모</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/machine-learning-spark-guide/" class="nav-list-link" style="font-size: small !important">고급 분석과 머신러닝 개요</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/kafka-zookeeper-troubleshooting/" class="nav-list-link" style="font-size: small !important">클러스터 네트워크 일시 장애로 인한 Kafka/Zookeeper 문제해결</a><li class="nav-list-item "><a href="http://localhost:4000/docs/development/hbase-troubleshooting/" class="nav-list-link" style="font-size: small !important">할아버지 클러스터의 엉망진창 HBase 문제해결</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/howto/" class="nav-list-link">howto</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/howto/jekyll-github-mistakes-blog/" class="nav-list-link" style="font-size: small !important">Jekyll, Github.io, Minimal mistakes 블로그 만들기, 목차 한글링크 버그</a><li class="nav-list-item "><a href="http://localhost:4000/docs/howto/markdown/" class="nav-list-link" style="font-size: small !important">Markdown 작성법</a><li class="nav-list-item "><a href="http://localhost:4000/docs/howto/hugo-staticgen/" class="nav-list-link" style="font-size: small !important">휴고 설치 및 설정, Learn 테마, Hugo Website</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/life/" class="nav-list-link">life</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/life/travel-cebu-2019/" class="nav-list-link" style="font-size: small !important">필리핀 세부 마리바고 블루워터 여름휴가</a></ul></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search HAHAFAM" aria-label="Search HAHAFAM" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="//github.com/hahafamilia" class="site-button" > hahafamilia on GitHub </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/development/">development</a><li class="breadcrumb-nav-list-item"><span>Apache Hadoop 2.2 운영</span></ol></nav><div id="main-content" class="main-content" role="main"><p>과거 하둡 플랫폼 운영당시 메모 형식으로 작성하였던 문서들을 옮겨 놓았어요. 내용이 잘 정리되어 있진 않아도 다시 읽어보니 하둡 1.X 버전으로 플랫폼 운영중에 하둡 2.X 버전으로 업그레이드 하면서 테스트했던 내용들을 메모 했었네요. Federation, HA, fencing, Snapshot, Journalnode, Datanode 성능 등을 테스트 했었군요.</p><h3 id="federation-에-namenode-추가"> <a href="#federation-에-namenode-추가" class="anchor-heading" aria-labelledby="federation-에-namenode-추가"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Federation 에 Namenode 추가</h3><p>namenode01-02 서버가 HA 구성되어 있고 Federation 구성되어있을경우 namenode03-04 를 추가합니다.</p><ol><li>namenode03, namenode04 에서 <code class="language-plaintext highlighter-rouge">core-site.xml hdfs-site.xml</code> namespace 관련 설정을 추가<li>namenode03 의 네임노드를 기존 cluster id 로 포맷, <code class="language-plaintext highlighter-rouge">bin/hdfs namenode -format -clusterId [clusterID]</code><li>namespace의 zookeeper 초기화, namenode03 의 zkfc 시작<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ bin/hdfs zkfc -formatZK	
$ sbin/hadoop-daemon.sh start zkfc
## 확인
$ zookeeper01:/[hadoop-home]/bin/zkCli.sh -server zookeeper01:2181
$ ls /hadoop-ha
</code></pre></div></div><li>namenode03 의 namenode 시작, <code class="language-plaintext highlighter-rouge">sbin/hadoop-daemon.sh start namenode</code><li>namenode04 의 네임노드 초기화, <code class="language-plaintext highlighter-rouge">bin/hdfs namenode -bootstrapStandby</code><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>14/07/09 15:09:33 INFO namenode.TransferFsImage: Opening connection to http://namenode194:40070/imagetransfer?getimage=1&amp;txid=16440263&amp;storageInfo=-56:239138164:1404883838982:CID-clusterID
</code></pre></div></div><li>namenode04 의 namenode 시작, zkfc 시작<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sbin/hadoop-daemon.sh start zkfc
$ sbin/hadoop-daemon.sh start namenode
</code></pre></div></div><li>datanode01 에서 namespace 관련 설정추가<li>namenode03 에서 datanode01 의 정보 업데이트 명령 수행<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ bin/hdfs dfsadmin -refreshNamenodes datanode01:50020
</code></pre></div></div><li>모든 datanode 에서 작업 수행</ol><h3 id="ha-기능-테스트"> <a href="#ha-기능-테스트" class="anchor-heading" aria-labelledby="ha-기능-테스트"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> HA 기능 테스트</h3><h4 id="hdfsfilesystem-라이브러리에서-configuration-값을-통해-hdfs-에-읽기쓰기-요청을-보낼때-어떤일이-일어날까"> <a href="#hdfsfilesystem-라이브러리에서-configuration-값을-통해-hdfs-에-읽기쓰기-요청을-보낼때-어떤일이-일어날까" class="anchor-heading" aria-labelledby="hdfsfilesystem-라이브러리에서-configuration-값을-통해-hdfs-에-읽기쓰기-요청을-보낼때-어떤일이-일어날까"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> HdfsFilesystem 라이브러리에서 Configuration 값을 통해 HDFS 에 읽기/쓰기 요청을 보낼때 어떤일이 일어날까?</h4><p>네임노드 접근시에 IPC 요청은 active/standby 2개의 서버로 요청되어 집니다. standby 로의 요청은 실패되어지고, 재시도 되지 않는다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2014-03-10 15:41:35,010 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020 , call org.apache.hadoop.hdfs.protocol.ClientProtocol.create from standby-nn.example.com:8928 Call#0 Retry#0: error: org.apache.hadoop.ipc.StandbyException: Operation category WRITE is not supported in state standby
</code></pre></div></div><h4 id="자동장애복구---autofailover"> <a href="#자동장애복구---autofailover" class="anchor-heading" aria-labelledby="자동장애복구---autofailover"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 자동장애복구 - autofailover</h4><ol><li>nn1-active, nn2-standby 상태에서 nn1 을 리부팅<li>nn2 번은 nn1번의 장애를 인지하고 ssh 펜싱을 시도하지만 ssh 원격접속을 하지 못해 active 상태로의 전환 실패<li>nn1 번이 재부팅 완료되면, ssh 펜싱 성공하고 active 상태로 전환<li>nn1 번의 하둡 데몬은 모두다 종료된 상태로, 서비스노드의 파일 접근이 있을경우 nn2 의 로그에 nn1 번으로의 연결 시도 로그가 계속 보입니다.<li>nn1 이 재부팅 되는동안 서비스노드로부터의 액세스는 대기 상태로 빠집니다.<li>다운타임이 짧을경우 하둡으로의 요청은 타임아웃되지 않고 nn2의 active 전환이 완료된후 하둡으로의 요청도 이어서 계속 되었다.<li>타임아웃 되는데 소요된 시간( 약 2분 10초 ), 14/03/10 18:51:24 ~ 14/03/10 18:53:35</ol><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>14/03/10 18:51:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/03/10 18:53:35 WARN retry.RetryInvocationHandler: Exception while invoking class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo. Not retrying because failovers (15) exceeded maximum allowed (15)
</code></pre></div></div><h4 id="자동장애복구에서-fencing"> <a href="#자동장애복구에서-fencing" class="anchor-heading" aria-labelledby="자동장애복구에서-fencing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 자동장애복구에서 fencing</h4><ul><li>fenching 로직을 통과하지 못할경우 standby 가 active로 올라오지 않습니다. <code class="language-plaintext highlighter-rouge">hdfs haadmin -failover | transitionToActive </code> 등의 명령어 들도 통하지 않는다.<li>이럴경우 <code class="language-plaintext highlighter-rouge">dfs.ha.automatic-failover.enabled (false)</code> 옵션을 끄고 <code class="language-plaintext highlighter-rouge">bin/hdfs haadmin -ns mycluster -transitionToActive nn1</code> active 전환을 시도합니다.<li>쉘 팬싱을 적용할경우, 팬싱이 실패되면 반복적으로 재시도 된다.<li>팬싱이 실패되는 상황에서 액티브 노드가 정상화 되면, standby - standby 상태가 된다.<li>이럴경우 팬싱쉘에서 강제적으로 exit 0 으로 줄경우 standby 를 액티브로 전환이 가능하다.<li>2번 팬싱실패 재시도중 &gt; 1번 정상화 네임노드실행 &gt; standby - standby &gt; 페일오버 명령어로 1번 정상화<li>1번 노드가 정상화 되면, 팬싱에 실패되더라도 2번 노드가 액티브로 올라옵니다.<li>standby - standy 상황에서 상대편 노드로의 연결을 계속 실행하면서 실행도중 아래와 같은 에러발생 합니다. 2개의 노드가 모두 연결될때만 메타 파일에 액세스 할 수 있도록 설계 된 것으로 보입니다.</ul><div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN 
</code></pre></div></div><h3 id="snaphost"> <a href="#snaphost" class="anchor-heading" aria-labelledby="snaphost"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Snaphost</h3><ul><li>스냅샷 생성은 빠릅니다. 아이 노드 조회 시간을 제외하고, 비용은 O (1)<li>수정이 스냅샷을 기준으로 한 ​​경우 추가 메모리에만 사용됩니다. 메모리 사용량은 O (M) , M은 수정 된 파일 / 디렉토리의 수입니다.<li>데이타 노드에 블록은 복사되지 않습니다. 스냅샷 파일은 차단 목록과 파일 크기를 기록한다. 데이터 복사가 없습니다.<li>스냅샷에 악영향을 정기적으로 HDFS 작업에 영향을 미치지 않습니다.<li>현재의 데이터에 직접 액세스 할 수 있도록 수정은 시간 역순으로 기록됩니다.<li>스냅샷 데이터는 전류 데이터로부터 변형을 감산함으로써 계산된다.<li>디렉토리의 스냅샷 사용 허락, <code class="language-plaintext highlighter-rouge">bin/hdfs dfsadmin -allowSnapshot /</code><li>디렉토리의 스냅샷 사용 차단, <code class="language-plaintext highlighter-rouge">bin/hdfs dfsadmin -disallowSnapshot /</code><li>스냅샷 생성, <code class="language-plaintext highlighter-rouge">bin/hdfs dfs -createSnapshot / snap1</code><li>스냅샷 삭제, <code class="language-plaintext highlighter-rouge">bin/hdfs dfs -deleteSnapshot /directory snap1</code><li>스냅샷 허용된 디렉토리, <code class="language-plaintext highlighter-rouge">bin/hdfs lsSnapshottableDir</code><li>스냅샷 간의 변화 추이, <code class="language-plaintext highlighter-rouge">bin/hdfs snapshotDiff /directory snap1 snap2</code><li>스냅샷 위치, <code class="language-plaintext highlighter-rouge">bin/hdfs dfs -ls /.snapshot/snap1</code></ul><h4 id="snapshot-테스트"> <a href="#snapshot-테스트" class="anchor-heading" aria-labelledby="snapshot-테스트"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Snapshot 테스트</h4><ol><li>t1.txt 파일생성 &gt; snap1 생성<li>t1.txt 파일변경 &gt; snap2 생성<li>t1.txt 파일변경 &gt; snap3 생성</ol><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bin/hdfs fsck /tmp -files -blocks -locations
bin/hdfs fsck /tmp/.snapshot/snap1/t1.txt -files -blocks -locations
</code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># file #1, version 1.0
BP-876852240-myip.108-1404457930723:blk_1073777524_36701 len=12 repl=2 [myip.118:40010, myip.114:40010]
BP-876852240-myip.108-1404457930723:blk_1073777524_36701 len=12 repl=2 [myip.118:40010, myip.114:40010]
# file #2, version 2.0
BP-876852240-myip.108-1404457930723:blk_1073777525_36702 len=12 repl=2 [myip.114:40010, myip.118:40010]
BP-876852240-myip.108-1404457930723:blk_1073777525_36702 len=12 repl=2 [myip.114:40010, myip.118:40010]
# file #3, version 3.0
BP-876852240-myip.108-1404457930723:blk_1073777526_36703 len=12 repl=2 [myip.118:40010, myip.115:40010]
BP-876852240-myip.108-1404457930723:blk_1073777526_36703 len=12 repl=2 [myip.118:40010, myip.115:40010]
</code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># file #2 복원, version 2.0
BP-876852240-myip.108-1404457930723:blk_1073777527_36704 len=12 repl=2 [myip.114:40010, myip.117:40010]
</code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># file #1 복원, version 1.0
BP-876852240-myip.108-1404457930723:blk_1073777528_36705 len=12 repl=2 [myip.116:40010, myip.118:40010]
</code></pre></div></div><h3 id="datanode-xceiver-테스트"> <a href="#datanode-xceiver-테스트" class="anchor-heading" aria-labelledby="datanode-xceiver-테스트"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Datanode Xceiver 테스트</h3><p>Datanode의 <code class="language-plaintext highlighter-rouge">dfs.datanode.max.xcievers</code> 는 동시 data connection 의 수입니다.</p><h4 id="테스트-환경"> <a href="#테스트-환경" class="anchor-heading" aria-labelledby="테스트-환경"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 테스트 환경</h4><ul><li>Datanode 1번 2번 에 각 xceiver 를 2개로 설정함.<li>클라이언트에서 요청 하는 블럭은 1번, 2번 DN이 모두 가지고 있음.</ul><h4 id="테스트-결과"> <a href="#테스트-결과" class="anchor-heading" aria-labelledby="테스트-결과"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 테스트 결과</h4><ul><li>5개의 클라이언트 연결 시도시, 1번 노드에서 2개의 연결은 성공하고, 3개의 연결은 실패한다.<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>13/11/12 14:25:08 WARN hdfs.DFSClient: Failed to connect to /myip.13:40010, add to deadNodes and continuejava.io.EOFException
13/11/12 14:25:08 WARN hdfs.DFSClient: Failed to connect to /myip.13:40010, add to deadNodes and continuejava.io.EOFException
13/11/12 14:25:08 WARN hdfs.DFSClient: Failed to connect to /myip.13:40010, add to deadNodes and continuejava.io.EOFException
</code></pre></div></div><li>실패한 3개의 클라이언트는 2번 노드로 3개의 연결을 시도하고, 1개의 연결은 실패한다.<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>13/11/12 14:25:08 WARN hdfs.DFSClient: Failed to connect to /myip.11:40010, add to deadNodes and continuejava.io.EOFException
</code></pre></div></div><li>실패한 1개의 연결은 네임노드로 블럭에 대한 노드정보를 3초간격으로 3회 재요청하고, 실패로 빠진다. ``` 13/11/12 14:25:08 INFO hdfs.DFSClient: Could not obtain block blk_-8368207181666867791_1294 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry… 13/11/12 14:25:11 WARN hdfs.DFSClient: Failed to connect to /myip.13:40010, add to deadNodes and continuejava.io.EOFException 13/11/12 14:25:11 WARN hdfs.DFSClient: Failed to connect to /myip.11:40010, add to deadNodes and continuejava.io.EOFException</ul><p>13/11/12 14:25:11 INFO hdfs.DFSClient: Could not obtain block blk_-8368207181666867791_1294 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry… 13/11/12 14:25:14 WARN hdfs.DFSClient: Failed to connect to /myip.13:40010, add to deadNodes and continuejava.io.EOFException 13/11/12 14:25:14 WARN hdfs.DFSClient: Failed to connect to /myip.11:40010, add to deadNodes and continuejava.io.EOFException</p><p>13/11/12 14:25:14 INFO hdfs.DFSClient: Could not obtain block blk_-8368207181666867791_1294 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry… 13/11/12 14:25:17 WARN hdfs.DFSClient: Failed to connect to /myip.13:40010, add to deadNodes and continuejava.io.EOFException 13/11/12 14:25:17 WARN hdfs.DFSClient: Failed to connect to /myip.11:40010, add to deadNodes and continuejava.io.EOFException</p><p>13/11/12 14:25:17 WARN hdfs.DFSClient: DFS Read: java.io.IOException: Could not obtain block: blk_-8368207181666867791_1294 file=/hdfs/path/filename at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:2426) at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:2218) at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2381) at java.io.DataInputStream.read(DataInputStream.java:83) at tsetThread.run(testThread.java:39) ```</p><h3 id="journalnode-서버-변경"> <a href="#journalnode-서버-변경" class="anchor-heading" aria-labelledby="journalnode-서버-변경"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> JournalNode 서버 변경</h3><p>Journalnode는 active 상태가 되는 네임노드에 epoch number 를 할당합니다. epoch number 확인은 active 전환하고 <code class="language-plaintext highlighter-rouge">path/current/last-promised-epoch, path/current/last-writer-epoch</code> 파일 내용을 학인할 수 있습니다.</p><h4 id="저널노드-서버-이동"> <a href="#저널노드-서버-이동" class="anchor-heading" aria-labelledby="저널노드-서버-이동"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 저널노드 서버 이동</h4><ol><li>기존 저널 다운<li>새로운 저널노드 업<li>기존 저널의 저장 데이터 를 새로운 저널노드로 옮김<li>새로운 저널 재시작<li>standby 네임노드 재시작<li>새로운 저널노드 epoch number 업데이트</ol><h3 id="설정들"> <a href="#설정들" class="anchor-heading" aria-labelledby="설정들"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 설정들</h3><h4 id="core-sitexml"> <a href="#core-sitexml" class="anchor-heading" aria-labelledby="core-sitexml"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> core-site.xml</h4><ul><li>fs.trash.interval<li>io.file.buffer.size</ul><h4 id="hdfs-sitexml"> <a href="#hdfs-sitexml" class="anchor-heading" aria-labelledby="hdfs-sitexml"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> hdfs-site.xml</h4><ul><li>dfs.namenode.handler.count<li>dfs.datanode.handler.count<li>dfs.datanode.max.transfer.threads<li>dfs.datanode.socket.write.timeout<li>dfs.socket.timeout<li>dfs.datanode.du.reserved<li>dfs.datanode.scan.preiod.hour</ul><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2017-2020 Patrick Marsceill. Distributed by an <a href="https://github.com/just-the-docs/just-the-docs/tree/main/LICENSE.txt">MIT license.</a></p><div class="d-flex mt-2"><p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/hahafamilia/hahafamilia.github.io/tree/main/docs/development/apache-hadoop-2.2.md" id="edit-this-page">Edit this page on GitHub</a></p></div></footer></div></div><div class="search-overlay"></div></div>
