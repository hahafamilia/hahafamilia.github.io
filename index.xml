<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Content on Hi Hugo</title>
    <link>http://hahafamilia.github.io/</link>
    <description>Recent content in Content on Hi Hugo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://hahafamilia.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About Me</title>
      <link>http://hahafamilia.github.io/about/</link>
      <pubDate>Mon, 16 Sep 2019 15:26:00 +0900</pubDate>
      
      <guid>http://hahafamilia.github.io/about/</guid>
      <description>Author Hahafamilia</description>
    </item>
    
    <item>
      <title>빅데이터 시각화, Zeppelin Interpreter, Hive, Impala</title>
      <link>http://hahafamilia.github.io/developement/bigdata/zeppelin-interpreter/</link>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/zeppelin-interpreter/</guid>
      <description>Apache Zeppelin 과 Cloudera CDH 의 Hive, Impala 를 연동하는 방법을 알아볼게요.
Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1 Cloudera CDH 6.1.1 Hive 2.1.1 Impala 3.1.0 Impala JDBC Driver 2.6.12  Hive Zeppelin Hive Interpreter Document 문서를 보면 Jdbc Interpreter 를 사용하라고 되어있네요. 기본으로 PostgreSQL Connector 지원하고 그외는 Connector 는 추가를 해줘야 해요.
Maven Repository Zeppelin 콘솔에서 우측 상단의 메뉴에서 interpreter 메뉴를 클릭하여 Interpreter 설정 화면으로 이동해요. Repository 버튼을 클릭하면 등록되어져 있는 Repository 를 확인 할 수 있어요.</description>
    </item>
    
    <item>
      <title>빅데이터 시각화 Zeppelin Usage</title>
      <link>http://hahafamilia.github.io/developement/bigdata/zeppelin-usage/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/zeppelin-usage/</guid>
      <description>Apache Zeppelin 은 노트북 방식의 시각화 툴이예요.
Environment  Oracle JDK 1.8 CentOS 7 Zepplin 0.8.1  Dynamic Form Zeppelin 에서는 Dynamic Form 을 제공하고 있어서 Form 을 통해 입력받은 값으로 조건을 주는 형태로 사용 가능해요. Dynamic Form 은 Paragraph scope 와 Note scope 에서 사용 문법의 차이가 있고, 또한 Programmatically 하게 추가하실 수 있어요. 예제에서는 text, select, checkbox 를 소개하고 있네요.
Paragraph scope Text input form ${formName=defaultValue} 의 형태예요.</description>
    </item>
    
    <item>
      <title>빅데이터 시각화 Zeppelin 설치, QuickStart</title>
      <link>http://hahafamilia.github.io/developement/bigdata/zeppelin-quickstart/</link>
      <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/zeppelin-quickstart/</guid>
      <description>Apache Zeppelin 은 노트북 방식의 시각화 툴이예요. 다양한 시각화 툴이 존재하지만 &amp;lsquo;가장 좋은 것&amp;rsquo;이 아니라 &amp;lsquo;나에게 맞는 것&amp;rsquo; 을 선택했어요. 제가 Zeppelin을 선택한 이유는 아래와 같아요.
 설치와 사용법이 쉬워야 한다. 요구사항을 유연하게 처리 할 수 있어야 한다. BI 웹 어드민을 개발 하지 않아도 되도록 정적 HTML 을 제공해야 한다.  화# Environment * Oracle JDK 1.8 * CentOS 7 * Zepplin 0.8.1
Zeppelin 와우! Zeppelin~ 아파치 오픈 소스 프로젝트에 채택된 국내 프로젝트네요.</description>
    </item>
    
    <item>
      <title>Oozie Workflow Email 알림 설정</title>
      <link>http://hahafamilia.github.io/developement/bigdata/oozie-workflow-email/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/oozie-workflow-email/</guid>
      <description>Oozie 에서 Workflow 의 결과에 따른 Email 알림을 받는 방법에 대해서 알아볼게요.
Workflow 를 1회성으로 실행시키는 경우와 Schedule 로 등록하여 주기적으로 실행하는 경우가 있을 수 있을텐데요. 1회성으로 Workflow 만 실행할때는 성공/실패에 대한 처리 결과를 받도록 하고, Schedule 로 등록하여 주기적으로 실행하는 경우에는 실패에 대한 알림 만을 받도록 합니다.
Version  Cloudera 6.1.1 Oozie 5.0.0 Hue 4.3.0  Oozie SMTP 설정 Cloudera Manager &amp;gt; Oozie &amp;gt; 구성 탭 에서 mail 을 검색해서, oozie.</description>
    </item>
    
    <item>
      <title>AvroFlumeEvent, 이벤트 데이터의 발생 시각에 따른 데이터 수집</title>
      <link>http://hahafamilia.github.io/developement/bigdata/spring-kafka-flume/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/spring-kafka-flume/</guid>
      <description>다음과 같은 데이터 파이프 라인을 가정해 볼게요.
 사용자의 Activity 이벤트가 발생 API 서버를 통해 Kafka 에 Produce Flume 을 통해 Kafka 의 메시지를 HDFS 로 적재 HDFS 에는 일자 별로 생성된 디렉토리에 저장  Flume 을 퉁한 데이터 수집시에 Hdfs Sink 는 useLocalTimestamp 설정은 제공 해요. 하지만 이 설정은 이벤트의 수집 시각을 기준으로 해요.
예제 그림에서 API 에서 시작된 데이터는 파이프라인을 거쳐 HDFS 에 도달하기까지 2초의 시간이 소요된다고 가정하면, 2019-08-01 23:59:59 시각에 발생한 이벤트는 useLocalTimestamp 설정에 의해 2019-08-02 00:00:01 의 시각으로 2019-08-02 디렉토리에 적재됩니다.</description>
    </item>
    
    <item>
      <title>Cloudera Manager 알람 설정, Gmail SMPT 서버 사용</title>
      <link>http://hahafamilia.github.io/developement/bigdata/cloudera-alert-email/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/cloudera-alert-email/</guid>
      <description>Cloudera Manager 알림을 보내는 방법은 SMTP, SNMP, Custom Script 세가지를 제공하고 있어요. 여기서 SNMP, Custom Script 는 Enterprise 버전에서만 지원해요. 별도의 SMTP 서버를 운영하고 있지 않다면 Gmail 을 이용할 수 있어요.
Cloudera Version Cloudera 6.1
Gmail 설정 우선 Gmail 설정에서 IMAP 사용이 허용되어야 해요. 그리고 Google 계정 설정 &amp;gt; 보안 &amp;gt; 보안 수준이 낮은 앱의 액세스 가 허용되어야 합니다.
 이 방법은 보안상 권장하지 않는 방법 이예요. 하지만 제가 근무하는 회사의 G Suite 에서는 액세스키에 의한 접근 기능이 제공되고 있지 안아서 이 방법을 사용하고 있어요.</description>
    </item>
    
    <item>
      <title>Python 개발환경, Pyenv, Anaconda3</title>
      <link>http://hahafamilia.github.io/developement/python/python-pyenv-anaconda-mac/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/python/python-pyenv-anaconda-mac/</guid>
      <description>Mac 에서 Homebrew 통해서 Python 가상화 환경을 구성하려고 합니다. 우선 Mac 버전이 모하비라면 모하비 brew error 글을 한번 읽어보세요.
Python 가상환경 구성방법은 여러가지가 있지만, pyenv/virtualenv 를 사용할거예요. 대략적인 과정은 pyenv 설치, anaconda3 설치, 가상환경 구성의 순서예요. pyenv 는 가상화 관리를 위해서 pyenv-virtual 패키지를 사용하는데, anaconda3 정도만 사요할 예정이면 설치 하지 않아요 되요.
pyenv brew help brew update brew install pyenv pyenv -v pyenv 1.2.13 pyenv install -list | grep anaconda .</description>
    </item>
    
    <item>
      <title>Hive Java UDF, 유니코드</title>
      <link>http://hahafamilia.github.io/developement/bigdata/hive-java-udf/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/hive-java-udf/</guid>
      <description>개요 Cloudera Document 6.1 Hive UDF 문서를 참고하여 Cloudera CDH 플랫폼에서 HIVE UDF 를 작성하는 방법을 알아봅니다.
또한 MySQL의 Collate 와 문자열 유니코드에 대해서도 간단히 알아보겠습니다.
저의 이번 경우는 HIVE로 집계된 데이터를 SQOOP으로 export 시에 오류가 발생하였습니다.
기존에 설계된 MySQL 디비의 테이블 칼럼 Collate 속성이 utf8-general-ci 로 설계되어 있어 Key 칼럼에 Accent 문자열을 포함하는 문자열 데이터 자정시에 상황에 따라 키중복이 발생했던 것이었습니다.
칼럼의 Collate 속성이 utf8-general-ci 일경우 아래와 같은 경우 ã 문자열은 저장이 되겠지만 a 문자열 저장시 Key 중복 오류가 발생합니다.</description>
    </item>
    
    <item>
      <title>Kafka Broker 디스크 증설, RAID구성, OS 재설치</title>
      <link>http://hahafamilia.github.io/developement/bigdata/kafka-broker-reinstall/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/bigdata/kafka-broker-reinstall/</guid>
      <description>Kafka Broker 재설치 Kafka Broker 서버의 디스크 용량을 증설하는 작업을 진행 하게 되었습니다. RAID 10으로 디스크 구성을 변경하다보니 불가피하게 OS를 재설치 합니다. Kafka는 Broker 서버의 장애 상황에서도 서비스를 유지 할 수 있도록 설계되어 있어요. Broker 서버를 1대씩 순차적으로 RAID 구성 및 OS 재설치 진행후에 Partition을 Reassign 할 계획입니다.
Environment  CentOS 7.6 Cloudera CDH 6.1.1 Cloudera Manager Kafka 2.0.0-cdh6.1.1 Kafka Manager Kafka Broker 3대 Replication fector 3  HowTo Cloudera Manager 에서 작업대상 Broker 서버를 서비스에서 제거해요.</description>
    </item>
    
    <item>
      <title>Markdown 작성법</title>
      <link>http://hahafamilia.github.io/developement/howto/markdown/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/howto/markdown/</guid>
      <description># header ## header ### header #### header ##### header ###### header  header header header header header header *** --- ===  ===
# header ## header ### header #### header ##### header ###### header  header header header header header header 1. List 1. List 1. Sub List 1. List  * List * List * List * List - List + List   List  List  List   List List List</description>
    </item>
    
    <item>
      <title>모든 주식을 소유하라</title>
      <link>http://hahafamilia.github.io/developement/book/%EB%AA%A8%EB%93%A0%EC%A3%BC%EC%8B%9D%EC%9D%84%EC%86%8C%EC%9C%A0%ED%95%98%EB%9D%BC/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/book/%EB%AA%A8%EB%93%A0%EC%A3%BC%EC%8B%9D%EC%9D%84%EC%86%8C%EC%9C%A0%ED%95%98%EB%9D%BC/</guid>
      <description>Description 세계 4대 투자의 거장, 존 보글의 투자 법칙.
2015년 워렌 버핏이 주주들에게 주천한 책!
교보문고
우화, 고트락스 가문 고트락스라는 부자 가문이 여러 대에 걸쳐 번창하여 형제, 자매, 삼촌, 사촌이 수천명이나 되었고, 미국의 모든 주식을 100% 소유하게 되었다. 얼마 후 브로커가 나타나서 다른 친척들보다 돈을 더 많이 벌 수 있는 방법이 있다고 속삭였다. 브로커들은 친척에게 보유 주식을 사고 팔게 했다. 브로커들은 대가로 수수료를 받고, 가문 사람들은 주식을 거래하는데 발생하는 자본이득에 대해서도 세금을 내야 했다.</description>
    </item>
    
    <item>
      <title>Jekyll, Github.io, Minimal mistakes 블로그 만들기, 목차 한글링크 버그</title>
      <link>http://hahafamilia.github.io/developement/howto/jekyll-github-mistakes-blog/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://hahafamilia.github.io/developement/howto/jekyll-github-mistakes-blog/</guid>
      <description>개발자 초창기에는 블로그(이전의 블로그) 활동도 열심히 했었는데&amp;hellip; 너무 잊고 살았었네요. 새롭게 블로그를 시작 할 생각에 Jekyll, Github.io 로 블로그를 구성하게 되었어요.
간단히 Jekyll 은 정적파일 생성기, Github.io 는 호스팅, Minimal mistakes 는 수많은 Jekyll 테마중의 하나예요.
선택의 기준은 markdown 에디터 때문이에요. 개발자는 에디터 툴을 가장 많이 다루는데요. 아무래도 markdown 으로 글을 작성하고 Git 으로 Push 하여 포스팅을 하는 구조라면 블로그 활동량이 많아지지 않을까 합니다.
그럼 Github.io, Jekyll, Minimal mistakes theme 를 이용해 블로그를 만들어 봐요.</description>
    </item>
    
  </channel>
</rss>